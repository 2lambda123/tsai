{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transforms\n",
    "\n",
    "> Main functions used to transform TSTensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.augment import RandTransform\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.external import *\n",
    "from tsai.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.ndimage import convolve1d, zoom\n",
    "import pywt\n",
    "from pyts.image.gaf import GramianAngularField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NATOPS\n",
      "X      : (360, 24, 51)\n",
      "y      : (360,)\n",
      "splits : ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=True, return_split=False)\n",
    "tfms = [None, Categorize()]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)\n",
    "train_ds = dsets.train\n",
    "valid_ds = dsets.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToNumpyCategory(Transform):\n",
    "    \"Categorize a numpy batch\"\n",
    "    order = 90\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def encodes(self, o: np.ndarray):\n",
    "        self.type = type(o)\n",
    "        self.cat = Categorize()\n",
    "        self.cat.setup(o)\n",
    "        self.vocab = self.cat.vocab\n",
    "        return np.asarray(stack([self.cat(oi) for oi in o]))\n",
    "\n",
    "    def decodes(self, o: (np.ndarray, torch.Tensor)):\n",
    "        return stack([self.cat.decode(oi) for oi in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 3, 2, 4, 0, 5, 2, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ToNumpyCategory()\n",
    "y_cat = t(y)\n",
    "y_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.decode(tensor(y_cat)), y)\n",
    "test_eq(t.decode(np.array(y_cat)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OneHot(Transform): \n",
    "    \"One-hot encode/ decode a batch\"\n",
    "    order = 90\n",
    "    def __init__(self, n_classes=None, **kwargs): \n",
    "        self.n_classes = n_classes\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: torch.Tensor): \n",
    "        if not self.n_classes: self.n_classes = len(np.unique(o))\n",
    "        return torch.eye(self.n_classes)[o]\n",
    "    def encodes(self, o: np.ndarray): \n",
    "        o = ToNumpyCategory()(o)\n",
    "        if not self.n_classes: self.n_classes = len(np.unique(o))\n",
    "        return np.eye(self.n_classes)[o]\n",
    "    def decodes(self, o: torch.Tensor): return torch.argmax(o, dim=-1)\n",
    "    def decodes(self, o: np.ndarray): return np.argmax(o, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_encoder = OneHot()\n",
    "y_cat = ToNumpyCategory()(y)\n",
    "oht = oh_encoder(y_cat)\n",
    "oht[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = 100\n",
    "\n",
    "t = torch.randint(0, n_classes, (n_samples,))\n",
    "oh_encoder = OneHot()\n",
    "oht = oh_encoder(t)\n",
    "test_eq(oht.shape, (n_samples, n_classes))\n",
    "test_eq(torch.argmax(oht, dim=-1), t)\n",
    "test_eq(oh_encoder.decode(oht), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = 100\n",
    "\n",
    "a = np.random.randint(0, n_classes, (n_samples,))\n",
    "oh_encoder = OneHot()\n",
    "oha = oh_encoder(a)\n",
    "test_eq(oha.shape, (n_samples, n_classes))\n",
    "test_eq(np.argmax(oha, axis=-1), a)\n",
    "test_eq(oh_encoder.decode(oha), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSStandardize(Transform):\n",
    "    \"Standardizes batch of type `NumpyTensor` or `TSTensor`\"\n",
    "    parameters, order = L('mean', 'std'), 97\n",
    "    def __init__(self, mean=None, std=None, by_sample=False, by_var=False, verbose=False):\n",
    "        self.mean = tensor(mean) if mean is not None else None\n",
    "        self.std = tensor(std) if std is not None else None\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axes = (2)\n",
    "        elif by_sample: self.axes = (1, 2)\n",
    "        elif by_var: self.axes = (0, 2)\n",
    "        else: self.axes = ()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std): return cls(mean, std)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x, *_ = dl.one_batch()\n",
    "            self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "            if len(self.mean.shape) == 0: \n",
    "                pv(f'{self.__class__.__name__} setup mean={self.mean}, std={self.std}, by_sample={self.by_sample}, by_var={self.by_var}\\n', \n",
    "                   self.verbose)\n",
    "            else: \n",
    "                pv(f'{self.__class__.__name__} setup mean shape={self.mean.shape}, std shape={self.std.shape}, by_sample={self.by_sample}, by_var={self.by_var}\\n', self.verbose)\n",
    "\n",
    "    def encodes(self, x:(NumpyTensor, TSTensor)): \n",
    "        if self.by_sample: self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "        return (x - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def mul_min(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.min(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    min_x = x\n",
    "    for ax in axes: min_x, _ = min_x.min(ax, keepdim)\n",
    "    return retain_type(min_x, x)\n",
    "\n",
    "\n",
    "@patch\n",
    "def mul_max(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.max(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    max_x = x\n",
    "    for ax in axes: max_x, _ = max_x.max(ax, keepdim)\n",
    "    return retain_type(max_x, x)\n",
    "\n",
    "\n",
    "class TSNormalize(Transform):\n",
    "    \"Normalizes batch of type `NumpyTensor` or `TSTensor`\"\n",
    "    parameters, order = L('min', 'max'), 97\n",
    "\n",
    "    def __init__(self, min=None, max=None, range=(-1, 1), by_sample=True, by_var=False, verbose=False):\n",
    "        self.min = tensor(min) if min is not None else None\n",
    "        self.max = tensor(max) if max is not None else None\n",
    "        self.range_min, self.range_max = range\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axes = (2)\n",
    "        elif by_sample: self.axes = (1, 2)\n",
    "        elif by_var: self.axes = (0, 2)\n",
    "        else: self.axes = ()\n",
    "        self.verbose = verbose\n",
    "            \n",
    "    @classmethod\n",
    "    def from_stats(cls, min, max, range_min=0, range_max=1): return cls(min, max, self.range_min, self.range_max)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.min is None or self.max is None:\n",
    "            x, *_ = dl.one_batch()\n",
    "            self.min, self.max = x.mul_min(self.axes, keepdim=self.axes!=()), x.mul_max(self.axes, keepdim=self.axes!=())\n",
    "            if len(self.min.shape) == 0: \n",
    "                pv(f'{self.__class__.__name__} setup min={self.min}, max={self.max}, range_min={self.range_min}, range_max={self.range_max}, by_sample={self.by_sample}, by_var={self.by_var}\\n', self.verbose)\n",
    "            else:\n",
    "                pv(f'{self.__class__.__name__} setup min shape={self.min.shape}, max shape={self.max.shape}, range_min={self.range_min}, range_max={self.range_max}, by_sample={self.by_sample}, by_var={self.by_var}\\n', self.verbose)\n",
    "\n",
    "    def encodes(self, x:(NumpyTensor, TSTensor)): \n",
    "        if self.by_sample: self.min, self.max = x.mul_min(self.axes, keepdim=self.axes!=()), x.mul_max(self.axes, keepdim=self.axes!=())\n",
    "        return torch.clamp(((x - self.min) / (self.max - self.min)) * (self.range_max - self.range_min) + self.range_min, \n",
    "                           self.range_min, self.range_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSStandardize setup mean shape=torch.Size([128, 1, 1]), std shape=torch.Size([128, 1, 1]), by_sample=True, by_var=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_tfms=[TSStandardize(by_sample=True, by_var=False, verbose=True)]\n",
    "dls = TSDataLoaders.from_dsets(train_ds, valid_ds, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTensor(samples:128, vars:24, len:51)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSStandardize(by_sample=True, verbose=True)(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms=[TSStandardize(by_sample=True, by_var=False, verbose=False)]\n",
    "dls = TSDataLoaders.from_dsets(train_ds, valid_ds, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)\n",
    "xb, yb = next(iter(dls.valid))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms=[TSNormalize(by_sample=True, by_var=False, verbose=False)]\n",
    "dls = TSDataLoaders.from_dsets(train_ds, valid_ds, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "assert xb.max() <= 1\n",
    "assert xb.min() >= -1\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)\n",
    "xb, yb = next(iter(dls.valid))\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TSDataLoaders.from_dsets(train_ds, valid_ds, bs=128, num_workers=0)\n",
    "xb, yb = next(iter(dls.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSStdBySample(Transform):\n",
    "    \"Standardizes each sample in a batch (optionally by_var)\"\n",
    "    order = 80\n",
    "    def __init__(self, by_var=False):\n",
    "        super().__init__()\n",
    "        if by_var: self.dim = (2)\n",
    "        else: self.dim = (1,2)\n",
    "    \n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        o /= o.std(self.dim, keepdim=True)\n",
    "        o -= o.mean(self.dim, keepdim=True)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(TSStdBySample()(xb).std(), 1, eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSIdentity(RandTransform):\n",
    "    \"Applies the identity tfm to a `TSTensor` batch\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=None, **kwargs): \n",
    "        self.magnitude = magnitude \n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSIdentity()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# partial(TSShuffle_HLs, ex=0), \n",
    "class TSShuffle_HLs(RandTransform):\n",
    "    \"Randomly shuffles HIs/LOs of an OHLC `TSTensor` batch\"\n",
    "    order = 70\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        timesteps = o.shape[-1] // 4\n",
    "        pos_rand_list = np.random.choice(np.arange(timesteps),size=random.randint(1, timesteps),replace=False)\n",
    "        rand_list = pos_rand_list * 4\n",
    "        highs = rand_list + 1\n",
    "        lows = highs + 1\n",
    "        a = np.vstack([highs, lows]).flatten('F')\n",
    "        b = np.vstack([lows, highs]).flatten('F')\n",
    "        output = o.clone()\n",
    "        output[...,a] = output[...,b]\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSShuffle_HLs()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# partial(TSShuffleSteps, ex=0), \n",
    "class TSShuffleSteps(RandTransform):\n",
    "    \"Randomly shuffles consecutive sequence datapoints in batch\"\n",
    "    order = 70\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        odd = 1 - o.shape[-1]%2\n",
    "        r = np.random.randint(2)\n",
    "        timesteps = o.shape[-1] // 2\n",
    "        pos_rand_list = np.random.choice(np.arange(0, timesteps - r * odd), size=random.randint(1, timesteps - r * odd),replace=False) * 2 + 1 + r\n",
    "        a = np.vstack([pos_rand_list, pos_rand_list - 1]).flatten('F')\n",
    "        b = np.vstack([pos_rand_list - 1, pos_rand_list]).flatten('F')\n",
    "        output = o.clone()\n",
    "        output[...,a] = output[...,b]\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = TSTensor(torch.arange(11).float())\n",
    "tt_ = []\n",
    "for _ in range(1000): \n",
    "    tt = TSShuffleSteps()(t, split_idx=0)\n",
    "    test_eq(len(set(tt.tolist())), len(t))\n",
    "    test_ne(tt, t)\n",
    "    tt_.extend([t for i,t in enumerate(tt) if t!=i])\n",
    "x, y = np.unique(tt_, return_counts=True) # This is to visualize distribution which should be equal for all and half for first and last items\n",
    "plt.bar(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSMagAddNoise(RandTransform):\n",
    "    \"Applies additive noise on the y-axis for each step of a `TSTensor` batch\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1, ex=None, **kwargs):\n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        # output = o + torch.normal(0, o.std() * self.magnitude, o.shape, dtype=o.dtype, device=o.device)\n",
    "        output = o + torch.normal(0, 1/3, o.shape, dtype=o.dtype, device=o.device) * (o[..., 1:] - o[..., :-1]).std(2, keepdims=True) * self.magnitude\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output\n",
    "\n",
    "class TSMagMulNoise(RandTransform): \n",
    "    \"Applies multiplicative noise on the y-axis for each step of a `TSTensor` batch\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        noise = torch.normal(1, self.magnitude * .025, o.shape, dtype=o.dtype, device=o.device)\n",
    "        output = o * noise\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSMagAddNoise()(xb, split_idx=0).shape, xb.shape)\n",
    "test_eq(TSMagMulNoise()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSMagAddNoise()(xb, split_idx=0), xb)\n",
    "test_ne(TSMagMulNoise()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_curve_generator(o, magnitude=0.1, order=4, noise=None):\n",
    "    seq_len = o.shape[-1]\n",
    "    f = CubicSpline(np.linspace(-seq_len, 2 * seq_len - 1, 3 * (order - 1) + 1, dtype=int), \n",
    "                    np.random.normal(loc=1.0, scale=magnitude, size=3 * (order - 1) + 1), axis=-1)\n",
    "    return f(np.arange(seq_len))\n",
    "\n",
    "def random_cum_curve_generator(o, magnitude=0.1, order=4, noise=None):\n",
    "    x = random_curve_generator(o, magnitude=magnitude, order=order, noise=noise).cumsum()\n",
    "    x -= x[0]\n",
    "    x /= x[-1]\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x * (o.shape[-1] - 1)\n",
    "\n",
    "def random_cum_noise_generator(o, magnitude=0.1, noise=None):\n",
    "    seq_len = o.shape[-1]\n",
    "    x = np.clip(np.ones(seq_len) + np.random.normal(loc=0, scale=magnitude, size=seq_len), 0, 1000).cumsum()\n",
    "    x -= x[0]\n",
    "    x /= x[-1]\n",
    "    return x * (o.shape[-1] - 1)\n",
    "\n",
    "def random_cum_linear_generator(o, magnitude=0.1):\n",
    "    seq_len = o.shape[-1]\n",
    "    win_len = int(round(seq_len * np.random.rand() * magnitude))\n",
    "    if win_len == seq_len: return np.arange(o.shape[-1])\n",
    "    start = np.random.randint(0, seq_len - win_len)\n",
    "    # mult between .5 and 2\n",
    "    rand = np.random.rand()\n",
    "    mult = 1 + rand\n",
    "    if np.random.randint(2): mult = 1 - rand/2\n",
    "    x = np.ones(seq_len)\n",
    "    x[start : start + win_len] = mult\n",
    "    x = x.cumsum()\n",
    "    x -= x[0]\n",
    "    x /= x[-1]\n",
    "    return np.clip(x, 0, 1) * (seq_len - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTimeNoise(RandTransform):\n",
    "    \"Applies noise to each step in the x-axis of a `TSTensor` batch based on smooth random curve\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.1, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)\n",
    "        output = o.new(f(random_cum_noise_generator(o, magnitude=self.magnitude)))\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSTimeNoise()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSTimeNoise()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSMagWarp(RandTransform):\n",
    "    \"Applies warping to the y-axis of a `TSTensor` batch based on a smooth random curve\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.02, ord=4, ex=None, **kwargs): \n",
    "        self.magnitude, self.ord, self.ex = magnitude, ord, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if self.magnitude and self.magnitude <= 0: return o\n",
    "        y_mult = random_curve_generator(o, magnitude=self.magnitude, order=self.ord)\n",
    "        output = o * o.new(y_mult)\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSMagWarp()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSMagWarp()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTimeWarp(RandTransform):\n",
    "    \"Applies time warping to the x-axis of a `TSTensor` batch based on a smooth random curve\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.02, ord=4, ex=None, **kwargs): \n",
    "        self.magnitude, self.ord, self.ex = magnitude, ord, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)\n",
    "        output = o.new(f(random_cum_curve_generator(o, magnitude=self.magnitude, order=self.ord)))\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSTimeWarp()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSTimeWarp()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSWindowWarp(RandTransform):\n",
    "    \"\"\"Applies window slicing to the x-axis of a `TSTensor` batch based on a random linear curve based on\n",
    "    https://halshs.archives-ouvertes.fr/halshs-01357973/document\"\"\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.1, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o\n",
    "        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)\n",
    "        output = o.new(f(random_cum_linear_generator(o, magnitude=self.magnitude)))\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSWindowWarp()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSWindowWarp()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSMagScale(RandTransform):\n",
    "    \"Applies scaling to the y-axis of a `TSTensor` batch based on a scalar\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.5, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        rand = random_half_normal()\n",
    "        scale = (1 - (rand  * self.magnitude)/2) if random.random() > 1/3 else (1 + (rand  * self.magnitude))\n",
    "        output = o * scale\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output\n",
    "    \n",
    "class TSMagScalePerVar(RandTransform):\n",
    "    \"Applies per_var scaling to the y-axis of a `TSTensor` batch based on a scalar\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.5, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        s = [1] * o.ndim\n",
    "        s[-2] = o.shape[-2]\n",
    "        rand = random_half_normal_tensor(s, device=o.device)\n",
    "        scale = (1 - (rand  * self.magnitude)/2) if random.random() > 1/3 else (1 + (rand  * self.magnitude))\n",
    "        output = o * scale\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSMagScale()(xb, split_idx=0).shape, xb.shape)\n",
    "test_eq(TSMagScalePerVar()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSMagScale()(xb, split_idx=0), xb)\n",
    "test_ne(TSMagScalePerVar()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomResizedCrop(RandTransform):\n",
    "    \"Randomly amplifies a sequence focusing on a random section of the steps\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.1, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = max(lambd, 1 - lambd)\n",
    "        win_len = int(round(seq_len * lambd))\n",
    "        if win_len == seq_len: return o\n",
    "        start = np.random.randint(0, seq_len - win_len)\n",
    "        return F.interpolate(o[..., start : start + win_len], size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "    \n",
    "TSRandomZoomIn = TSRandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomZoomIn(.5)(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSWindowSlicing(RandTransform):\n",
    "    \"Randomly extracts an resize a ts slice based on https://halshs.archives-ouvertes.fr/halshs-01357973/document\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.1, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        win_len = int(round(seq_len * (1 - self.magnitude)))\n",
    "        if win_len == seq_len: return o\n",
    "        start = np.random.randint(0, seq_len - win_len)\n",
    "        return F.interpolate(o[..., start : start + win_len], size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSWindowSlicing()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSWindowSlicing()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomZoomOut(RandTransform):\n",
    "    \"Randomly compresses a sequence on the x-axis\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.1, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = max(lambd, 1 - lambd)\n",
    "        win_len = int(round(seq_len * lambd))\n",
    "        if win_len == seq_len: return o\n",
    "        start = (seq_len - win_len) // 2\n",
    "        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)\n",
    "        interp = F.interpolate(o, size=win_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        output[..., start:start + win_len] = o.new(interp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomZoomOut(.5)(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomTimeScale(RandTransform):\n",
    "    \"Randomly amplifies/ compresses a sequence on the x-axis keeping the same length\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.1, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        if np.random.rand() <= 0.5: return TSRandomZoomIn(magnitude=self.magnitude, ex=self.ex, mode=self.mode)(o, split_idx=0)\n",
    "        else: return TSRandomZoomOut(magnitude=self.magnitude, ex=self.ex, mode=self.mode)(o, split_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomTimeScale(.5)(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomTimeStep(RandTransform):\n",
    "    \"Compresses a sequence on the x-axis by randomly selecting sequence steps and interpolating to previous size\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.02, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        new_seq_len = int(round(seq_len * max(.5, (1 - np.random.rand() * self.magnitude))))\n",
    "        if  new_seq_len == seq_len: return o\n",
    "        timesteps = np.sort(np.random.choice(np.arange(seq_len),new_seq_len, replace=False))\n",
    "        output = F.interpolate(o[..., timesteps], size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomTimeStep()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSBlur(RandTransform):\n",
    "    \"Blurs a sequence applying a filter of type [1, 0, 1]\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        self.filterargs = np.array([1, 0, 1])\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        w = self.filterargs * np.random.rand(3)\n",
    "        w = w / w.sum()\n",
    "        output = o.new(convolve1d(o.cpu(), w, mode='nearest'))\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSBlur()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSBlur()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSSmooth(RandTransform):\n",
    "    \"Smoothens a sequence applying a filter of type [1, 5, 1]\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        self.filterargs = np.array([1, 5, 1])\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        w = self.filterargs * np.random.rand(3)\n",
    "        w = w / w.sum()\n",
    "        output = o.new(convolve1d(o.cpu(), w, mode='nearest'))\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSSmooth()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSSmooth()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maddest(d, axis=None): #Mean Absolute Deviation\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "class TSFreqDenoise(RandTransform):\n",
    "    \"Denoises a sequence applying a wavelet decomposition method\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.1, ex=None, wavelet='db4', level=2, thr=None, thr_mode='hard', pad_mode='per', **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        self.wavelet, self.level, self.thr, self.thr_mode, self.pad_mode = wavelet, level, thr, thr_mode, pad_mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        \"\"\"\n",
    "        1. Adapted from waveletSmooth function found here:\n",
    "        http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
    "        2. Threshold equation and using hard mode in threshold as mentioned\n",
    "        in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
    "        http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "        \"\"\"\n",
    "        seq_len = o.shape[-1]\n",
    "        # Decompose to get the wavelet coefficients\n",
    "        coeff = pywt.wavedec(o.cpu(), self.wavelet, mode=self.pad_mode)\n",
    "        # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "        # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
    "        sigma = (1/0.6745) * maddest(coeff[-self.level])\n",
    "        # Calculate the univeral threshold\n",
    "        uthr = sigma * np.sqrt(2*np.log(seq_len)) * (1 if self.thr is None else self.magnitude)\n",
    "        coeff[1:] = (pywt.threshold(c, value=uthr, mode=self.thr_mode) for c in coeff[1:])\n",
    "        # Reconstruct the signal using the thresholded coefficients\n",
    "        output = o.new(pywt.waverec(coeff, self.wavelet, mode=self.pad_mode)[..., :seq_len])\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSFreqDenoise()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSFreqDenoise()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomFreqNoise(RandTransform):\n",
    "    \"Applys random noise using a wavelet decomposition method\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.1, ex=None, wavelet='db4', level=2, mode='constant', **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        self.wavelet, self.level, self.mode = wavelet, level, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        self.level = 1 if self.level is None else self.level\n",
    "        coeff = pywt.wavedec(o.cpu(), self.wavelet, mode=self.mode, level=self.level)\n",
    "        coeff[1:] = [c * (1 + 2 * (np.random.rand() - 0.5) * self.magnitude) for c in coeff[1:]]\n",
    "        output = o.new(pywt.waverec(coeff, self.wavelet, mode=self.mode)[..., :o.shape[-1]])\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomFreqNoise()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomResizedLookBack(RandTransform):\n",
    "    \"Selects a random number of sequence steps starting from the end and return an output of the same shape\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.1, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.mode = magnitude, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = min(lambd, 1 - lambd)\n",
    "        output = o.clone()[..., int(round(lambd * seq_len)):]\n",
    "        return F.interpolate(output, size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): \n",
    "    o = TSRandomResizedLookBack()(xb, split_idx=0)\n",
    "    test_eq(o.shape[-1], xb.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSVarOut(RandTransform):\n",
    "    \"Set the value of a random number of variables to zero\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.05, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        in_vars = o.shape[-2]\n",
    "        if in_vars == 1: return o\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = min(lambd, 1 - lambd)\n",
    "        p = np.arange(in_vars).cumsum()\n",
    "        p = p/p[-1]\n",
    "        p = p / p.sum()\n",
    "        p = p[::-1]\n",
    "        out_vars = np.random.choice(np.arange(in_vars), int(round(lambd * in_vars)), p=p, replace=False)\n",
    "        if len(out_vars) == 0:  return o\n",
    "        output = o.clone()\n",
    "        output[...,out_vars,:] = 0\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSVarOut()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSCutOut(RandTransform):\n",
    "    \"Sets a random section of the sequence to zero\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.05, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = min(lambd, 1 - lambd)\n",
    "        win_len = int(round(seq_len * lambd))\n",
    "        start = np.random.randint(-win_len + 1, seq_len)\n",
    "        end = start + win_len\n",
    "        start = max(0, start)\n",
    "        end = min(end, seq_len)\n",
    "        output = o.clone()\n",
    "        output[..., start:end] = 0\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSCutOut()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTimeStepOut(RandTransform):\n",
    "    \"Sets random sequence steps to zero\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.05, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        magnitude = min(.5, self.magnitude)\n",
    "        seq_len = o.shape[-1]\n",
    "        timesteps = np.sort(np.random.choice(np.arange(seq_len), int(round(seq_len * magnitude)), replace=False))\n",
    "        output = o.clone()\n",
    "        output[..., timesteps] = 0\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSTimeStepOut()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomCropPad(RandTransform):\n",
    "    \"Crops a section of the sequence of a random length\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.05, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = max(lambd, 1 - lambd)\n",
    "        win_len = int(round(seq_len * lambd))\n",
    "        if win_len == seq_len: return o\n",
    "        start = np.random.randint(0, seq_len - win_len)\n",
    "        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)\n",
    "        output[..., start : start + win_len] = o[..., start : start + win_len]\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomCropPad()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSMaskOut(RandTransform):\n",
    "    \"Set a random number of steps to zero\"\n",
    "    order = 95\n",
    "    def __init__(self, magnitude=0.05, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        mask = torch.rand_like(o) <= self.magnitude\n",
    "        output = o.clone()\n",
    "        output[mask] = 0\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSMaskOut()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSMaskOut()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTranslateX(RandTransform):\n",
    "    \"Moves a selected sequence window a random number of steps\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=0.1, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        seq_len = o.shape[-1]\n",
    "        lambd = np.random.beta(self.magnitude, self.magnitude)\n",
    "        lambd = min(lambd, 1 - lambd)\n",
    "        shift = int(round(seq_len * lambd))\n",
    "        if shift == 0 or shift == seq_len: return o\n",
    "        if np.random.rand() < 0.5: shift = -shift\n",
    "        new_start = max(0, shift)\n",
    "        new_end = min(seq_len + shift, seq_len)\n",
    "        start = max(0, -shift)\n",
    "        end = min(seq_len - shift, seq_len)\n",
    "        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)\n",
    "        output[..., new_start : new_end] = o[..., start : end]\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSTranslateX()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomShift(RandTransform):\n",
    "    \"Shifts and splits a sequence\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=0.02, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        pos = int(round(np.random.randint(0, o.shape[-1]) * self.magnitude)) * (random.randint(0, 1)*2-1)\n",
    "        output = torch.cat((o[..., pos:], o[..., :pos]), dim=-1)\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomShift()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSHorizontalFlip(RandTransform):\n",
    "    \"Flips the sequence along the x-axis\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        output = torch.flip(o, [-1])\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSHorizontalFlip()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSHorizontalFlip()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomTrend(RandTransform):\n",
    "    \"Randomly rotates the sequence along the z-axis\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=0.1, ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        flat_x = o.reshape(o.shape[0], -1)\n",
    "        ran = flat_x.max(dim=-1, keepdim=True).values - flat_x.min(dim=-1, keepdim=True).values\n",
    "        trend = torch.linspace(0, 1, o.shape[-1], device=o.device) * ran\n",
    "        t = (1 + self.magnitude * 2 * (np.random.rand() - 0.5) * trend)\n",
    "        t -= t.mean(-1, keepdim=True)\n",
    "        if o.ndim == 3: t = t.unsqueeze(1)\n",
    "        output = o + t\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output\n",
    "    \n",
    "TSRandomRotate = TSRandomTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomTrend()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSVerticalFlip(RandTransform):\n",
    "    \"Applies a negative value to the time sequence\"\n",
    "    order = 90\n",
    "    def __init__(self, magnitude=1., ex=None, **kwargs): \n",
    "        self.magnitude, self.ex = magnitude, ex\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        return - o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSVerticalFlip()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSVerticalFlip()(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSResize(RandTransform):\n",
    "    \"Resizes the sequence length of a time series\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=-0.5, size=None, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.size, self.ex, self.mode = magnitude, size, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if self.magnitude == 0: return o\n",
    "        size = ifnone(self.size, int(round((1 + self.magnitude) * o.shape[-1])))\n",
    "        output = F.interpolate(o, size=size, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in np.linspace(.2, 2, 10): test_eq(TSResize(sz)(xb, split_idx=0).shape[-1], int(round(xb.shape[-1]*(1+sz))))\n",
    "test_ne(TSResize(1)(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomSize(RandTransform):\n",
    "    \"Randomly resizes the sequence length of a time series\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0., ex=None, mode='linear', **kwargs):\n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        size_perc = 1 / (1 + (random_half_normal() if random.random() > 1/3 else - random_half_normal() / 2) * (1 + self.magnitude))\n",
    "        if random.random() > .5: size_perc = 1. / size_perc\n",
    "        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_ = []\n",
    "for i in range(100): \n",
    "    o = TSRandomSize(1)(xb, split_idx=0)\n",
    "    seq_len_.append(o.shape[-1])\n",
    "test_lt(min(seq_len_), xb.shape[-1])\n",
    "test_gt(max(seq_len_), xb.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomLargerSize(RandTransform):\n",
    "    \"Randomly resizes the sequence length of a time series\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1., ex=None, mode='linear', **kwargs):\n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        size_perc = 1 + random_half_normal() * self.magnitude\n",
    "        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "\n",
    "class TSRandomSmallerSize(RandTransform):\n",
    "    \"Randomly resizes the sequence length of a time series\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=1., ex=None, mode='linear', **kwargs):\n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)):\n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        size_perc = max(.5, 1 - random_half_normal() *  self.magnitude)\n",
    "        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_ = []\n",
    "for i in range(100): \n",
    "    o = TSRandomLargerSize()(xb, split_idx=0)\n",
    "    seq_len_.append(o.shape[-1])\n",
    "test_eq(min(seq_len_), xb.shape[-1])\n",
    "test_gt(max(seq_len_), xb.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomLowRes(RandTransform):\n",
    "    \"Randomly resizes the sequence length of a time series to a lower resolution\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=.5, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        size_perc = 1 - (np.random.rand() * (1 - self.magnitude))\n",
    "        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSDownUpScale(RandTransform):\n",
    "    \"Downscales a time series and upscales it again to previous sequence length\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=0.5, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o\n",
    "        output = F.interpolate(o, size=int((1 - self.magnitude) * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        output = F.interpolate(output, size=o.shape[-1], mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSDownUpScale()(xb, split_idx=0).shape, xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRandomDownUpScale(RandTransform):\n",
    "    \"Randomly downscales a time series and upscales it again to previous sequence length\"\n",
    "    order = 80\n",
    "    def __init__(self, magnitude=.5, ex=None, mode='linear', **kwargs): \n",
    "        \"mode:  'nearest' | 'linear' | 'area'\"\n",
    "        self.magnitude, self.ex, self.mode = magnitude, ex, mode\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o\n",
    "        scale_factor = 0.5 + 0.5 * np.random.rand() \n",
    "        output = F.interpolate(o, size=int(scale_factor * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        output = F.interpolate(output, size=o.shape[-1], mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)\n",
    "        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TSRandomDownUpScale()(xb, split_idx=0).shape, xb.shape)\n",
    "test_ne(TSDownUpScale()(xb, split_idx=0), xb)\n",
    "test_eq(TSDownUpScale()(xb, split_idx=1), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "all_TS_randaugs = [\n",
    "    \n",
    "    TSIdentity, \n",
    "    \n",
    "    # Noise\n",
    "    (TSMagAddNoise, 0.1, 1.),\n",
    "    (partial(TSMagMulNoise, ex=0), 0.1, 1),\n",
    "    (partial(TSTimeNoise, ex=0), 0.1, 1.),\n",
    "    (partial(TSRandomFreqNoise, ex=0), 0.1, 1.),\n",
    "    partial(TSShuffleSteps, ex=0),\n",
    "    (TSRandomTimeScale, 0.05, 0.5), \n",
    "    (TSRandomTimeStep, 0.05, 0.5), \n",
    "    (partial(TSFreqDenoise, ex=0), 0.1, 1.),\n",
    "    (TSRandomLowRes, 0.05, 0.5),\n",
    "    \n",
    "    # Magnitude\n",
    "    (partial(TSMagWarp, ex=0), 0.02, 0.2),\n",
    "    (TSMagScale, 0.2, 1.),\n",
    "    (partial(TSMagScalePerVar, ex=0), 0.2, 1.),\n",
    "    partial(TSBlur, ex=0),\n",
    "    partial(TSSmooth, ex=0),\n",
    "    partial(TSDownUpScale, ex=0),\n",
    "    partial(TSRandomDownUpScale, ex=0), \n",
    "    (TSRandomTrend, 0.1, 0.5), \n",
    "    TSVerticalFlip, \n",
    "    (TSVarOut, 0.05, 0.5), \n",
    "    (TSCutOut, 0.05, 0.5), \n",
    "    \n",
    "    # Time\n",
    "    (partial(TSTimeWarp, ex=0), 0.02, 0.2),\n",
    "    (TSWindowWarp, 0.05, 0.5),\n",
    "    (TSRandomSize, 0.05, 1.),\n",
    "    TSHorizontalFlip, \n",
    "    (TSTranslateX, 0.1, 0.5),\n",
    "    (TSRandomShift, 0.02, 0.2), \n",
    "    (TSRandomZoomIn, 0.05, 0.5), \n",
    "    (TSWindowSlicing, 0.05, 0.2),\n",
    "    (TSRandomZoomOut, 0.05, 0.5),\n",
    "    (TSRandomResizedLookBack, 0.1, 1.),\n",
    "    (TSTimeStepOut, 0.01, 0.2),\n",
    "    (TSRandomCropPad, 0.05, 0.5), \n",
    "    (TSRandomResizedCrop, 0.05, 0.5),\n",
    "    (TSMaskOut, 0.01, 0.2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandAugment(RandTransform):\n",
    "    order = 60\n",
    "    def __init__(self, tfms:list, N:int=1, M:int=3, **kwargs):\n",
    "        '''\n",
    "        tfms   : list of tfm functions (not called)\n",
    "        N      : number of tfms applied to each batch (usual values 1-3)\n",
    "        M      : tfm magnitude multiplier (1-10, usually 3-5). Only works if tfms are tuples (tfm, min, max)\n",
    "        kwargs : RandTransform kwargs\n",
    "        '''\n",
    "        super().__init__(**kwargs)\n",
    "        if not isinstance(tfms, list): tfms = [tfms]\n",
    "        self.tfms, self.N, self.magnitude = tfms, min(len(tfms), N), M / 10\n",
    "        self.n_tfms, self.tfms_idxs = len(tfms), np.arange(len(tfms))\n",
    "\n",
    "    def encodes(self, o:(NumpyTensor, TSTensor)):\n",
    "        if not self.N or not self.magnitude: return o\n",
    "        tfms = self.tfms if self.n_tfms==1 else L(self.tfms)[np.random.choice(np.arange(self.n_tfms), self.N, replace=False)]\n",
    "        tfms_ = []\n",
    "        for tfm in tfms:\n",
    "            if isinstance(tfm, tuple):\n",
    "                t, min_val, max_val = tfm\n",
    "                tfms_ += [t(magnitude=self.magnitude * float(max_val - min_val) + min_val)]\n",
    "            else:  tfms_ += [tfm()]\n",
    "        output = compose_tfms(o, tfms_, split_idx=self.split_idx)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ne(RandAugment(TSMagAddNoise, N=5, M=10)(xb, split_idx=0), xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TestTfm(RandTransform):\n",
    "    \"Utility class to test the output of selected tfms during training\"\n",
    "    def __init__(self, tfm, magnitude=1., ex=None, **kwargs): \n",
    "        self.tfm, self.magnitude, self.ex = tfm, magnitude, ex\n",
    "        self.tfmd, self.shape = [], []\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: (NumpyTensor, TSTensor)): \n",
    "        if not self.magnitude or self.magnitude <= 0: return o\n",
    "        output = self.tfm(o, split_idx=self.split_idx)\n",
    "        self.tfmd.append(torch.equal(o, output))\n",
    "        self.shape.append(o.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tfm_name(tfm): \n",
    "    if hasattr(tfm, \"func\"): tfm_name = tfm.func.__name__\n",
    "    elif isinstance(tfm, tuple): \n",
    "        if hasattr(tfm[0], \"func\"): tfm_name = tfm[0].func.__name__\n",
    "        else: tfm_name = tfm[0].__name__\n",
    "    elif hasattr(tfm, \"__name__\"): tfm_name = tfm.__name__\n",
    "    else: tfm_name = str(tfm)\n",
    "    return tfm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_TS_randaugs_names = [get_tfm_name(t) for t in all_TS_randaugs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.transforms.ipynb.\n",
      "Converted 003b_data.image.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_callback.ipynb.\n",
      "Converted 100_models.utils.ipynb.\n",
      "Converted 100b_models.layers.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.FCN.ipynb.\n",
      "Converted 103b_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 130_models.Hybrid.ipynb.\n",
      "Converted 200_trading.utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/tsai/tsai\n",
      "Correct conversion! 😃\n",
      "Total time elapsed 73 s\n",
      "Wednesday 11/11/20 11:20:17 CET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
