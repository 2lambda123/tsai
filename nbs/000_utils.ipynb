{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> Helper functions used throughout the library not related to timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def totensor(o):\n",
    "    if isinstance(o, torch.Tensor): return o\n",
    "    elif isinstance(o, np.ndarray):  return torch.from_numpy(o)\n",
    "    assert False, f\"Can't convert {type(o)} to torch.Tensor\"\n",
    "\n",
    "\n",
    "def toarray(o):\n",
    "    if isinstance(o, np.ndarray): return o\n",
    "    elif isinstance(o, torch.Tensor): return o.cpu().numpy()\n",
    "    assert False, f\"Can't convert {type(o)} to np.array\"\n",
    "\n",
    "\n",
    "def to3dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]#torch.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: return o[0,0]#torch.squeeze(o, 1)\n",
    "    if o.ndim == 2: return o[0]#torch.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to3darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return 0[0]#np.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: o = 0[0,0]#np.squeeze(o, 1)\n",
    "    elif o.ndim == 2: o = 0[0]#np.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "    \n",
    "    \n",
    "def to3d(o):\n",
    "    if o.ndim == 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2d(o):\n",
    "    if o.ndim == 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to1d(o):\n",
    "    if o.ndim == 1: return o\n",
    "    if isinstance(o, np.ndarray): return to1darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to1dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlus(o):\n",
    "    if o.ndim >= 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to3dPlus(o):\n",
    "    if o.ndim >= 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlusTensor(o):\n",
    "    return to2dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to2dPlusArray(o):\n",
    "    return to2dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def to3dPlusTensor(o):\n",
    "    return to3dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to3dPlusArray(o):\n",
    "    return to3dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def Todtype(dtype):\n",
    "    def _to_type(o, dtype=dtype):\n",
    "        if o.dtype == dtype: return o\n",
    "        elif isinstance(o, torch.Tensor): o = o.to(dtype=dtype)\n",
    "        elif isinstance(o, np.ndarray): o = o.astype(dtype)\n",
    "        return o\n",
    "    return _to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100).astype(np.float32)\n",
    "b = torch.from_numpy(a).float()\n",
    "test_eq(totensor(a), b)\n",
    "test_eq(a, toarray(b))\n",
    "test_eq(to3dtensor(a).ndim, 3)\n",
    "test_eq(to2dtensor(a).ndim, 2)\n",
    "test_eq(to1dtensor(a).ndim, 1)\n",
    "test_eq(to3darray(b).ndim, 3)\n",
    "test_eq(to2darray(b).ndim, 2)\n",
    "test_eq(to1darray(b).ndim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bytes2size(size_bytes):\n",
    "    if size_bytes == 0: return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def bytes2GB(byts):\n",
    "    return round(byts / math.pow(1024, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delete_all_in_dir(tgt_dir, exception=None):\n",
    "    if exception is not None and len(L(exception)) > 1: exception = tuple(exception)\n",
    "    for file in os.listdir(tgt_dir):\n",
    "        if exception is not None and file.endswith(exception): continue\n",
    "        file_path = os.path.join(tgt_dir, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path): os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path): shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dictionary): \n",
    "    return {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_tuple(o): return isinstance(o, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def itemify(*o, tup_id=None): \n",
    "    items = L(*o).zip()\n",
    "    if tup_id is not None: return L([item[tup_id] for item in items])\n",
    "    else: return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_none(o):\n",
    "    return o in [[], [None], None]\n",
    "\n",
    "def ifisnone(a, b):\n",
    "    \"`a` if `a` is None else `b`\"\n",
    "    return None if is_none(a) else b\n",
    "\n",
    "def ifnoneelse(a, b, c=None):\n",
    "    \"`b` if `a` is None else `c`\"\n",
    "    return b if a is None else ifnone(c, a)\n",
    "\n",
    "def ifisnoneelse(a, b, c=None):\n",
    "    \"`b` if `a` is None else `c`\"\n",
    "    return b if is_none(a) else ifnone(c, a)\n",
    "\n",
    "def ifelse(a, b, c):\n",
    "    \"`b` if `a` is True else `c`\"\n",
    "    return b if a else c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(ifisnone(None, 2), None)\n",
    "test_eq(ifisnone([], 2), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(ifnoneelse(None, 1, 2), 1)\n",
    "test_eq(ifnoneelse(1, 2, 3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_not_close(a,b,eps=1e-5):\n",
    "    \"Is `a` within `eps` of `b`\"\n",
    "    if hasattr(a, '__array__') or hasattr(b,'__array__'):\n",
    "        return (abs(a-b)>eps).all()\n",
    "    if isinstance(a, (Iterable,Generator)) or isinstance(b, (Iterable,Generator)):\n",
    "        return is_not_close(np.array(a), np.array(b), eps=eps)\n",
    "    return abs(a-b)>eps\n",
    "\n",
    "# Cell\n",
    "def test_not_close(a,b,eps=1e-5):\n",
    "    \"`test` that `a` is within `eps` of `b`\"\n",
    "    test(a,b,partial(is_not_close,eps=eps),'not_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack(o, axis=0):\n",
    "    if isinstance(o[0], torch.Tensor): return torch.stack(tuple(o), dim=axis)\n",
    "    else: return np.stack(o, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "a = np.random.rand(2, 3, 4)\n",
    "t = torch.from_numpy(a)\n",
    "test_eq_type(stack(itemify(a, tup_id=0)), a)\n",
    "test_eq_type(stack(itemify(t, tup_id=0)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cat2int(o):\n",
    "    cat = Categorize()\n",
    "    cat.setup(o)\n",
    "    return stack(TfmdLists(o, cat)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(['b', 'a', 'a', 'b', 'a', 'b', 'a'])\n",
    "test_eq_type(cat2int(a), tensor([1, 0, 0, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cycle_dl(dl): \n",
    "    for _ in dl: _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def memmap2cache(o, bs=64, verbose=True):\n",
    "    print('Writing to buffer cache...\\n')\n",
    "    start = partial = time.time()\n",
    "    n_batches = len(o) // bs\n",
    "    for i in range(n_batches): \n",
    "        np.array(o[slice(bs*i, bs*(1+i))]) \n",
    "        if verbose and i > 0 and i%10==0: \n",
    "            print(f'{i:4} {1000*(time.time() - partial)/10:5.0f} ms')\n",
    "            partial = time.time()\n",
    "    print('\\n...complete')\n",
    "    print(f'\\nTotal time : {1000*(time.time() - start):.1f} ms ({1000 * (time.time() - start)/n_batches:.1f} ms / batch)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
