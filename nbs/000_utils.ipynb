{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> Helper functions used throughout the library not related to timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python         : 3.7.6\n",
      "tsai           : 0.2.9\n",
      "fastai         : 2.1.6\n",
      "fastcore       : 1.3.5\n",
      "torch          : 1.7.0\n",
      "scipy          : 1.5.2\n",
      "numpy          : 1.19.1\n",
      "pandas         : 1.1.3\n",
      "matplotlib     : 3.3.2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import tsai\n",
    "a = !python  -V\n",
    "p = a[0].split(' ')\n",
    "print(f'python         : {p[1]}')\n",
    "print('tsai           :', tsai.__version__)\n",
    "print('fastai         :', fastai.__version__)\n",
    "print('fastcore       :', fastcore.__version__)\n",
    "print('torch          :', torch.__version__)\n",
    "print('scipy          :', sp.__version__)\n",
    "print('numpy          :', np.__version__)\n",
    "print('pandas         :', pd.__version__)\n",
    "print('matplotlib     :', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def totensor(o):\n",
    "    if isinstance(o, torch.Tensor): return o\n",
    "    elif isinstance(o, np.ndarray):  return torch.from_numpy(o)\n",
    "    elif isinstance(o, (list, L)): return torch.tensor(o)\n",
    "    assert False, f\"Can't convert {type(o)} to torch.Tensor\"\n",
    "\n",
    "\n",
    "def toarray(o):\n",
    "    if isinstance(o, np.ndarray): return o\n",
    "    elif isinstance(o, torch.Tensor): return o.cpu().numpy()\n",
    "    elif isinstance(o, (list, L)): return np.array(o)\n",
    "    assert False, f\"Can't convert {type(o)} to np.array\"\n",
    "    \n",
    "    \n",
    "def toL(o):\n",
    "    if isinstance(o, L): return o\n",
    "    elif isinstance(o, list): return L(o)\n",
    "    elif isinstance(o, (np.ndarray, torch.Tensor)): return L(o.tolist())\n",
    "    assert False, f'passed object needs to be of type L, list, np.ndarray or torch.Tensor but is {type(o)}'\n",
    "\n",
    "\n",
    "def to3dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: return o[0,0]\n",
    "    if o.ndim == 2: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to3darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: o = o[0,0]\n",
    "    elif o.ndim == 2: o = o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "    \n",
    "    \n",
    "def to3d(o):\n",
    "    if o.ndim == 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2d(o):\n",
    "    if o.ndim == 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to1d(o):\n",
    "    if o.ndim == 1: return o\n",
    "    if isinstance(o, np.ndarray): return to1darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to1dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlus(o):\n",
    "    if o.ndim >= 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to3dPlus(o):\n",
    "    if o.ndim >= 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlusTensor(o):\n",
    "    return to2dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to2dPlusArray(o):\n",
    "    return to2dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def to3dPlusTensor(o):\n",
    "    return to3dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to3dPlusArray(o):\n",
    "    return to3dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def todtype(dtype):\n",
    "    def _to_type(o, dtype=dtype):\n",
    "        if o.dtype == dtype: return o\n",
    "        elif isinstance(o, torch.Tensor): o = o.to(dtype=dtype)\n",
    "        elif isinstance(o, np.ndarray): o = o.astype(dtype)\n",
    "        return o\n",
    "    return _to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100).astype(np.float32)\n",
    "b = torch.from_numpy(a).float()\n",
    "test_eq(totensor(a), b)\n",
    "test_eq(a, toarray(b))\n",
    "test_eq(to3dtensor(a).ndim, 3)\n",
    "test_eq(to2dtensor(a).ndim, 2)\n",
    "test_eq(to1dtensor(a).ndim, 1)\n",
    "test_eq(to3darray(b).ndim, 3)\n",
    "test_eq(to2darray(b).ndim, 2)\n",
    "test_eq(to1darray(b).ndim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bytes2size(size_bytes):\n",
    "    if size_bytes == 0: return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def bytes2GB(byts):\n",
    "    return round(byts / math.pow(1024, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delete_all_in_dir(tgt_dir, exception=None):\n",
    "    if exception is not None and len(L(exception)) > 1: exception = tuple(exception)\n",
    "    for file in os.listdir(tgt_dir):\n",
    "        if exception is not None and file.endswith(exception): continue\n",
    "        file_path = os.path.join(tgt_dir, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path): os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path): shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dictionary): \n",
    "    return {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_tuple(o): return isinstance(o, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def itemify(*o, tup_id=None): \n",
    "    o = [o_ for o_ in L(*o) if o_ is not None]\n",
    "    items = L(o).zip()\n",
    "    if tup_id is not None: return L([item[tup_id] for item in items])\n",
    "    else: return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 5), (3, 6)]\n",
      "[(1,), (2,), (3,)]\n",
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "print(itemify(a, b))\n",
    "test_eq(len(itemify(a, b)), len(a))\n",
    "a = [1, 2, 3]\n",
    "b = None\n",
    "print(itemify(a, b))\n",
    "test_eq(len(itemify(a, b)), len(a))\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = None\n",
    "print(itemify(a, b, c))\n",
    "test_eq(len(itemify(a, b, c)), len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isnone(o):\n",
    "    return o is None\n",
    "\n",
    "def exists(o): return o is not None\n",
    "\n",
    "def ifelse(a, b, c):\n",
    "    \"`b` if `a` is True else `c`\"\n",
    "    return b if a else c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(3)\n",
    "test_eq(isnone(a), False)\n",
    "test_eq(exists(a), True)\n",
    "b = None\n",
    "test_eq(isnone(b), True)\n",
    "test_eq(exists(b), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_not_close(a, b, eps=1e-5):\n",
    "    \"Is `a` within `eps` of `b`\"\n",
    "    if hasattr(a, '__array__') or hasattr(b, '__array__'):\n",
    "        return (abs(a - b) > eps).all()\n",
    "    if isinstance(a, (Iterable, Generator)) or isinstance(b, (Iterable, Generator)):\n",
    "        return is_not_close(np.array(a), np.array(b), eps=eps)\n",
    "    return abs(a - b) > eps\n",
    "\n",
    "\n",
    "def test_not_close(a, b, eps=1e-5):\n",
    "    \"`test` that `a` is within `eps` of `b`\"\n",
    "    test(a, b, partial(is_not_close, eps=eps), 'not_close')\n",
    "\n",
    "\n",
    "def test_type(a, b):\n",
    "    return test_eq(type(a), type(b))\n",
    "\n",
    "\n",
    "def test_ok(f, *args, **kwargs):\n",
    "    try: \n",
    "        f(*args, **kwargs)\n",
    "        e = 0\n",
    "    except: \n",
    "        e = 1\n",
    "        pass\n",
    "    test_eq(e, 0)\n",
    "    \n",
    "def test_not_ok(f, *args, **kwargs):\n",
    "    try: \n",
    "        f(*args, **kwargs)\n",
    "        e = 0\n",
    "    except: \n",
    "        e = 1\n",
    "        pass\n",
    "    test_eq(e, 1)\n",
    "    \n",
    "def test_error(error, f, *args, **kwargs):\n",
    "    try: f(*args, **kwargs)\n",
    "    except Exception as e: \n",
    "        test_eq(str(e), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assert_fn(*args, **kwargs): assert False, 'assertion test'\n",
    "test_error('assertion test', assert_fn, 35, a=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_gt(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,gt,'>')\n",
    "\n",
    "def test_ge(a,b):\n",
    "    \"`test` that `a>=b`\"\n",
    "    test(a,b,ge,'>')\n",
    "    \n",
    "def test_lt(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,lt,'<')\n",
    "\n",
    "def test_le(a,b):\n",
    "    \"`test` that `a>b`\"\n",
    "    test(a,b,le,'<=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ok(test_gt, 5, 4)\n",
    "test_not_ok(test_gt, 4, 4)\n",
    "test_ok(test_ge, 4, 4)\n",
    "test_not_ok(test_ge, 3, 4)\n",
    "\n",
    "test_ok(test_lt, 3, 4)\n",
    "test_not_ok(test_lt, 4, 4)\n",
    "test_ok(test_le, 4, 4)\n",
    "test_not_ok(test_le, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack(o, axis=0, retain=True):\n",
    "    if isinstance(o[0], torch.Tensor): \n",
    "        return retain_type(torch.stack(tuple(o), dim=axis),  o[0]) if retain else torch.stack(tuple(o), dim=axis)\n",
    "    else: \n",
    "        return retain_type(np.stack(o, axis), o[0]) if retain else np.stack(o, axis)\n",
    "    \n",
    "def stack_pad(l):\n",
    "    def resize(row, size):\n",
    "        new = np.array(row)\n",
    "        new.resize(size)\n",
    "        return new\n",
    "    row_length = max(l, key=len).__len__()\n",
    "    mat = np.array([resize(row, row_length) for row in l])\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[0,1,2], [4,5,6,7]]\n",
    "test_eq(stack_pad(a).shape, (2, 4))\n",
    "test_eq(type(stack_pad(a)), np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2, 3, 4)\n",
    "t = torch.from_numpy(a)\n",
    "test_eq_type(stack(itemify(a, tup_id=0)), a)\n",
    "test_eq_type(stack(itemify(t, tup_id=0)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_shuffle(o, random_state=None):\n",
    "    res = sklearn.utils.shuffle(o, random_state=random_state)\n",
    "    if isinstance(o, L): return L(list(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "test_eq_type(random_shuffle(a, 1), np.array([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))\n",
    "t = torch.arange(10)\n",
    "test_eq_type(random_shuffle(t, 1), tensor([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))\n",
    "l = list(a)\n",
    "test_eq(random_shuffle(l, 1), [2, 9, 6, 4, 0, 3, 1, 7, 8, 5])\n",
    "l2 = L(l)\n",
    "test_eq_type(random_shuffle(l2, 1), L([2, 9, 6, 4, 0, 3, 1, 7, 8, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cat2int(o):\n",
    "    cat = Categorize()\n",
    "    cat.setup(o)\n",
    "    return stack(TfmdLists(o, cat)[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(['b', 'a', 'a', 'b', 'a', 'b', 'a'])\n",
    "test_eq_type(cat2int(a), TensorCategory([1, 0, 0, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase([1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBase([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cycle_dl(dl): \n",
    "    for _ in dl: _\n",
    "        \n",
    "def cycle_dl_to_device(dl):\n",
    "    for bs in dl: [b.to(default_device()) for b in bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cache_memmap(o, slice_len=1000, verbose=False):\n",
    "    start = 0\n",
    "    slice_len = 1000\n",
    "    for i in range(len(o) // 1000 + 1): \n",
    "        o[start:start + slice_len]\n",
    "        start += slice_len\n",
    "        if verbose and i % 10 == 0: print(i)\n",
    "    \n",
    "memmap2cache =  cache_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func_defaults(f): \n",
    "    fa = inspect.getfullargspec(f)\n",
    "    if fa.defaults is None: return dict(zip(fa.args, [''] * (len(fa.args))))\n",
    "    else: return dict(zip(fa.args, [''] * (len(fa.args) - len(fa.defaults)) + list(fa.defaults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idx_from_df_col_vals(df, col, val_list):\n",
    "    return [df[df[col] == val].index[0] for val in val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sublist_idxs(aList, bList):\n",
    "    \"Get idxs that when applied to aList will return bList. aList must contain all values in bList\"\n",
    "    sorted_aList = aList[np.argsort(aList)]\n",
    "    return np.argsort(aList)[np.searchsorted(sorted_aList, bList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3, 5, 7, 1, 9, 8, 6, 2])\n",
    "y = np.array([6, 1, 5, 7])\n",
    "idx = get_sublist_idxs(x, y)\n",
    "test_eq(x[idx], y)\n",
    "x = np.array([3, 5, 7, 1, 9, 8, 6, 6, 2])\n",
    "y = np.array([6, 1, 5, 7, 5])\n",
    "idx = get_sublist_idxs(x, y)\n",
    "test_eq(x[idx], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def display_pd_df(df, max_rows:Union[bool, int]=False, max_columns:Union[bool, int]=False):\n",
    "    if max_rows:\n",
    "        old_max_rows = pd.get_option('display.max_rows')\n",
    "        if max_rows is not True and isinstance(max_rows, Integral): pd.set_option('display.max_rows', max_rows)\n",
    "        else: pd.set_option('display.max_rows', df.shape[0])\n",
    "    if max_columns:\n",
    "        old_max_columns = pd.get_option('display.max_columns')\n",
    "        if max_columns is not True and isinstance(max_columns, Integral): pd.set_option('display.max_columns', max_columns)\n",
    "        else: pd.set_option('display.max_columns', df.shape[1])\n",
    "    display(df)\n",
    "    if max_rows: pd.set_option('display.max_rows', old_max_rows)\n",
    "    if max_columns: pd.set_option('display.max_columns', old_max_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.954647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   ...        24\n",
       "0   0.794083  ...  0.325186\n",
       "..       ...  ...       ...\n",
       "69  0.954647  ...  0.344995\n",
       "\n",
       "[70 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "old_max_rows, old_max_columns = pd.get_option('display.max_rows'), pd.get_option('display.max_columns')\n",
    "df = pd.DataFrame(np.random.rand(70, 25))\n",
    "display_pd_df(df, max_rows=2, max_columns=3)\n",
    "test_eq(old_max_rows, pd.get_option('display.max_rows'))\n",
    "test_eq(old_max_columns, pd.get_option('display.max_columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ttest(data1, data2, equal_var=False):\n",
    "    \"Calculates t-statistic and p-value based on 2 sample distributions\"\n",
    "    t_stat, p_value = scipy.stats.ttest_ind(data1, data2, equal_var=equal_var)\n",
    "    return t_stat, np.sign(t_stat) * p_value\n",
    "\n",
    "def tscore(o): \n",
    "    if o.std() == 0: return 0\n",
    "    else: return np.sqrt(len(o)) * o.mean() / o.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2.0233289155386274, 0.04489771418011204)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.normal(0.5, 1, 100)\n",
    "b = np.random.normal(0.15, .5, 50)\n",
    "plt.hist(a, 50)\n",
    "plt.hist(b, 50)\n",
    "plt.show()\n",
    "ttest(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.572307611625291, tensor(6.5608))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.normal(0.5, 1, 100)\n",
    "t = torch.normal(0.5, 1, (100, ))\n",
    "tscore(a), tscore(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ttest_tensor(a, b):\n",
    "    \"differentiable pytorch function equivalent to scipy.stats.ttest_ind with equal_var=False\"\n",
    "    # calculate standard errors\n",
    "    se1, se2 = torch.std(a)/np.sqrt(len(a)), torch.std(b)/np.sqrt(len(b))\n",
    "    # standard error on the difference between the samples\n",
    "    sed = torch.sqrt(se1**2.0 + se2**2.0)\n",
    "    # calculate the t statistic\n",
    "    t_stat = (torch.mean(a) - torch.mean(b)) / sed\n",
    "    return t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2091, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(100).requires_grad_(True) + .1\n",
    "b = torch.rand(100).requires_grad_(True)\n",
    "ttest_tensor(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19677707356866858, 0.21118511851185118)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#export\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def pcc(a, b):\n",
    "    return pearsonr(a, b)[0]\n",
    "\n",
    "def scc(a, b):\n",
    "    return spearmanr(a, b)[0]\n",
    "\n",
    "a = np.random.normal(0.5, 1, 100)\n",
    "b = np.random.normal(0.15, .5, 100)\n",
    "pcc(a, b), scc(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_fn(fn, verbose=False):\n",
    "    \"Removes a file (fn) if exists\"\n",
    "    try: \n",
    "        os.remove(fn)\n",
    "        pv(f'{fn} file removed', verbose)\n",
    "    except OSError: \n",
    "        pv(f'{fn} does not exist', verbose)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/remove_fn_test.npy file removed\n",
      "data/remove_fn_test.npy does not exist\n"
     ]
    }
   ],
   "source": [
    "fn = 'data/remove_fn_test.npy'\n",
    "a = np.zeros(1)\n",
    "np.save(fn, a)\n",
    "remove_fn(fn, True)\n",
    "remove_fn(fn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def npsave(array_fn, array, verbose=True):\n",
    "    remove_fn(array_fn, verbose)\n",
    "    pv(f'saving {array_fn}...', verbose)\n",
    "    np.save(array_fn, array)\n",
    "    pv(f'...{array_fn} saved', verbose)\n",
    "    \n",
    "np_save = npsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/remove_fn_test.npy does not exist\n",
      "saving data/remove_fn_test.npy...\n",
      "...data/remove_fn_test.npy saved\n",
      "data/remove_fn_test.npy file removed\n",
      "data/remove_fn_test.npy does not exist\n"
     ]
    }
   ],
   "source": [
    "fn = 'data/remove_fn_test.npy'\n",
    "a = np.zeros(1)\n",
    "npsave(fn, a)\n",
    "del a\n",
    "np.load(fn, mmap_mode='r+')\n",
    "remove_fn(fn, True)\n",
    "remove_fn(fn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def permute_2D(array, axis=None):\n",
    "    \"Permute rows or columns in an array. This can be used, for example, in feature permutation\"\n",
    "    if axis == 0: return array[np.random.randn(*array.shape).argsort(axis=0), np.arange(array.shape[-1])[None, :]] \n",
    "    elif axis == 1 or axis == -1: return array[np.arange(len(array))[:,None], np.random.randn(*array.shape).argsort(axis=1)] \n",
    "    return array[np.random.randn(*array.shape).argsort(axis=0), np.random.randn(*array.shape).argsort(axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(100 * 50).reshape(100, 50) \n",
    "test_eq(permute_2D(s, axis=0).mean(0), s.mean(0))\n",
    "test_ne(permute_2D(s, axis=0), s)\n",
    "test_eq(permute_2D(s, axis=1).mean(1), s.mean(1))\n",
    "test_ne(permute_2D(s, axis=1), s)\n",
    "test_ne(permute_2D(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_normal():\n",
    "    \"Returns a number between -1 and 1 with a normal distribution\"\n",
    "    while True:\n",
    "        o = np.random.normal(loc=0., scale=1/3)\n",
    "        if abs(o) <= 1: break\n",
    "    return o\n",
    "\n",
    "def random_half_normal():\n",
    "    \"Returns a number between 0 and 1 with a half-normal distribution\"\n",
    "    while True:\n",
    "        o = abs(np.random.normal(loc=0., scale=1/3))\n",
    "        if o <= 1: break\n",
    "    return o\n",
    "\n",
    "def random_normal_tensor(shape=1, device=None):\n",
    "    \"Returns a tensor of a predefined shape between -1 and 1 with a normal distribution\"\n",
    "    return torch.empty(shape, device=device).normal_(mean=0, std=1/3).clamp_(-1, 1)\n",
    "\n",
    "def random_half_normal_tensor(shape=1, device=None):\n",
    "    \"Returns a tensor of a predefined shape between 0 and 1 with a half-normal distribution\"\n",
    "    return abs(torch.empty(shape, device=device).normal_(mean=0, std=1/3)).clamp_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clip_outliers(o):\n",
    "    Q1, Q3 = np.percentile(o, [25, 75])\n",
    "    IQR = Q3 - Q1\n",
    "    if isinstance(o, (np.ndarray, pd.core.series.Series)):\n",
    "        return np.clip(o, Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "    elif isinstance(o, torch.Tensor):\n",
    "        return torch.clamp(o, Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "\n",
    "def default_dpi():\n",
    "    DPI = plt.gcf().get_dpi()\n",
    "    plt.close()\n",
    "    return int(DPI)\n",
    "\n",
    "def get_plot_fig(size=None, dpi=default_dpi()):\n",
    "    fig = plt.figure(figsize=(size / dpi, size / dpi), dpi=dpi, frameon=False) if size else plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    config = plt.gcf()\n",
    "    plt.close('all')\n",
    "    return config\n",
    "\n",
    "def fig2buf(fig):\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    fig.canvas.draw()\n",
    "    return np.asarray(canvas.buffer_rgba())[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_dpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_scatter(x, y, deg=1):\n",
    "    linreg = sp.stats.linregress(x, y)\n",
    "    plt.scatter(x, y, label=f'R2:{linreg.rvalue:.2f}', color='lime', edgecolor='black', alpha=.5)\n",
    "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, deg))(np.unique(x)), color='r')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand(100)\n",
    "b = np.random.rand(100)**2\n",
    "plot_scatter(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import seaborn as sns\n",
    "def jointplot_scatter(x,y,**kwargs):\n",
    "    sns.jointplot(x, y, kind='scatter', **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "def jointplot_kde(x,y,**kwargs):\n",
    "    sns.jointplot(x, y, kind='kde', **kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idxs(o, aList): return array([o.tolist().index(v) for v in aList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random_shuffle(np.arange(100, 200))\n",
    "b = np.random.choice(a, 10, False)\n",
    "idxs = get_idxs(a, b)\n",
    "test_eq(a[idxs], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def apply_cmap(o, cmap):\n",
    "    o = toarray(o)\n",
    "    out = plt.get_cmap(cmap)(o)[..., :3]\n",
    "    out = tensor(out).squeeze(1)\n",
    "    return out.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(16, 1, 40, 50)\n",
    "s = L(a.shape)\n",
    "s[1] = 3\n",
    "test_eq(L(apply_cmap(a, 'viridis').shape), s)\n",
    "\n",
    "s[0] = 1\n",
    "a = np.random.rand(1, 40, 50)\n",
    "test_eq(L(apply_cmap(a, 'viridis').shape), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def torch_tile(a, n_tile, dim=0):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.cat([init_dim * torch.arange(n_tile) + i for i in range(init_dim)]).to(device=a.device)\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(torch_tile(torch.arange(2), 3), tensor([0, 0, 0, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_tsfresh_df(ts):\n",
    "    r\"\"\"Prepares a time series (Tensor/ np.ndarray) to be used as a tsfresh dataset to allow feature extraction\"\"\"\n",
    "    ts = to3d(ts)\n",
    "    if isinstance(ts, np.ndarray):\n",
    "        ids = np.repeat(np.arange(len(ts)), ts.shape[-1]).reshape(-1,1)\n",
    "        joint_ts =  ts.transpose(0,2,1).reshape(-1, ts.shape[1])\n",
    "        cols = ['id'] + np.arange(ts.shape[1]).tolist()\n",
    "        df = pd.DataFrame(np.concatenate([ids, joint_ts], axis=1), columns=cols)\n",
    "    elif isinstance(ts, torch.Tensor):\n",
    "        ids = torch_tile(torch.arange(len(ts)), ts.shape[-1]).reshape(-1,1)\n",
    "        joint_ts =  ts.transpose(1,2).reshape(-1, ts.shape[1])\n",
    "        cols = ['id']+np.arange(ts.shape[1]).tolist()\n",
    "        df = pd.DataFrame(torch.cat([ids, joint_ts], dim=1).numpy(), columns=cols)\n",
    "    df['id'] = df['id'].astype(int)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.rand(16, 3, 20)\n",
    "a = to_tsfresh_df(ts)\n",
    "ts = ts.numpy()\n",
    "b = to_tsfresh_df(ts)\n",
    "test_eq(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def pcorr(a, b): \n",
    "    return scipy.stats.pearsonr(a, b)\n",
    "\n",
    "def scorr(a, b): \n",
    "    corr = scipy.stats.spearmanr(a, b)\n",
    "    return corr[0], corr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def torch_diff(t, lag=1, pad=True):\n",
    "    import torch.nn.functional as F\n",
    "    diff = t[..., lag:] - t[..., :-lag]\n",
    "    if pad: return F.pad(diff, (lag,0))\n",
    "    else: return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(24).reshape(2,3,4)\n",
    "test_eq(torch_diff(t, 1)[..., 1:].float().mean(), 1.)\n",
    "test_eq(torch_diff(t, 2)[..., 2:].float().mean(), 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_outliers_IQR(o, axis=None):\n",
    "    if isinstance(o, torch.Tensor): o = o.detach().cpu().numpy()\n",
    "    Q1 = np.percentile(o, 25, axis=axis, keepdims=axis is not None)\n",
    "    Q3 = np.percentile(o, 75, axis=axis, keepdims=axis is not None)\n",
    "    IQR = Q3 - Q1\n",
    "    max, min = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    return Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "\n",
    "def get_percentile(o, percentile, axis=None):\n",
    "    if isinstance(o, torch.Tensor): o = o.detach().cpu().numpy()\n",
    "    return np.percentile(o, percentile, axis=axis, keepdims=axis is not None)\n",
    "\n",
    "def torch_clamp(o, min=None, max=None):\n",
    "    r\"\"\"Clamp torch.Tensor using 1 or multiple dimensions\"\"\"\n",
    "    if min is not None: o = torch.max(o, min)\n",
    "    if max is not None: o = torch.min(o, max)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def torch_slice_by_dim(t, index, dim=-1, **kwargs):\n",
    "    if not isinstance(index, torch.Tensor): index = torch.Tensor(index)\n",
    "    assert t.ndim == index.ndim, \"t and index must have the same ndim\"\n",
    "    index = index.long()\n",
    "    return torch.gather(t, dim, index, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7327],\n",
       "        [0.4772],\n",
       "        [0.3080],\n",
       "        [0.0434],\n",
       "        [0.8216]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(5, 3)\n",
    "index = torch.randint(0, 3, (5, 1))\n",
    "# index = [[0, 2], [0, 1], [1, 2], [0, 2], [0, 1]]\n",
    "torch_slice_by_dim(t, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def concat(*ls, dim=0):\n",
    "    \"Concatenate tensors, arrays, lists, or tuples by a dimension\"\n",
    "    if not len(ls): return []\n",
    "    it = ls[0]\n",
    "    if isinstance(it, torch.Tensor): return torch.cat(ls, dim=dim)\n",
    "    elif isinstance(it, np.ndarray): return np.concatenate(ls, axis=dim)\n",
    "    else:\n",
    "        res = np.concatenate(ls, axis=dim).tolist()\n",
    "        return retain_type(res, typ=type(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cls_name(o): return o.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(cls_name(timer), 'Timer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
