{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> Helper functions used throughout the library not related to timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ToTensor(o):\n",
    "    if isinstance(o, torch.Tensor): return o\n",
    "    elif isinstance(o, np.ndarray):  return torch.from_numpy(o)\n",
    "    assert False, f\"Can't convert {type(o)} to torch.Tensor\"\n",
    "\n",
    "\n",
    "def ToArray(o):\n",
    "    if isinstance(o, np.ndarray): return o\n",
    "    elif isinstance(o, torch.Tensor): return o.cpu().numpy()\n",
    "    assert False, f\"Can't convert {type(o)} to np.array\"\n",
    "\n",
    "\n",
    "def To3DTensor(o):\n",
    "    o = ToTensor(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def To2DTensor(o):\n",
    "    o = ToTensor(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]#torch.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def To1DTensor(o):\n",
    "    o = ToTensor(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: return o[0,0]#torch.squeeze(o, 1)\n",
    "    if o.ndim == 2: return o[0]#torch.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def To3DArray(o):\n",
    "    o = ToArray(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def To2DArray(o):\n",
    "    o = ToArray(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return 0[0]#np.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def To1DArray(o):\n",
    "    o = ToArray(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: o = 0[0,0]#np.squeeze(o, 1)\n",
    "    elif o.ndim == 2: o = 0[0]#np.squeeze(o, 0)\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "    \n",
    "    \n",
    "def To3D(o):\n",
    "    if o.ndim == 3: return o\n",
    "    if isinstance(o, np.ndarray): return To3DArray(o)\n",
    "    if isinstance(o, torch.Tensor): return To3DTensor(o)\n",
    "    \n",
    "    \n",
    "def To2D(o):\n",
    "    if o.ndim == 2: return o\n",
    "    if isinstance(o, np.ndarray): return To2DArray(o)\n",
    "    if isinstance(o, torch.Tensor): return To2DTensor(o)\n",
    "    \n",
    "    \n",
    "def To1D(o):\n",
    "    if o.ndim == 1: return o\n",
    "    if isinstance(o, np.ndarray): return To1DArray(o)\n",
    "    if isinstance(o, torch.Tensor): return To1DTensor(o)\n",
    "    \n",
    "    \n",
    "def To2DPlus(o):\n",
    "    if o.ndim >= 2: return o\n",
    "    if isinstance(o, np.ndarray): return To2DArray(o)\n",
    "    elif isinstance(o, torch.Tensor): return To2DTensor(o)\n",
    "    \n",
    "    \n",
    "def To3DPlus(o):\n",
    "    if o.ndim >= 3: return o\n",
    "    if isinstance(o, np.ndarray): return To3DArray(o)\n",
    "    elif isinstance(o, torch.Tensor): return To3DTensor(o)\n",
    "    \n",
    "    \n",
    "def To2DPlusTensor(o):\n",
    "    return To2DPlus(ToTensor(o))\n",
    "\n",
    "\n",
    "def To2DPlusArray(o):\n",
    "    return To2DPlus(ToArray(o))\n",
    "\n",
    "\n",
    "def To3DPlusTensor(o):\n",
    "    return To3DPlus(ToTensor(o))\n",
    "\n",
    "\n",
    "def To3DPlusArray(o):\n",
    "    return To3DPlus(ToArray(o))\n",
    "\n",
    "\n",
    "def Todtype(dtype):\n",
    "    def _to_type(o, dtype=dtype):\n",
    "        if o.dtype == dtype: return o\n",
    "        elif isinstance(o, torch.Tensor): o = o.to(dtype=dtype)\n",
    "        elif isinstance(o, np.ndarray): o = o.astype(dtype)\n",
    "        return o\n",
    "    return _to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100).astype(np.float32)\n",
    "b = torch.from_numpy(a).float()\n",
    "test_eq(ToTensor(a), b)\n",
    "test_eq(a, ToArray(b))\n",
    "test_eq(To3DTensor(a).ndim, 3)\n",
    "test_eq(To2DTensor(a).ndim, 2)\n",
    "test_eq(To1DTensor(a).ndim, 1)\n",
    "test_eq(To3DArray(b).ndim, 3)\n",
    "test_eq(To2DArray(b).ndim, 2)\n",
    "test_eq(To1DArray(b).ndim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bytes2size(size_bytes):\n",
    "    if size_bytes == 0: return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def bytes2GB(byts):\n",
    "    return round(byts / math.pow(1024, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delete_all_in_dir(tgt_dir, exception=None):\n",
    "    if exception is not None and len(L(exception)) > 1: exception = tuple(exception)\n",
    "    for file in os.listdir(tgt_dir):\n",
    "        if exception is not None and file.endswith(exception): continue\n",
    "        file_path = os.path.join(tgt_dir, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path): os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path): shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dictionary): \n",
    "    return {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_tuple(o): return isinstance(o, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def itemify(*o, tup_id=None): \n",
    "    items = L(*o).zip()\n",
    "    if tup_id is not None: return L([item[tup_id] for item in items])\n",
    "    else: return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_none(o):\n",
    "    return o in [[], [None], None]\n",
    "\n",
    "def ifisnone(a, b):\n",
    "    \"`a` if `a` is None else `b`\"\n",
    "    return None if is_none(a) else b\n",
    "\n",
    "def ifnoneelse(a, b, c=None):\n",
    "    \"`b` if `a` is None else `c`\"\n",
    "    return b if a is None else ifnone(c, a)\n",
    "\n",
    "def ifisnoneelse(a, b, c=None):\n",
    "    \"`b` if `a` is None else `c`\"\n",
    "    return b if is_none(a) else ifnone(c, a)\n",
    "\n",
    "def ifelse(a, b, c):\n",
    "    \"`b` if `a` is True else `c`\"\n",
    "    return b if a else c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(ifisnone(None, 2), None)\n",
    "test_eq(ifisnone([], 2), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(ifnoneelse(None, 1, 2), 1)\n",
    "test_eq(ifnoneelse(1, 2, 3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_not_close(a,b,eps=1e-5):\n",
    "    \"Is `a` within `eps` of `b`\"\n",
    "    if hasattr(a, '__array__') or hasattr(b,'__array__'):\n",
    "        return (abs(a-b)>eps).all()\n",
    "    if isinstance(a, (Iterable,Generator)) or isinstance(b, (Iterable,Generator)):\n",
    "        return is_not_close(np.array(a), np.array(b), eps=eps)\n",
    "    return abs(a-b)>eps\n",
    "\n",
    "# Cell\n",
    "def test_not_close(a,b,eps=1e-5):\n",
    "    \"`test` that `a` is within `eps` of `b`\"\n",
    "    test(a,b,partial(is_not_close,eps=eps),'not_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def mul_min(x:torch.Tensor, axes=None, keepdim=False):\n",
    "    if axes is None: return x.min()\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    min_x = x\n",
    "    for ax in axes: min_x, _ = min_x.min(ax, keepdim)\n",
    "    return min_x\n",
    "\n",
    "@patch\n",
    "def mul_max(x:torch.Tensor, axes=None, keepdim=False):\n",
    "    if axes is None: return x.max()\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    max_x = x\n",
    "    for ax in axes: max_x, _ = max_x.max(ax, keepdim)\n",
    "    return max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack(o, axis=0):\n",
    "    if isinstance(o[0], torch.Tensor): return torch.stack(tuple(o), dim=axis)\n",
    "    else: return np.stack(o, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "a = np.random.rand(2, 3, 4)\n",
    "t = torch.from_numpy(a)\n",
    "test_eq_type(stack(itemify(a, tup_id=0)), a)\n",
    "test_eq_type(stack(itemify(t, tup_id=0)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is a convenience function will use later proposed by Thomas Capelle @tcapelle to be able to easily benchmark dl performance\n",
    "def cycle_dl(dl):\n",
    "    for _ in iter(dl): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "defaults.device = device\n",
    "cpus = defaults.cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current notebook saved.\n",
      "\n",
      "Converted 000_utils.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.tfms.ipynb.\n",
      "Converted 010_rocket_functions.ipynb.\n",
      "Converted 100_layers.ipynb.\n",
      "Converted 101_ResNet.ipynb.\n",
      "Converted 102_InceptionTime.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "Correct conversion!\n",
      "Total elapsed time 0 s\n",
      "14-04-2020 08:54:12\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from save_nb import *\n",
    "from nbdev.export import *\n",
    "save_nb()\n",
    "notebook2script()\n",
    "last_saved(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
