{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Helper function used to build PyTorch timeseries models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn.init import normal_\n",
    "from fastai.torch_core import Module\n",
    "from fastai.layers import *\n",
    "from torch.nn.utils import weight_norm, spectral_norm\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def noop(x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_lin_zero(m):\n",
    "    if isinstance(m, (nn.Linear)): \n",
    "        if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "        nn.init.constant_(m.weight, 0)\n",
    "    for l in m.children(): init_lin_zero(l)\n",
    "        \n",
    "lin_zero_init = init_lin_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "class SwishBeta(Module):\n",
    "    def __init__(self, beta=1.): \n",
    "        self.sigmoid = torch.sigmoid\n",
    "        self.beta = nn.Parameter(torch.Tensor(1).fill_(beta).to(default_device()))\n",
    "    def forward(self, x): return x.mul(self.sigmoid(x*self.beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def same_padding1d(seq_len, ks, stride=1, dilation=1):\n",
    "    \"Same padding formula as used in Tensorflow\"\n",
    "    p = (seq_len - 1) * stride + (ks - 1) * dilation + 1 - seq_len\n",
    "    return p // 2, p - p // 2\n",
    "\n",
    "\n",
    "class Pad1d(nn.ConstantPad1d):\n",
    "    def __init__(self, padding, value=0.):\n",
    "        super().__init__(padding, value)\n",
    "\n",
    "\n",
    "@delegates(nn.Conv1d)\n",
    "class Conv1dSame(Module):\n",
    "    \"Conv1d with padding='same'\"\n",
    "    def __init__(self, ni, nf, ks=3, stride=1, dilation=1, **kwargs):\n",
    "        self.ks, self.stride, self.dilation = ks, stride, dilation\n",
    "        self.conv1d_same = nn.Conv1d(ni, nf, ks, stride=stride, dilation=dilation, **kwargs)\n",
    "        self.weight = self.conv1d_same.weight\n",
    "        self.bias = self.conv1d_same.bias\n",
    "        self.pad = Pad1d\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.padding = same_padding1d(x.shape[-1], self.ks, dilation=self.dilation) #stride=self.stride not used in padding calculation!\n",
    "        return self.conv1d_same(self.pad(self.padding)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_linear(Conv1dSame(2, 3, 3), None, init='auto', bias_std=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_in = 3\n",
    "c_out = 5\n",
    "seq_len = 6\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "test_eq(Conv1dSame(c_in, c_out, ks=3, stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, seq_len))\n",
    "test_eq(Conv1dSame(c_in, c_out, ks=3, stride=1, dilation=2, bias=False)(t).shape, (bs, c_out, seq_len))\n",
    "test_eq(Conv1dSame(c_in, c_out, ks=3, stride=2, dilation=1, bias=False)(t).shape, (bs, c_out, seq_len//2))\n",
    "test_eq(Conv1dSame(c_in, c_out, ks=3, stride=2, dilation=2, bias=False)(t).shape, (bs, c_out, seq_len//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def same_padding2d(H, W, ks, stride=(1, 1), dilation=(1, 1)):\n",
    "    \"Same padding formula as used in Tensorflow\"\n",
    "    if isinstance(ks, Integral): ks = (ks, ks)\n",
    "    if ks[0] == 1:  p_h = 0\n",
    "    else:  p_h = (H - 1) * stride[0] + (ks[0] - 1) * dilation[0] + 1 - H\n",
    "    if ks[1] == 1:  p_w = 0\n",
    "    else:  p_w = (W - 1) * stride[1] + (ks[1] - 1) * dilation[1] + 1 - W\n",
    "    return (p_w // 2, p_w - p_w // 2, p_h // 2, p_h - p_h // 2)\n",
    "\n",
    "\n",
    "class Pad2d(nn.ConstantPad2d):\n",
    "    def __init__(self, padding, value=0.):\n",
    "        super().__init__(padding, value)\n",
    "\n",
    "\n",
    "@delegates(nn.Conv2d)\n",
    "class Conv2dSame(Module):\n",
    "    \"Conv2d with padding='same'\"\n",
    "    def __init__(self, ni, nf, ks=(3, 3), stride=(1, 1), dilation=(1, 1), **kwargs):\n",
    "        if isinstance(ks, Integral): ks = (ks, ks)\n",
    "        if isinstance(stride, Integral): stride = (stride, stride)\n",
    "        if isinstance(dilation, Integral): dilation = (dilation, dilation)\n",
    "        self.ks, self.stride, self.dilation = ks, stride, dilation\n",
    "        self.conv2d_same = nn.Conv2d(ni, nf, ks, stride=stride, dilation=dilation, **kwargs)\n",
    "        self.weight = self.conv2d_same.weight\n",
    "        self.bias = self.conv2d_same.bias\n",
    "        self.pad = Pad2d\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.padding = same_padding2d(x.shape[-2], x.shape[-1], self.ks, dilation=self.dilation) #stride=self.stride not used in padding calculation!\n",
    "        return self.conv2d_same(self.pad(self.padding)(x))\n",
    "    \n",
    "    \n",
    "@delegates(nn.Conv2d)\n",
    "def Conv2d(ni, nf, kernel_size=None, ks=None, stride=1, padding='same', dilation=1, init='auto', bias_std=0.01, **kwargs):\n",
    "    \"conv1d layer with padding='same', 'valid', or any integer (defaults to 'same')\"\n",
    "    assert not (kernel_size and ks), 'use kernel_size or ks but not both simultaneously'\n",
    "    assert kernel_size is not None or ks is not None, 'you need to pass a ks'\n",
    "    kernel_size = kernel_size or ks\n",
    "    if padding == 'same': \n",
    "        conv = Conv2dSame(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)\n",
    "    elif padding == 'valid': conv = nn.Conv2d(ni, nf, kernel_size, stride=stride, padding=0, dilation=dilation, **kwargs)\n",
    "    else: conv = nn.Conv2d(ni, nf, kernel_size, stride=stride, padding=padding, dilation=dilation, **kwargs)\n",
    "    init_linear(conv, None, init=init, bias_std=bias_std)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_in = 3\n",
    "c_out = 5\n",
    "h = 16\n",
    "w = 20\n",
    "t = torch.rand(bs, c_in, h, w)\n",
    "test_eq(Conv2dSame(c_in, c_out, ks=3, stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))\n",
    "test_eq(Conv2dSame(c_in, c_out, ks=(3, 1), stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))\n",
    "test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(1, 1), dilation=(2, 2), bias=False)(t).shape, (bs, c_out, h, w))\n",
    "test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(2, 2), dilation=(1, 1), bias=False)(t).shape, (bs, c_out, h//2, w//2))\n",
    "test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(2, 2), dilation=(2, 2), bias=False)(t).shape, (bs, c_out, h//2, w//2))\n",
    "test_eq(Conv2d(c_in, c_out, ks=3, padding='same', stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Modified from https://github.com/locuslab/TCN/blob/master/TCN/tcn.py\n",
    "class Conv1dCausal(Module):\n",
    "    def __init__(self, ni, nf, ks, stride=1, dilation=1, **kwargs):\n",
    "        padding = (ks - 1) * dilation\n",
    "        self.conv_causal = nn.Conv1d(ni, nf, ks, stride=stride, padding=padding, dilation=dilation, **kwargs)\n",
    "        self.weight = self.conv_causal.weight\n",
    "        self.bias = self.conv_causal.bias\n",
    "        self.chomp_size = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_causal(x)\n",
    "        return x[..., :-self.chomp_size].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_linear(Conv1dCausal(2, 3, 3), None, init='auto', bias_std=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_in = 3\n",
    "c_out = 5\n",
    "seq_len = 512\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "dilation = 1\n",
    "test_eq(Conv1dCausal(c_in, c_out, ks=3, dilation=dilation)(t).shape, Conv1dSame(c_in, c_out, ks=3, dilation=dilation)(t).shape)\n",
    "dilation = 2\n",
    "test_eq(Conv1dCausal(c_in, c_out, ks=3, dilation=dilation)(t).shape, Conv1dSame(c_in, c_out, ks=3, dilation=dilation)(t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(nn.Conv1d)\n",
    "def Conv1d(ni, nf, kernel_size=None, ks=None, stride=1, padding='same', dilation=1, init='auto', bias_std=0.01, **kwargs):\n",
    "    \"conv1d layer with padding='same', 'causal', 'valid', or any integer (defaults to 'same')\"\n",
    "    assert not (kernel_size and ks), 'use kernel_size or ks but not both simultaneously'\n",
    "    assert kernel_size is not None or ks is not None, 'you need to pass a ks'\n",
    "    kernel_size = kernel_size or ks\n",
    "    if padding == 'same': \n",
    "        if kernel_size%2==1: \n",
    "            conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=kernel_size//2 * dilation, dilation=dilation, **kwargs)\n",
    "        else:\n",
    "            conv = Conv1dSame(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)\n",
    "    elif padding == 'causal': conv = Conv1dCausal(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)\n",
    "    elif padding == 'valid': conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=0, dilation=dilation, **kwargs)\n",
    "    else: conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=padding, dilation=dilation, **kwargs)\n",
    "    init_linear(conv, None, init=init, bias_std=bias_std)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "ni = 3\n",
    "nf = 5\n",
    "seq_len = 6\n",
    "ks = 3\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "test_eq(Conv1d(ni, nf, ks, padding=0)(t).shape, (bs, c_out, seq_len - (2 * (ks//2))))\n",
    "test_eq(Conv1d(ni, nf, ks, padding='valid')(t).shape, (bs, c_out, seq_len - (2 * (ks//2))))\n",
    "test_eq(Conv1d(ni, nf, ks, padding='same')(t).shape, (bs, c_out, seq_len))\n",
    "test_eq(Conv1d(ni, nf, ks, padding='causal')(t).shape, (bs, c_out, seq_len))\n",
    "test_error('use kernel_size or ks but not both simultaneously', Conv1d, ni, nf, kernel_size=3, ks=3)\n",
    "test_error('you need to pass a ks', Conv1d, ni, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(3, 5, kernel_size=(3,), stride=(1,), padding=(1,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv1d(ni, nf, ks, padding='same')\n",
    "init_linear(conv, None, init='auto', bias_std=.01)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1dCausal(\n",
       "  (conv_causal): Conv1d(3, 5, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv1d(ni, nf, ks, padding='causal')\n",
    "init_linear(conv, None, init='auto', bias_std=.01)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(3, 5, kernel_size=(3,), stride=(1,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv1d(ni, nf, ks, padding='valid')\n",
    "init_linear(conv, None, init='auto', bias_std=.01)\n",
    "weight_norm(conv)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(3, 5, kernel_size=(3,), stride=(1,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv1d(ni, nf, ks, padding=0)\n",
    "init_linear(conv, None, init='auto', bias_std=.01)\n",
    "weight_norm(conv)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SeparableConv1d(Module):\n",
    "    def __init__(self, ni, nf, ks, stride=1, padding='same', dilation=1, bias=True, bias_std=0.01):\n",
    "        self.depthwise_conv = Conv1d(ni, ni, ks, stride=stride, padding=padding, dilation=dilation, groups=ni, bias=bias)\n",
    "        self.pointwise_conv = nn.Conv1d(ni, nf, 1, stride=1, padding=0, dilation=1, groups=1, bias=bias)\n",
    "        if bias:\n",
    "            if bias_std != 0: \n",
    "                normal_(self.depthwise_conv.bias, 0, bias_std)\n",
    "                normal_(self.pointwise_conv.bias, 0, bias_std)\n",
    "            else: \n",
    "                self.depthwise_conv.bias.data.zero_()\n",
    "                self.pointwise_conv.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "c_in = 6\n",
    "c_out = 5\n",
    "seq_len = 512\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "test_eq(SeparableConv1d(c_in, c_out, 3)(t).shape, (bs, c_out, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AddCoords1d(Module):\n",
    "    \"\"\"Add coordinates to ease position identification without modifying mean and std\"\"\"\n",
    "    def forward(self, x):\n",
    "        bs, _, seq_len = x.shape\n",
    "        cc = torch.linspace(-1,1,x.shape[-1]).repeat(bs, 1, 1).to(x.device)\n",
    "        cc = (cc - cc.mean()) / cc.std()\n",
    "        x = torch.cat([x, cc], dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_in = 3\n",
    "c_out = 5\n",
    "seq_len = 50\n",
    "\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "t = (t - t.mean()) / t.std()\n",
    "test_eq(AddCoords1d()(t).shape, (bs, c_in + 1, seq_len))\n",
    "new_t = AddCoords1d()(t)\n",
    "test_close(new_t.mean(),0, 1e-2)\n",
    "test_close(new_t.std(), 1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvBlock(nn.Sequential):\n",
    "    \"Create a sequence of conv1d (`ni` to `nf`), activation (if `act_cls`) and `norm_type` layers.\"\n",
    "    def __init__(self, ni, nf, kernel_size=None, ks=3, stride=1, padding='same', bias=None, bias_std=0.01, norm='Batch', zero_norm=False, bn_1st=True,\n",
    "                 act=nn.ReLU, act_kwargs={}, init='auto', dropout=0., xtra=None, coord=False, separable=False,  **kwargs):\n",
    "        kernel_size = kernel_size or ks\n",
    "        ndim = 1\n",
    "        layers = [AddCoords1d()] if coord else []\n",
    "        norm_type = getattr(NormType,f\"{snake2camel(norm)}{'Zero' if zero_norm else ''}\") if norm is not None else None\n",
    "        bn = norm_type in (NormType.Batch, NormType.BatchZero)\n",
    "        inn = norm_type in (NormType.Instance, NormType.InstanceZero)\n",
    "        if bias is None: bias = not (bn or inn)\n",
    "        if separable: conv = SeparableConv1d(ni + coord, nf, ks=kernel_size, bias=bias, stride=stride, padding=padding, **kwargs)\n",
    "        else: conv = Conv1d(ni + coord, nf, ks=kernel_size, bias=bias, stride=stride, padding=padding, **kwargs)\n",
    "        act = None if act is None else act(**act_kwargs)\n",
    "        if not separable: init_linear(conv, act, init=init, bias_std=bias_std)\n",
    "        if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n",
    "        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n",
    "        layers += [conv]\n",
    "        act_bn = []        \n",
    "        if act is not None: act_bn.append(act)\n",
    "        if bn: act_bn.append(BatchNorm(nf, norm_type=norm_type, ndim=ndim))\n",
    "        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))\n",
    "        if bn_1st: act_bn.reverse()\n",
    "        if dropout: layers += [nn.Dropout(dropout)]\n",
    "        layers += act_bn\n",
    "        if xtra: layers.append(xtra)\n",
    "        super().__init__(*layers)     \n",
    "                            \n",
    "Conv = partial(ConvBlock, norm=None, act=None)\n",
    "ConvBN = partial(ConvBlock, norm='Batch', act=None)\n",
    "ConvIN = partial(ConvBlock, norm='Instance', act=None)\n",
    "CoordConv = partial(ConvBlock, norm=None, act=None, coord=True)\n",
    "CoordConvBN = partial(ConvBlock, norm='Batch', act=None, coord=True)\n",
    "SepConv = partial(ConvBlock, norm=None, act=None, separable=True)\n",
    "SepConvBN = partial(ConvBlock, norm='Batch', act=None, separable=True)\n",
    "SepConvIN = partial(ConvBlock, norm='Instance', act=None, separable=True)\n",
    "SepCoordConv = partial(ConvBlock, norm=None, act=None, coord=True, separable=True)\n",
    "SepCoordConvBN = partial(ConvBlock, norm='Batch', act=None, coord=True, separable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock1dPlus(Module):\n",
    "    \"Resnet block from `ni` to `nh` with `stride`\"\n",
    "    @delegates(ConvLayer.__init__)\n",
    "    def __init__(self, expansion, ni, nf, coord=False, stride=1, groups=1, reduction=None, nh1=None, nh2=None, dw=False, g2=1,\n",
    "                 sa=False, sym=False, norm='Batch', zero_norm=True, act_cls=defaults.activation, ks=3,\n",
    "                 pool=AvgPool, pool_first=True, **kwargs):\n",
    "        if nh2 is None: nh2 = nf\n",
    "        if nh1 is None: nh1 = nh2\n",
    "        nf,ni = nf*expansion,ni*expansion\n",
    "        k0 = dict(norm=norm, zero_norm=False, act=act_cls, **kwargs)\n",
    "        k1 = dict(norm=norm, zero_norm=zero_norm, act=None, **kwargs)\n",
    "        convpath  = [ConvBlock(ni,  nh2, ks, coord=coord, stride=stride, groups=ni if dw else groups, **k0),\n",
    "                     ConvBlock(nh2,  nf, ks, coord=coord, groups=g2, **k1)\n",
    "        ] if expansion == 1 else [\n",
    "                     ConvBlock(ni,  nh1, 1, coord=coord, **k0),\n",
    "                     ConvBlock(nh1, nh2, ks, coord=coord, stride=stride, groups=nh1 if dw else groups, **k0),\n",
    "                     ConvBlock(nh2,  nf, 1, coord=coord, groups=g2, **k1)]\n",
    "        if reduction: convpath.append(SEModule(nf, reduction=reduction, act_cls=act_cls))\n",
    "        if sa: convpath.append(SimpleSelfAttention(nf,ks=1,sym=sym))\n",
    "        self.convpath = nn.Sequential(*convpath)\n",
    "        idpath = []\n",
    "        if ni!=nf: idpath.append(ConvBlock(ni, nf, 1, coord=coord, act=None, **kwargs))\n",
    "        if stride!=1: idpath.insert((1,0)[pool_first], pool(stride, ndim=1, ceil_mode=True))\n",
    "        self.idpath = nn.Sequential(*idpath)\n",
    "        self.act = defaults.activation(inplace=True) if act_cls is defaults.activation else act_cls()\n",
    "\n",
    "    def forward(self, x): return self.act(self.convpath(x) + self.idpath(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SEModule1d(ni, reduction=16, act=nn.ReLU, act_kwargs={}):\n",
    "    \"Squeeze and excitation module for 1d\"\n",
    "    nf = math.ceil(ni//reduction/8)*8\n",
    "    assert nf != 0, 'nf cannot be 0'\n",
    "    return SequentialEx(nn.AdaptiveAvgPool1d(1), \n",
    "                        ConvBlock(ni, nf, ks=1, norm=None, act=act, act_kwargs=act_kwargs),\n",
    "                        ConvBlock(nf, ni, ks=1, norm=None, act=nn.Sigmoid), ProdLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(8, 32, 12)\n",
    "test_eq(SEModule1d(t.shape[1], 16, act=nn.ReLU, act_kwargs={})(t).shape, t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Norm(nf, ndim=1, norm='Batch', zero_norm=False, init=True, **kwargs):\n",
    "    \"Norm layer with `nf` features and `ndim` with auto init.\"\n",
    "    assert 1 <= ndim <= 3\n",
    "    nl = getattr(nn, f\"{snake2camel(norm)}Norm{ndim}d\")(nf, **kwargs)\n",
    "    if nl.affine and init:\n",
    "        nl.bias.data.fill_(1e-3)\n",
    "        nl.weight.data.fill_(0. if zero_norm else 1.)\n",
    "    return nl\n",
    "\n",
    "BN1d = partial(Norm, ndim=1, norm='Batch')\n",
    "IN1d = partial(Norm, ndim=1, norm='Instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "ni = 3\n",
    "nf = 5\n",
    "sl = 4\n",
    "ks = 5\n",
    "\n",
    "t = torch.rand(bs, ni, sl)\n",
    "test_eq(ConvBlock(ni, nf, ks)(t).shape, (bs, nf, sl))\n",
    "test_eq(ConvBlock(ni, nf, ks, padding='causal')(t).shape, (bs, nf, sl))\n",
    "test_eq(ConvBlock(ni, nf, ks, coord=True)(t).shape, (bs, nf, sl))\n",
    "ConvBlock(ni, nf, ks, stride=2)(t).shape\n",
    "test_eq(ConvBlock(ni, nf, ks, stride=2)(t).shape, (bs, nf, sl//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(BN1d(ni)(t).shape, (bs, ni, sl))\n",
    "test_eq(BN1d(ni).weight.data.mean().item(), 1.)\n",
    "test_eq(BN1d(ni, zero_norm=True).weight.data.mean().item(), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (0): AddCoords1d()\n",
       "  (1): Conv1d(4, 5, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "  (2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Swish()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(ConvBlock(ni, nf, ks, norm='batch', zero_norm=True)[1].weight.data.unique().item(), 0)\n",
    "test_ne(ConvBlock(ni, nf, ks, norm='batch', zero_norm=False)[1].weight.data.unique().item(), 0)\n",
    "test_eq(ConvBlock(ni, nf, ks, bias=False)[0].bias, None)\n",
    "ConvBlock(ni, nf, ks, act=Swish, coord=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinLnDrop(nn.Sequential):\n",
    "    \"Module grouping `LayerNorm1d`, `Dropout` and `Linear` layers\"\n",
    "    def __init__(self, n_in, n_out, ln=True, p=0., act=None, lin_first=False):\n",
    "        layers = [nn.LayerNorm(n_out if lin_first else n_in)] if ln else []\n",
    "        if p != 0: layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_in, n_out, bias=not ln)]\n",
    "        if act is not None: lin.append(act)\n",
    "        layers = lin+layers if lin_first else layers+lin\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinLnDrop(\n",
       "  (0): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "  (1): Dropout(p=0.5, inplace=False)\n",
       "  (2): Linear(in_features=2, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinLnDrop(2, 3, p=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LambdaPlus(Module):\n",
    "    def __init__(self, func, *args, **kwargs): self.func,self.args,self.kwargs=func,args,kwargs\n",
    "    def forward(self, x): return self.func(x, *self.args, **self.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Squeeze(Module):\n",
    "    def __init__(self, dim=-1): self.dim = dim\n",
    "    def forward(self, x): return x.squeeze(dim=self.dim)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "\n",
    "\n",
    "class Unsqueeze(Module):\n",
    "    def __init__(self, dim=-1): self.dim = dim\n",
    "    def forward(self, x): return x.unsqueeze(dim=self.dim)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "\n",
    "\n",
    "class Add(Module):\n",
    "    def forward(self, x, y): return x.add(y)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}'\n",
    "\n",
    "\n",
    "class Concat(Module):\n",
    "    def __init__(self, dim=1): self.dim = dim\n",
    "    def forward(self, *x): return torch.cat(*x, dim=self.dim)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "\n",
    "\n",
    "class Permute(Module):\n",
    "    def __init__(self, *dims): self.dims = dims\n",
    "    def forward(self, x): return x.permute(self.dims)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}(dims={', '.join([str(d) for d in self.dims])})\"\n",
    "    \n",
    "    \n",
    "class Transpose(Module):\n",
    "    def __init__(self, *dims, contiguous=False): self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x): \n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "    def __repr__(self): \n",
    "        if self.contiguous: return f\"{self.__class__.__name__}(dims={', '.join([str(d) for d in self.dims])}).contiguous()\"\n",
    "        else: return f\"{self.__class__.__name__}({', '.join([str(d) for d in self.dims])})\"\n",
    "    \n",
    "    \n",
    "class View(Module):\n",
    "    def __init__(self, *shape): self.shape = shape\n",
    "    def forward(self, x): return x.view(x.shape[0], *self.shape)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({', '.join(['bs'] + [str(s) for s in self.shape])})\"\n",
    "    \n",
    "    \n",
    "class Reshape(Module):\n",
    "    def __init__(self, *shape): self.shape = shape\n",
    "    def forward(self, x): return x.reshape(x.shape[0], *self.shape)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({', '.join(['bs'] + [str(s) for s in self.shape])})\"\n",
    "    \n",
    "    \n",
    "class Max(Module):\n",
    "    def __init__(self, dim=None, keepdim=False): self.dim, self.keepdim = dim, keepdim\n",
    "    def forward(self, x): return x.max(self.dim, keepdim=self.keepdim)[0]\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim}, keepdim={self.keepdim})'\n",
    "\n",
    "    \n",
    "class LastStep(Module):\n",
    "    def forward(self, x): return x[..., -1]\n",
    "    def __repr__(self): return f'{self.__class__.__name__}()'\n",
    "    \n",
    "    \n",
    "class SoftMax(Module):\n",
    "    \"SoftMax layer\"\n",
    "    def __init__(self, dim=-1):\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        return F.softmax(x, dim=self.dim)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})' \n",
    "    \n",
    "\n",
    "class Clamp(Module):\n",
    "    def __init__(self, min=None, max=None):\n",
    "        self.min, self.max = min, max\n",
    "    def forward(self, x):\n",
    "        return x.clamp(min=self.min, max=self.max)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(min={self.min}, max={self.max})' \n",
    "    \n",
    "    \n",
    "class Clip(Module):\n",
    "    def __init__(self, min=None, max=None):\n",
    "        self.min, self.max = min, max\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.min is not None:\n",
    "            x = torch.maximum(x, self.min)\n",
    "        if self.max is not None:\n",
    "            x = torch.minimum(x, self.max)\n",
    "        return x\n",
    "    def __repr__(self): return f'{self.__class__.__name__}()' \n",
    "    \n",
    "Noop = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Transpose(1, 2),\n",
       " Permute(dims=0, 2, 1),\n",
       " View(bs, -1, 2, 10),\n",
       " Transpose(dims=1, 2).contiguous(),\n",
       " Reshape(bs, -1, 2, 10),\n",
       " Sequential())"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 2\n",
    "nf = 5\n",
    "sl = 4\n",
    "\n",
    "t = torch.rand(bs, nf, sl)\n",
    "test_eq(Permute(0,2,1)(t).shape, (bs, sl, nf))\n",
    "test_eq(Max(1)(t).shape, (bs, sl))\n",
    "test_eq(Transpose(1,2)(t).shape, (bs, sl, nf))\n",
    "test_eq(Transpose(1,2, contiguous=True)(t).shape, (bs, sl, nf))\n",
    "test_eq(View(-1, 2, 10)(t).shape, (bs, 1, 2, 10))\n",
    "test_eq(Reshape(-1, 2, 10)(t).shape, (bs, 1, 2, 10))\n",
    "Transpose(1,2), Permute(0,2,1), View(-1, 2, 10), Transpose(1,2, contiguous=True), Reshape(-1, 2, 10), Noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Sharpen(Module):\n",
    "    \"This is used to increase confidence in predictions - MixMatch paper\"\n",
    "    def __init__(self, T=.5): self.T = T\n",
    "    def forward(self, x):\n",
    "        x = x**(1. / self.T)\n",
    "        return x / x.sum(dim=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "n_classes = 3\n",
    "\n",
    "t = (torch.rand(n_samples, n_classes) - .5) * 10\n",
    "probas = F.softmax(t, -1)\n",
    "sharpened_probas = Sharpen()(probas)\n",
    "plt.plot(probas.flatten().sort().values, color='r')\n",
    "plt.plot(sharpened_probas.flatten().sort().values, color='b')\n",
    "plt.show()\n",
    "test_gt(sharpened_probas[n_samples//2:].max(-1).values.sum().item(), probas[n_samples//2:].max(-1).values.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Sequential(nn.Sequential):\n",
    "    \"\"\"Class that allows you to pass one or multiple inputs\"\"\"\n",
    "    def forward(self, *x):\n",
    "        for i, module in enumerate(self._modules.values()): \n",
    "            x = module(*x) if isinstance(x, (list, tuple, L)) else module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Temp_Scale(Module):\n",
    "    \"Used to perform Temperature Scaling (dirichlet=False) or Single-parameter Dirichlet calibration (dirichlet=True)\"\n",
    "    def __init__(self, temp=1., dirichlet=False):\n",
    "        self.weight = nn.Parameter(tensor(temp))\n",
    "        self.bias = None\n",
    "        self.log_softmax = dirichlet\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.log_softmax: x = F.log_softmax(x, dim=-1)\n",
    "        return x.div(self.weight)\n",
    "\n",
    "\n",
    "class Vector_Scale(Module):\n",
    "    \"Used to perform Vector Scaling (dirichlet=False) or Diagonal Dirichlet calibration (dirichlet=True)\"\n",
    "    def __init__(self, n_classes=1, dirichlet=False):\n",
    "        self.weight = nn.Parameter(torch.ones(n_classes))\n",
    "        self.bias = nn.Parameter(torch.zeros(n_classes))\n",
    "        self.log_softmax = dirichlet\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.log_softmax: x = F.log_softmax(x, dim=-1)\n",
    "        return x.mul(self.weight).add(self.bias)\n",
    "\n",
    "\n",
    "class Matrix_Scale(Module):\n",
    "    \"Used to perform Matrix Scaling (dirichlet=False) or Dirichlet calibration (dirichlet=True)\"\n",
    "    def __init__(self, n_classes=1, dirichlet=False):\n",
    "        self.ms = nn.Linear(n_classes, n_classes)\n",
    "        self.ms.weight.data = nn.Parameter(torch.eye(n_classes))\n",
    "        nn.init.constant_(self.ms.bias.data, 0.)\n",
    "        self.weight = self.ms.weight\n",
    "        self.bias = self.ms.bias\n",
    "        self.log_softmax = dirichlet\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.log_softmax: x = F.log_softmax(x, dim=-1)\n",
    "        return self.ms(x)\n",
    "    \n",
    "    \n",
    "def get_calibrator(calibrator=None, n_classes=1, **kwargs):\n",
    "    if calibrator is None or not calibrator: return noop\n",
    "    elif calibrator.lower() == 'temp': return Temp_Scale(dirichlet=False, **kwargs)\n",
    "    elif calibrator.lower() == 'vector': return Vector_Scale(n_classes=n_classes, dirichlet=False, **kwargs)\n",
    "    elif calibrator.lower() == 'matrix': return Matrix_Scale(n_classes=n_classes, dirichlet=False, **kwargs)\n",
    "    elif calibrator.lower() == 'dtemp': return Temp_Scale(dirichlet=True, **kwargs)\n",
    "    elif calibrator.lower() == 'dvector': return Vector_Scale(n_classes=n_classes, dirichlet=True, **kwargs)\n",
    "    elif calibrator.lower() == 'dmatrix': return Matrix_Scale(n_classes=n_classes, dirichlet=True, **kwargs)\n",
    "    else: assert False, f'please, select a correct calibrator instead of {calibrator}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_out = 3\n",
    "\n",
    "t = torch.rand(bs, c_out)\n",
    "for calibrator, cal_name in zip(['temp', 'vector', 'matrix'], ['Temp_Scale', 'Vector_Scale', 'Matrix_Scale']): \n",
    "    cal = get_calibrator(calibrator, n_classes=c_out)\n",
    "#     print(calibrator)\n",
    "#     print(cal.weight, cal.bias, '\\n')\n",
    "    test_eq(cal(t), t)\n",
    "    test_eq(cal.__class__.__name__, cal_name)\n",
    "for calibrator, cal_name in zip(['dtemp', 'dvector', 'dmatrix'], ['Temp_Scale', 'Vector_Scale', 'Matrix_Scale']):\n",
    "    cal = get_calibrator(calibrator, n_classes=c_out)\n",
    "#     print(calibrator)\n",
    "#     print(cal.weight, cal.bias, '\\n')\n",
    "    test_eq(cal(t), F.log_softmax(t, dim=1))\n",
    "    test_eq(cal.__class__.__name__, cal_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_out = 3\n",
    "\n",
    "t = torch.rand(bs, c_out)\n",
    "\n",
    "test_eq(Temp_Scale()(t).shape, t.shape)\n",
    "test_eq(Vector_Scale(c_out)(t).shape, t.shape)\n",
    "test_eq(Matrix_Scale(c_out)(t).shape, t.shape)\n",
    "test_eq(Temp_Scale(dirichlet=True)(t).shape, t.shape)\n",
    "test_eq(Vector_Scale(c_out, dirichlet=True)(t).shape, t.shape)\n",
    "test_eq(Matrix_Scale(c_out, dirichlet=True)(t).shape, t.shape)\n",
    "\n",
    "test_eq(Temp_Scale()(t), t)\n",
    "test_eq(Vector_Scale(c_out)(t), t)\n",
    "test_eq(Matrix_Scale(c_out)(t), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_out = 5\n",
    "\n",
    "t = torch.rand(bs, c_out)\n",
    "test_eq(Vector_Scale(c_out)(t), t)\n",
    "test_eq(Vector_Scale(c_out).weight.data, torch.ones(c_out))\n",
    "test_eq(Vector_Scale(c_out).weight.requires_grad, True)\n",
    "test_eq(type(Vector_Scale(c_out).weight), torch.nn.parameter.Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "c_out = 3\n",
    "weight = 2\n",
    "bias = 1\n",
    "\n",
    "t = torch.rand(bs, c_out)\n",
    "test_eq(Matrix_Scale(c_out)(t).shape, t.shape)\n",
    "test_eq(Matrix_Scale(c_out).weight.requires_grad, True)\n",
    "test_eq(type(Matrix_Scale(c_out).weight), torch.nn.parameter.Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogitAdjustmentLayer(Module):\n",
    "    \"Logit Adjustment for imbalanced datasets\"\n",
    "    def __init__(self, class_priors):\n",
    "        self.class_priors = class_priors\n",
    "    def forward(self, x):\n",
    "        return x.add(self.class_priors)\n",
    "    \n",
    "LogitAdjLayer = LogitAdjustmentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, n_classes = 16, 3\n",
    "class_priors = torch.rand(n_classes)\n",
    "logits = torch.randn(bs, n_classes) * 2\n",
    "test_eq(LogitAdjLayer(class_priors)(logits), logits + class_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PPV(Module):\n",
    "    def __init__(self, dim=-1): \n",
    "        self.dim = dim\n",
    "    def forward(self, x): \n",
    "        return torch.gt(x, 0).sum(dim=self.dim).float() / x.shape[self.dim]\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "    \n",
    "\n",
    "class PPAuc(Module):\n",
    "    def __init__(self, dim=-1): \n",
    "        self.dim = dim\n",
    "    def forward(self, x): \n",
    "        x = F.relu(x).sum(self.dim) / (abs(x).sum(self.dim) + 1e-8)\n",
    "        return x\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "    \n",
    "    \n",
    "class MaxPPVPool1d(Module):\n",
    "    \"Drop-in replacement for AdaptiveConcatPool1d - multiplies nf by 2\"\n",
    "    def forward(self, x):\n",
    "        _max = x.max(dim=-1).values\n",
    "        _ppv = torch.gt(x, 0).sum(dim=-1).float() / x.shape[-1]\n",
    "        return torch.cat((_max, _ppv), dim=-1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "nf = 5\n",
    "sl = 4\n",
    "\n",
    "t = torch.rand(bs, nf, sl)\n",
    "test_eq(MaxPPVPool1d()(t).shape, (bs, nf*2, 1))\n",
    "test_eq(MaxPPVPool1d()(t).shape, AdaptiveConcatPool1d(1)(t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptiveWeightedAvgPool1d(Module):\n",
    "    '''Global Pooling layer that performs a weighted average along the temporal axis\n",
    "    \n",
    "    It can be considered as a channel-wise form of local temporal attention. Inspired by the paper: \n",
    "    Hyun, J., Seong, H., & Kim, E. (2019). Universal Pooling--A New Pooling Method for Convolutional Neural Networks. arXiv preprint arXiv:1907.11440.'''\n",
    "\n",
    "    def __init__(self, n_in, seq_len, mult=2, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=True):\n",
    "        layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            inp_mult = mult if i > 0 else 1\n",
    "            out_mult = mult if i < n_layers -1 else 1\n",
    "            p = dropout[i] if is_listy(dropout) else dropout\n",
    "            layers.append(LinLnDrop(seq_len * inp_mult, seq_len * out_mult, ln=False, p=p, \n",
    "                                    act=act if i < n_layers-1 and n_layers > 1 else None))\n",
    "        self.layers = layers\n",
    "        self.softmax = SoftMax(-1)\n",
    "        if zero_init: init_lin_zero(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        wap = x\n",
    "        for l in self.layers: wap = l(wap)\n",
    "        wap = self.softmax(wap)\n",
    "        return torch.mul(x, wap).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GAP1d(Module):\n",
    "    \"Global Adaptive Pooling + Flatten\"\n",
    "    def __init__(self, output_size=1):\n",
    "        self.gap = nn.AdaptiveAvgPool1d(output_size)\n",
    "        self.flatten = Flatten()\n",
    "    def forward(self, x):\n",
    "        return self.flatten(self.gap(x))\n",
    "    \n",
    "    \n",
    "class GACP1d(Module):\n",
    "    \"Global AdaptiveConcatPool + Flatten\"\n",
    "    def __init__(self, output_size=1):\n",
    "        self.gacp = AdaptiveConcatPool1d(output_size)\n",
    "        self.flatten = Flatten()\n",
    "    def forward(self, x):\n",
    "        return self.flatten(self.gacp(x))\n",
    "    \n",
    "\n",
    "class GAWP1d(Module):\n",
    "    \"Global AdaptiveWeightedAvgPool1d + Flatten\"\n",
    "    def __init__(self, n_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False):\n",
    "        self.gacp = AdaptiveWeightedAvgPool1d(n_in, seq_len, n_layers=n_layers, ln=ln, dropout=dropout, act=act, zero_init=zero_init)\n",
    "        self.flatten = Flatten()\n",
    "    def forward(self, x):\n",
    "        return self.flatten(self.gacp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GlobalWeightedAveragePool1d(Module):\n",
    "    \"\"\" Global Weighted Average Pooling layer \n",
    "    \n",
    "    Inspired by Building Efficient CNN Architecture for Offline Handwritten Chinese Character Recognition\n",
    "    https://arxiv.org/pdf/1804.01259.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, seq_len): \n",
    "        self.weight = nn.Parameter(torch.ones(1, n_in, seq_len))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, n_in, seq_len))\n",
    "\n",
    "    def forward(self, x):\n",
    "        α = F.softmax(torch.sigmoid(x * self.weight + self.bias), dim=-1)\n",
    "        return (x * α).sum(-1)\n",
    "\n",
    "GWAP1d = GlobalWeightedAveragePool1d\n",
    "\n",
    "def gwa_pool_head(n_in, c_out, seq_len, bn=True, fc_dropout=0.):\n",
    "    return nn.Sequential(GlobalWeightedAveragePool1d(n_in, seq_len), Flatten(), LinBnDrop(n_in, c_out, p=fc_dropout, bn=bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(16, 64, 50)\n",
    "head = gwa_pool_head(64, 5, 50)\n",
    "test_eq(head(t).shape, (16, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AttentionalPool1d(Module):\n",
    "    \"\"\"Global Adaptive Pooling layer inspired by Attentional Pooling for Action Recognition https://arxiv.org/abs/1711.01467\"\"\"\n",
    "    def __init__(self, n_in, c_out, bn=False): \n",
    "        store_attr()\n",
    "        self.bn = nn.BatchNorm1d(n_in) if bn else None\n",
    "        self.conv1 = Conv1d(n_in, 1, 1)\n",
    "        self.conv2 = Conv1d(n_in, c_out, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bn is not None: x = self.bn(x) \n",
    "        return (self.conv1(x) @ self.conv2(x).transpose(1,2)).transpose(1,2)\n",
    "    \n",
    "class GAttP1d(nn.Sequential):\n",
    "    def __init__(self, n_in, c_out, bn=False):\n",
    "        super().__init__(AttentionalPool1d(n_in, c_out, bn=bn), Flatten())\n",
    "        \n",
    "def attentional_pool_head(n_in, c_out, seq_len=None, bn=True, **kwargs):\n",
    "    return nn.Sequential(AttentionalPool1d(n_in, c_out, bn=bn, **kwargs), Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, c_in, seq_len = 16, 1, 50\n",
    "c_out = 3\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "test_eq(GAP1d()(t).shape, (bs, c_in))\n",
    "test_eq(GACP1d()(t).shape, (bs, c_in*2))\n",
    "bs, c_in, seq_len = 16, 4, 50\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "test_eq(GAP1d()(t).shape, (bs, c_in))\n",
    "test_eq(GACP1d()(t).shape, (bs, c_in*2))\n",
    "test_eq(GAWP1d(c_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False)(t).shape, (bs, c_in))\n",
    "test_eq(GAWP1d(c_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False)(t).shape, (bs, c_in))\n",
    "test_eq(GAWP1d(c_in, seq_len, n_layers=1, ln=False, dropout=0.5, zero_init=False)(t).shape, (bs, c_in))\n",
    "test_eq(GAWP1d(c_in, seq_len, n_layers=1, ln=False, dropout=0.5, zero_init=True)(t).shape, (bs, c_in))\n",
    "test_eq(AttentionalPool1d(c_in, c_out)(t).shape, (bs, c_out, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, c_in, seq_len = 16, 128, 50\n",
    "c_out = 14\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "attp = attentional_pool_head(c_in, c_out)\n",
    "test_eq(attp(t).shape, (bs, c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_pool_head(n_in, c_out, seq_len=None, concat_pool=False, fc_dropout=0., bn=False, y_range=None, **kwargs):\n",
    "    if kwargs: print(f'{kwargs}  not being used')\n",
    "    if concat_pool: n_in*=2\n",
    "    layers = [GACP1d(1) if concat_pool else GAP1d(1)]\n",
    "    layers += [LinBnDrop(n_in, c_out, bn=bn, p=fc_dropout)]\n",
    "    if y_range: layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "pool_head = create_pool_head\n",
    "average_pool_head = partial(pool_head, concat_pool=False)\n",
    "setattr(average_pool_head, \"__name__\", \"average_pool_head\")\n",
    "concat_pool_head = partial(pool_head, concat_pool=True)\n",
    "setattr(concat_pool_head, \"__name__\", \"concat_pool_head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): GACP1d(\n",
       "    (gacp): AdaptiveConcatPool1d(\n",
       "      (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool1d(output_size=1)\n",
       "    )\n",
       "    (flatten): Flatten(full=False)\n",
       "  )\n",
       "  (1): LinBnDrop(\n",
       "    (0): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=24, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_pool_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "test_eq(create_pool_head(nf, c_out, seq_len, concat_pool=True, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "create_pool_head(nf, c_out, seq_len, concat_pool=True, bn=True, fc_dropout=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def max_pool_head(n_in, c_out, seq_len, fc_dropout=0., bn=False, y_range=None, **kwargs):\n",
    "    if kwargs: print(f'{kwargs}  not being used')\n",
    "    layers = [nn.MaxPool1d(seq_len, **kwargs), Flatten()]\n",
    "    layers += [LinBnDrop(n_in, c_out, bn=bn, p=fc_dropout)]\n",
    "    if y_range: layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(max_pool_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_pool_plus_head(*args, lin_ftrs=None, fc_dropout=0., concat_pool=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    nf = args[0]\n",
    "    c_out = args[1]\n",
    "    if concat_pool: nf = nf * 2\n",
    "    lin_ftrs = [nf, 512, c_out] if lin_ftrs is None else [nf] + lin_ftrs + [c_out]\n",
    "    ps = L(fc_dropout)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool1d() if concat_pool else nn.AdaptiveAvgPool1d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], c_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "pool_plus_head = create_pool_plus_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool1d(\n",
       "    (ap): AdaptiveAvgPool1d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool1d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten(full=False)\n",
       "  (2): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25, inplace=False)\n",
       "  (4): Linear(in_features=24, out_features=512, bias=False)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_pool_plus_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "test_eq(create_pool_plus_head(nf, c_out, concat_pool=True, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "create_pool_plus_head(nf, c_out, seq_len, fc_dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_conv_head(*args, adaptive_size=None, y_range=None):\n",
    "    nf = args[0]\n",
    "    c_out = args[1]\n",
    "    layers = [nn.AdaptiveAvgPool1d(adaptive_size)] if adaptive_size is not None else []\n",
    "    for i in range(2):\n",
    "        if nf > 1: \n",
    "            layers += [ConvBlock(nf, nf // 2, 1)] \n",
    "            nf = nf//2\n",
    "        else: break\n",
    "    layers += [ConvBlock(nf, c_out, 1), GAP1d(1)]\n",
    "    if y_range: layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "conv_head = create_conv_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ConvBlock(\n",
       "    (0): Conv1d(12, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): ConvBlock(\n",
       "    (0): Conv1d(6, 3, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (2): ConvBlock(\n",
       "    (0): Conv1d(3, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (3): GAP1d(\n",
       "    (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "    (flatten): Flatten(full=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_conv_head(nf, c_out, seq_len)(t).shape, (bs, c_out))\n",
    "test_eq(create_conv_head(nf, c_out, adaptive_size=50)(t).shape, (bs, c_out))\n",
    "create_conv_head(nf, c_out, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mlp_head(nf, c_out, seq_len=None, flatten=True, fc_dropout=0., bn=False, y_range=None):\n",
    "    if flatten: nf *= seq_len\n",
    "    layers = [Flatten()] if flatten else []\n",
    "    layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]\n",
    "    if y_range: layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "mlp_head = create_mlp_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(full=False)\n",
       "  (1): LinBnDrop(\n",
       "    (0): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=240, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_mlp_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "create_mlp_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_fc_head(nf, c_out, seq_len=None, flatten=True, lin_ftrs=None, y_range=None, fc_dropout=0., bn=False, bn_final=False, act=nn.ReLU(inplace=True)):\n",
    "    if flatten: nf *= seq_len\n",
    "    layers = [Flatten()] if flatten else []\n",
    "    lin_ftrs = [nf, 512, c_out] if lin_ftrs is None else [nf] + lin_ftrs + [c_out]\n",
    "    if not is_listy(fc_dropout): fc_dropout = [fc_dropout]*(len(lin_ftrs) - 1)\n",
    "    actns = [act for _ in range(len(lin_ftrs) - 2)] + [None]\n",
    "    layers += [LinBnDrop(lin_ftrs[i], lin_ftrs[i+1], bn=bn and (i!=len(actns)-1 or bn_final), p=p, act=a) for i,(p,a) in enumerate(zip(fc_dropout+[0.], actns))]\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "fc_head = create_fc_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(full=False)\n",
       "  (1): LinBnDrop(\n",
       "    (0): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=240, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_fc_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "create_mlp_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_rnn_head(*args, fc_dropout=0., bn=False, y_range=None):\n",
    "    nf = args[0]\n",
    "    c_out = args[1]\n",
    "    layers = [LastStep()]\n",
    "    layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]\n",
    "    if y_range: layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "rnn_head = create_rnn_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LastStep()\n",
       "  (1): LinBnDrop(\n",
       "    (0): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=12, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "c_out = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(create_rnn_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))\n",
    "create_rnn_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def imputation_head(c_in, c_out, seq_len=None, ks=1, y_range=None, fc_dropout=0.):\n",
    "    layers = [nn.Dropout(fc_dropout), nn.Conv1d(c_in, c_out, ks)]\n",
    "    if y_range is not None: \n",
    "        y_range = (tensor(y_range[0]), tensor(y_range[1]))\n",
    "        layers += [SigmoidRange(*y_range)]\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.0, inplace=False)\n",
       "  (1): Conv1d(12, 2, kernel_size=(1,), stride=(1,))\n",
       "  (2): SigmoidRange(low=tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.2000, 0.2000, 0.2000, 0.3000,\n",
       "          0.3000, 0.3000, 0.3000]), high=tensor([0.6000, 0.6000, 0.6000, 0.6000, 0.7000, 0.7000, 0.7000, 0.7000, 0.8000,\n",
       "          0.8000, 0.8000, 0.8000]))\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "nf = 12\n",
    "ni = 2\n",
    "seq_len = 20\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=None, fc_dropout=0.)\n",
    "test_eq(head(t).shape, (bs, ni, seq_len))\n",
    "head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=(.3,.7), fc_dropout=0.)\n",
    "test_ge(head(t).min(), .3)\n",
    "test_le(head(t).max(), .7)\n",
    "y_range = (tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.2000, 0.2000, 0.2000, 0.3000,\n",
    "                   0.3000, 0.3000, 0.3000]),\n",
    "           tensor([0.6000, 0.6000, 0.6000, 0.6000, 0.7000, 0.7000, 0.7000, 0.7000, 0.8000,\n",
    "                   0.8000, 0.8000, 0.8000]))\n",
    "test_ge(head(t).min(), .1)\n",
    "test_le(head(t).max(), .9)\n",
    "head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=y_range, fc_dropout=0.)\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class create_conv_lin_3d_head(nn.Sequential):\n",
    "    \"Module to create a 3d output head\"\n",
    "\n",
    "    def __init__(self, n_in, n_out, seq_len, d=(), conv_first=True, conv_bn=True, lin_first=False, lin_bn=True, act=None, fc_dropout=0., **kwargs):\n",
    "\n",
    "        assert len(d) == 2, \"you must pass a tuple of len == 2 to create a 3d output\"\n",
    "        conv = [BatchNorm(n_in, ndim=1)] if conv_bn else []\n",
    "        conv.append(Conv1d(n_in, d[0], 1, padding=0, bias=not conv_bn, **kwargs))\n",
    "\n",
    "        l = [Transpose(-1, -2), BatchNorm(n_out if lin_first else seq_len, ndim=1), Transpose(-1, -2)] if lin_bn else []\n",
    "        if fc_dropout != 0: l.append(nn.Dropout(fc_dropout))\n",
    "\n",
    "        lin = [nn.Linear(seq_len, d[1], bias=not lin_bn)]\n",
    "        if act is not None: lin.append(act)\n",
    "\n",
    "        lin_layers = lin+l if lin_first else l+lin\n",
    "        layers = conv + lin_layers if conv_first else lin_layers + conv\n",
    "\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "conv_lin_3d_head = create_conv_lin_3d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_conv_lin_3d_head(\n",
       "  (0): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Conv1d(3, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  (2): Transpose(-1, -2)\n",
       "  (3): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Transpose(-1, -2)\n",
       "  (5): Linear(in_features=50, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(16, 3, 50)\n",
    "head = conv_lin_3d_head(3, 20, 50, (4,5))\n",
    "test_eq(head(t).shape, (16, 4, 5))\n",
    "head = conv_lin_3d_head(3, 20, 50, (2, 10))\n",
    "test_eq(head(t).shape, (16, 2, 10))\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class create_lin_3d_head(nn.Sequential):\n",
    "    \"Module to create a 3d output head with linear layers\"\n",
    "\n",
    "    def __init__(self, n_in, n_out, seq_len, d=(), lin_first=False, bn=True, act=None, fc_dropout=0.):\n",
    "\n",
    "        assert len(d) == 2, \"you must pass a tuple of len == 2 to create a 3d output\"\n",
    "        layers = [Flatten()]\n",
    "        layers += LinBnDrop(n_in * seq_len, n_out, bn=bn, p=fc_dropout, act=act, lin_first=lin_first)\n",
    "        layers += [Reshape(*d)]\n",
    "\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "lin_3d_head = create_lin_3d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_lin_3d_head(\n",
       "  (0): Flatten(full=False)\n",
       "  (1): BatchNorm1d(3200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Linear(in_features=3200, out_features=5, bias=False)\n",
       "  (3): Reshape(bs, 5, 1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(16, 64, 50)\n",
    "head = lin_3d_head(64, 10, 50, (5,2))\n",
    "test_eq(head(t).shape, (16, 5, 2))\n",
    "head = lin_3d_head(64, 5, 50, (5, 1))\n",
    "test_eq(head(t).shape, (16, 5, 1))\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class create_conv_3d_head(nn.Sequential):\n",
    "    \"Module to create a 3d output head with a convolutional layer\"\n",
    "    def __init__(self, n_in, c_out, seq_len, d=(), lin_first=False, bn=True, act=None, fc_dropout=0.):\n",
    "        assert len(d) == 2, \"you must pass a tuple of len == 2 to create a 3d output\"\n",
    "        assert d[1] == seq_len, 'You can only use this head when learn.dls.len == learn.dls.d'\n",
    "        super().__init__(Conv(n_in, d[0], 1))\n",
    "        \n",
    "conv_3d_head = create_conv_3d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "c_out = 4\n",
    "seq_len = 50\n",
    "d = (2,50)\n",
    "nf = 128\n",
    "t = torch.rand(bs, nf, seq_len)\n",
    "test_eq(conv_3d_head(nf, c_out, seq_len, d)(t).shape, (bs, *d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def universal_pool_head(n_in, c_out, seq_len, mult=2, pool_n_layers=2, pool_ln=True, pool_dropout=0.5, pool_act=nn.ReLU(),\n",
    "                        zero_init=True, bn=True, fc_dropout=0.):\n",
    "    return nn.Sequential(AdaptiveWeightedAvgPool1d(n_in, seq_len, n_layers=pool_n_layers, mult=mult, ln=pool_ln, dropout=pool_dropout, act=pool_act), \n",
    "                         Flatten(), LinBnDrop(n_in, c_out, p=fc_dropout, bn=bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, c_in, seq_len = 16, 128, 50\n",
    "c_out = 14\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "uph = universal_pool_head(c_in, c_out, seq_len)\n",
    "test_eq(uph(t).shape, (bs, c_out))\n",
    "uph = universal_pool_head(c_in, c_out, seq_len, 2)\n",
    "test_eq(uph(t).shape, (bs, c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "heads = [mlp_head, fc_head, average_pool_head, max_pool_head, concat_pool_head, pool_plus_head, conv_head, rnn_head, \n",
    "         conv_lin_3d_head, lin_3d_head, conv_3d_head, attentional_pool_head, universal_pool_head, gwa_pool_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_mlp_head\n",
      "create_fc_head\n",
      "average_pool_head\n",
      "max_pool_head\n",
      "concat_pool_head\n",
      "create_pool_plus_head\n",
      "create_conv_head\n",
      "create_rnn_head\n",
      "create_conv_lin_3d_head\n",
      "create_lin_3d_head\n",
      "create_conv_3d_head\n",
      "attentional_pool_head\n",
      "universal_pool_head\n",
      "gwa_pool_head\n"
     ]
    }
   ],
   "source": [
    "bs, c_in, seq_len = 16, 128, 50\n",
    "c_out = 14\n",
    "d = (7, 2)\n",
    "t = torch.rand(bs, c_in, seq_len)\n",
    "for head in heads: \n",
    "    print(head.__name__)\n",
    "    if head.__name__ == 'create_conv_3d_head': \n",
    "        test_eq(head(c_in, c_out, seq_len, (d[0], seq_len))(t).shape, (bs, *(d[0], seq_len)))\n",
    "    elif '3d' in head.__name__: \n",
    "        test_eq(head(c_in, c_out, seq_len, d)(t).shape, (bs, *d))\n",
    "    else: \n",
    "        test_eq(head(c_in, c_out, seq_len)(t).shape, (bs, c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SqueezeExciteBlock(Module):\n",
    "    def __init__(self, ni, reduction=16):\n",
    "        self.avg_pool = GAP1d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(ni, ni // reduction, bias=False), nn.ReLU(),  nn.Linear(ni // reduction, ni, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc(y).unsqueeze(2)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "ni = 32\n",
    "sl = 4\n",
    "t = torch.rand(bs, ni, sl)\n",
    "test_eq(SqueezeExciteBlock(ni)(t).shape, (bs, ni, sl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GaussianNoise(Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        self.sigma, self.is_relative_detach = sigma, is_relative_detach\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma not in [0, None]:\n",
    "            scale = self.sigma * (x.detach() if self.is_relative_detach else x)\n",
    "            sampled_noise = torch.empty(x.size()).normal_().to(device) * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(2,3,4)\n",
    "test_ne(GaussianNoise()(t), t)\n",
    "test_eq(GaussianNoise()(t).shape, t.shape)\n",
    "t = torch.ones(2,3)\n",
    "test_ne(GaussianNoise()(t), t)\n",
    "test_eq(GaussianNoise()(t).shape, t.shape)\n",
    "t = torch.ones(2)\n",
    "test_ne(GaussianNoise()(t), t)\n",
    "test_eq(GaussianNoise()(t).shape, t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gambler_loss(reward=2):\n",
    "    def _gambler_loss(model_output, targets):\n",
    "        outputs = torch.nn.functional.softmax(model_output, dim=1)\n",
    "        outputs, reservation = outputs[:, :-1], outputs[:, -1]\n",
    "        gain = torch.gather(outputs, dim=1, index=targets.unsqueeze(1)).squeeze()\n",
    "        doubling_rate = (gain + reservation / reward).log()\n",
    "        return - doubling_rate.mean()\n",
    "    return _gambler_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6411)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = torch.rand(16, 3)\n",
    "targets = torch.randint(0, 2, (16,))\n",
    "criterion = gambler_loss(2)\n",
    "criterion(model_output, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def CrossEntropyLossOneHot(output, target, **kwargs):\n",
    "    if target.ndim == 2: _, target = target.max(dim=1)\n",
    "    return nn.CrossEntropyLoss(**kwargs)(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7212)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.rand(16, 2)\n",
    "target = torch.randint(0, 2, (16,))\n",
    "CrossEntropyLossOneHot(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6211, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsai.data.transforms import OneHot\n",
    "output = nn.Parameter(torch.rand(16, 2))\n",
    "target = torch.randint(0, 2, (16,))\n",
    "one_hot_target = OneHot()(target)\n",
    "CrossEntropyLossOneHot(output, one_hot_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def proba_certainty(output):\n",
    "    if output.sum(-1).mean().item() != 1: output = F.softmax(output, -1)\n",
    "    return (output.max(-1).values - 1. / output.shape[-1])/( 1 - 1. / output.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4452, 0.3608, 0.6892, 0.9910, 0.8369, 0.2892, 0.8220, 0.3600, 0.9841,\n",
       "        0.2769, 0.5915, 0.6938, 0.9888, 0.9749, 0.6841, 0.9897],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "target = random_shuffle(concat(torch.zeros(5), torch.ones(7), torch.ones(4) + 1)).long()\n",
    "output = nn.Parameter(5 * torch.rand((16, 3)) - 5 * torch.rand((16, 3)))\n",
    "proba_certainty(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def CrossEntropyLossOneHotWithUncertainty():\n",
    "    def _CrossEntropyLossOneHotWithUncertainty(output, target, **kwargs):\n",
    "        return (proba_certainty(output) * CrossEntropyLossOneHot(output, target, reduction='none', **kwargs)).mean()\n",
    "    return _CrossEntropyLossOneHotWithUncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest_ind:            t = -1.5827  p = 0.118873\n",
      "ttest_ind_from_stats: t = -1.5827  p = 0.118873\n",
      "formula:              t = -1.5827  p = 0.118873\n",
      "formula:              t = -1.5827\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# https://stackoverflow.com/questions/22611446/perform-2-sample-t-test\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "from scipy.special import stdtr\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create sample data.\n",
    "a = np.random.randn(40)\n",
    "b = 4*np.random.randn(50)\n",
    "\n",
    "# Use scipy.stats.ttest_ind.\n",
    "t, p = ttest_ind(a, b, equal_var=False)\n",
    "print(\"ttest_ind:            t = %g  p = %g\" % (t, p))\n",
    "\n",
    "# Compute the descriptive statistics of a and b.\n",
    "abar = a.mean()\n",
    "avar = a.var(ddof=1)\n",
    "na = a.size\n",
    "adof = na - 1\n",
    "\n",
    "bbar = b.mean()\n",
    "bvar = b.var(ddof=1)\n",
    "nb = b.size\n",
    "bdof = nb - 1\n",
    "\n",
    "# Use scipy.stats.ttest_ind_from_stats.\n",
    "t2, p2 = ttest_ind_from_stats(abar, np.sqrt(avar), na,\n",
    "                              bbar, np.sqrt(bvar), nb,\n",
    "                              equal_var=False)\n",
    "print(\"ttest_ind_from_stats: t = %g  p = %g\" % (t2, p2))\n",
    "\n",
    "# Use the formulas directly.\n",
    "tf = (abar - bbar) / np.sqrt(avar/na + bvar/nb)\n",
    "dof = (avar/na + bvar/nb)**2 / (avar**2/(na**2*adof) + bvar**2/(nb**2*bdof))\n",
    "pf = 2*stdtr(dof, -np.abs(tf))\n",
    "\n",
    "print(\"formula:              t = %g  p = %g\" % (tf, pf))\n",
    "\n",
    "a = tensor(a)\n",
    "b = tensor(b)\n",
    "tf = (a.mean() - b.mean()) / torch.sqrt(a.var()/a.size(0) + b.var()/b.size(0))\n",
    "print(\"formula:              t = %g\" % (tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.5827)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_tensor(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ttest_bin_loss(output, target):\n",
    "    output = nn.Softmax(dim=-1)(output[:, 1])\n",
    "    return ttest_tensor(output[target == 0], output[target == 1])\n",
    "\n",
    "def ttest_reg_loss(output, target):\n",
    "    return ttest_tensor(output[target <= 0], output[target > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    output = torch.rand(256, 2)\n",
    "    target = torch.randint(0, 2, (256,))\n",
    "    test_close(ttest_bin_loss(output, target).item(), \n",
    "               ttest_ind(nn.Softmax(dim=-1)(output[:, 1])[target == 0], nn.Softmax(dim=-1)(output[:, 1])[target == 1], equal_var=False)[0], eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CenterLoss(Module):\n",
    "    r\"\"\"\n",
    "    Code in Pytorch has been slightly modified from: https://github.com/KaiyangZhou/pytorch-center-loss/blob/master/center_loss.py\n",
    "    Based on paper: Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
    "\n",
    "    Args:\n",
    "        c_out (int): number of classes.\n",
    "        logits_dim (int): dim 1 of the logits. By default same as c_out (for one hot encoded logits)\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, c_out, logits_dim=None):\n",
    "        logits_dim = ifnone(logits_dim, c_out)\n",
    "        self.c_out, self.logits_dim = c_out, logits_dim\n",
    "        self.centers = nn.Parameter(torch.randn(c_out, logits_dim).to(device=default_device()))\n",
    "        self.classes = torch.arange(c_out).long().to(device=default_device())\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, logits_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        bs = x.shape[0]\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(bs, self.c_out) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.c_out, bs).T\n",
    "        distmat = torch.addmm(distmat, x, self.centers.T, beta=1, alpha=-2)\n",
    "\n",
    "        labels = labels.unsqueeze(1).expand(bs, self.c_out)\n",
    "        mask = labels.eq(self.classes.expand(bs, self.c_out))\n",
    "\n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / bs\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class CenterPlusLoss(Module):\n",
    "    \n",
    "    def __init__(self, loss, c_out, λ=1e-2, logits_dim=None):\n",
    "        self.loss, self.c_out, self.λ = loss, c_out, λ\n",
    "        self.centerloss = CenterLoss(c_out, logits_dim)\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        return self.loss(x, labels) + self.λ * self.centerloss(x, labels)\n",
    "    def __repr__(self): return f\"CenterPlusLoss(loss={self.loss}, c_out={self.c_out}, λ={self.λ})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11.4214, grad_fn=<DivBackward0>),\n",
       " TensorBase(2.3296, grad_fn=<AliasBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in = 10\n",
    "x = torch.rand(64, c_in).to(device=default_device())\n",
    "x = F.softmax(x, dim=1)\n",
    "label = x.max(dim=1).indices\n",
    "CenterLoss(c_in)(x, label), CenterPlusLoss(LabelSmoothingCrossEntropyFlat(), c_in)(x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CenterPlusLoss(loss=FlattenedLoss of LabelSmoothingCrossEntropy(), c_out=10, λ=0.01)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CenterPlusLoss(LabelSmoothingCrossEntropyFlat(), c_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FocalLoss(Module):\n",
    "\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        self.gamma, self.eps, self.ce = gamma, eps, CrossEntropyLossFlat()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7463)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in = 10\n",
    "x = torch.rand(64, c_in).to(device=default_device())\n",
    "x = F.softmax(x, dim=1)\n",
    "label = x.max(dim=1).indices\n",
    "FocalLoss(c_in)(x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TweedieLoss(Module):\n",
    "    def __init__(self, p=1.5, eps=1e-10):\n",
    "        \"\"\"\n",
    "        Tweedie loss as calculated in LightGBM\n",
    "        Args:\n",
    "            p: tweedie variance power (1 < p < 2)\n",
    "            eps: small number to avoid log(zero).\n",
    "        \"\"\"\n",
    "        assert p > 1 and p < 2, \"make sure 1 < p < 2\"\n",
    "        self.p, self.eps = p, eps\n",
    "\n",
    "    def forward(self, inp, targ):\n",
    "        inp = inp.flatten()\n",
    "        targ = targ.flatten()\n",
    "        torch.clamp_min_(inp, self.eps)\n",
    "        a = targ * torch.exp((1 - self.p) * torch.log(inp)) / (1 - self.p)\n",
    "        b = torch.exp((2 - self.p) * torch.log(inp)) / (2 - self.p)\n",
    "        loss = -a + b\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1643)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in = 10\n",
    "output = torch.rand(64).to(device=default_device())\n",
    "target = torch.rand(64).to(device=default_device())\n",
    "TweedieLoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GEGLU(Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim=-1)\n",
    "        return x * F.gelu(gates)\n",
    "\n",
    "\n",
    "class ReGLU(Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim=-1)\n",
    "        return x * F.relu(gates)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Sequential): \n",
    "    def __init__(self, dim, dropout=0., act='reglu'):\n",
    "        act = act.lower()\n",
    "        act_mult = 2 if act in ['geglu', 'reglu'] else 1\n",
    "        if act == 'relu': act_fn = nn.ReLU()\n",
    "        elif act == 'gelu': act_fn = nn.GELU()\n",
    "        elif act == 'geglu': act_fn = GEGLU()\n",
    "        else: act_fn = ReGLU()\n",
    "        super().__init__(nn.Linear(dim, dim * act_mult), \n",
    "                         act_fn, \n",
    "                         nn.Dropout(dropout), \n",
    "                         nn.Linear(dim, dim), \n",
    "                         nn.Dropout(dropout))\n",
    "\n",
    "\n",
    "class TokenLayer(Module):\n",
    "    def __init__(self, token=True): self.token = token\n",
    "    def forward(self, x): return x[..., 0] if self.token is not None else x.mean(-1)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ScaledDotProductAttention(Module):\n",
    "    \"\"\"Scaled Dot-Product Attention module (Vaswani et al., 2017) with optional residual attention from previous layer (He et al, 2020)\"\"\"\n",
    "\n",
    "    def __init__(self, res_attention:bool=False):  self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "\n",
    "        Output shape: \n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q / np.sqrt(q.shape[-2]), k)      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev \n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [q_len x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.7253e-12, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5044, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 16\n",
    "C = 10\n",
    "M = 1500 # seq_len\n",
    "\n",
    "n_heads = 1\n",
    "D = 128 # model dimension\n",
    "N = 512 # max_seq_len - latent's index dimension\n",
    "d_k = D // n_heads\n",
    "\n",
    "xb = torch.randn(B, C, M)\n",
    "xb = (xb - xb.mean()) / xb.std()\n",
    "\n",
    "# Attention\n",
    "# input (Q)\n",
    "lin = nn.Linear(M, N, bias=False)\n",
    "Q = lin(xb).transpose(1,2)\n",
    "test_eq(Q.shape, (B, N, C))\n",
    "\n",
    "# q\n",
    "to_q = nn.Linear(C, D, bias=False)\n",
    "q = to_q(Q)\n",
    "q = nn.LayerNorm(D)(q)\n",
    "\n",
    "# k, v\n",
    "context = xb.transpose(1,2)\n",
    "to_kv = nn.Linear(C, D * 2, bias=False)\n",
    "k, v = to_kv(context).chunk(2, dim = -1)\n",
    "k = k.transpose(-1, -2)\n",
    "k = nn.LayerNorm(M)(k)\n",
    "v = nn.LayerNorm(D)(v)\n",
    "\n",
    "test_eq(q.shape, (B, N, D))\n",
    "test_eq(k.shape, (B, D, M))\n",
    "test_eq(v.shape, (B, M, D))\n",
    "\n",
    "output, attn, scores = ScaledDotProductAttention(res_attention=True)(q.unsqueeze(1), k.unsqueeze(1), v.unsqueeze(1))\n",
    "test_eq(output.shape, (B, 1, N, D))\n",
    "test_eq(attn.shape, (B, 1, N, M))\n",
    "test_eq(scores.shape, (B, 1, N, M))\n",
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MultiheadAttention(Module):\n",
    "    def __init__(self, d_model:int, n_heads:int, d_k:Optional[int]=None, d_v:Optional[int]=None, res_attention:bool=False, dropout:float=0.):\n",
    "        \"\"\"Multi Head Attention Layer\n",
    "        \n",
    "        Input shape:  \n",
    "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
    "            K, V:    [batch_size (bs) x q_len x d_model]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        \n",
    "        d_k = ifnone(d_k, d_model // n_heads)\n",
    "        d_v = ifnone(d_v, d_model // n_heads)\n",
    "        \n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        self.sdp_attn = ScaledDotProductAttention(res_attention=self.res_attention)\n",
    "\n",
    "        # Poject output\n",
    "        project_out = not (n_heads == 1 and d_model == d_k)\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(dropout)) if project_out else nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None, \n",
    "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights                                                  # output: [bs x q_len x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_mask torch.Size([50, 50]) key_padding_mask torch.Size([16, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 50, 6]), torch.Size([16, 3, 50, 50]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.rand([16, 3, 50, 8]) \n",
    "k = torch.rand([16, 3, 50, 8]).transpose(-1, -2)\n",
    "v = torch.rand([16, 3, 50, 6])\n",
    "attn_mask = torch.triu(torch.ones(50, 50)) # shape: q_len x q_len\n",
    "key_padding_mask = torch.zeros(16, 50)\n",
    "key_padding_mask[[1, 3, 6, 15], -10:] = 1\n",
    "key_padding_mask = key_padding_mask.bool()\n",
    "print('attn_mask', attn_mask.shape, 'key_padding_mask', key_padding_mask.shape)\n",
    "output, attn = ScaledDotProductAttention()(q, k, v, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "output.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 50, 128]), torch.Size([16, 3, 50, 50]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "output, attn = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)(t, t, t, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "output.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "att_mask = (torch.rand((50, 50)) > .85).float()\n",
    "att_mask[att_mask == 1] = -np.inf\n",
    "\n",
    "mha = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)\n",
    "output, attn = mha(t, t, t, attn_mask=att_mask)\n",
    "test_eq(torch.isnan(output).sum().item(), 0)\n",
    "test_eq(torch.isnan(attn).sum().item(), 0)\n",
    "loss = output[:2, :].sum()\n",
    "test_eq(torch.isnan(loss).sum().item(), 0)\n",
    "loss.backward()\n",
    "for n, p in mha.named_parameters(): test_eq(torch.isnan(p.grad).sum().item(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "attn_mask = (torch.rand((50, 50)) > .85)\n",
    "\n",
    "# True values will be masked\n",
    "mha = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)\n",
    "output, attn = mha(t, t, t, attn_mask=att_mask)\n",
    "test_eq(torch.isnan(output).sum().item(), 0)\n",
    "test_eq(torch.isnan(attn).sum().item(), 0)\n",
    "loss = output[:2, :].sum()\n",
    "test_eq(torch.isnan(loss).sum().item(), 0)\n",
    "loss.backward()\n",
    "for n, p in mha.named_parameters(): test_eq(torch.isnan(p.grad).sum().item(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 000c_data.preparation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 002b_data.unwindowed.ipynb.\n",
      "Converted 002c_data.metadatasets.ipynb.\n",
      "Converted 003_data.preprocessing.ipynb.\n",
      "Converted 003b_data.transforms.ipynb.\n",
      "Converted 003c_data.mixed_augmentation.ipynb.\n",
      "Converted 003d_data.image.ipynb.\n",
      "Converted 003e_data.features.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 050_losses.ipynb.\n",
      "Converted 051_metrics.ipynb.\n",
      "Converted 052_learner.ipynb.\n",
      "Converted 052b_tslearner.ipynb.\n",
      "Converted 053_optimizer.ipynb.\n",
      "Converted 060_callback.core.ipynb.\n",
      "Converted 061_callback.noisy_student.ipynb.\n",
      "Converted 062_callback.gblend.ipynb.\n",
      "Converted 063_callback.MVP.ipynb.\n",
      "Converted 064_callback.PredictionDynamics.ipynb.\n",
      "Converted 100_models.layers.ipynb.\n",
      "Converted 100b_models.utils.ipynb.\n",
      "Converted 100c_models.explainability.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.MLP.ipynb.\n",
      "Converted 103b_models.FCN.ipynb.\n",
      "Converted 103c_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 108c_models.TSTPlus.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 111b_models.MINIROCKET.ipynb.\n",
      "Converted 111c_models.MINIROCKET_Pytorch.ipynb.\n",
      "Converted 111d_models.MINIROCKETPlus_Pytorch.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 113_models.TCN.ipynb.\n",
      "Converted 114_models.XCM.ipynb.\n",
      "Converted 114b_models.XCMPlus.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 121_models.TabTransformer.ipynb.\n",
      "Converted 122_models.TabFusionTransformer.ipynb.\n",
      "Converted 123_models.TSPerceiver.ipynb.\n",
      "Converted 124_models.TSTransformerPlus.ipynb.\n",
      "Converted 130_models.MultiInputNet.ipynb.\n",
      "Converted 140_models.misc.ipynb.\n",
      "Converted 900_tutorials.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/tsai/tsai\n",
      "Correct conversion! 😃\n",
      "Total time elapsed 502 s\n",
      "Friday 16/07/21 17:50:32 CEST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
