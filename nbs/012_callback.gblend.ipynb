{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callback.gblend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Blending\n",
    "\n",
    "> Callback used to apply gradient blending to multi-modal models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unofficial PyTorch implementation by Ignacio Oguiza (timeseriesAI@gmail.com) based on: Wang, W., Tran, D., & Feiszli, M. (2020). **What Makes Training Multi-Modal Classification Networks Hard?**. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12695-12705)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.preprocessing import *\n",
    "from tsai.data.transforms import *\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GBlendLoss(Module):\n",
    "    \"Wrapper loss used by the gradient blending callback to allow weights applied to each modality.\"\n",
    "\n",
    "    def __init__(self, crit=None, w=None):\n",
    "        self.crit = ifnone(crit, CrossEntropyLossFlat())\n",
    "        self.w = w\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        # unweighted loss\n",
    "        if not is_listy(preds): return self.crit(preds, target)\n",
    "        \n",
    "        # weighted loss\n",
    "        if self.w is None: self.w = tensor([1.] * len(preds))\n",
    "        loss = 0\n",
    "        for i, pred in enumerate(preds): loss += self.crit(pred, target) * self.w[i]\n",
    "        return loss / sum(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GBlend(Callback):\n",
    "    r\"\"\"A callback to implement multi-modal gradient blending.\n",
    "    \n",
    "    This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@gmail.com based on: Wang, W., Tran, D., & Feiszli, M. (2020). \n",
    "    What Makes Training Multi-Modal Classification Networks Hard?. In Proceedings of the IEEE/CVF Conference on Computer Vision and \n",
    "    Pattern Recognition (pp. 12695-12705).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, V_pct=.1, n:Union[None, int, tuple, list]=(10, 5), sel_metric:Optional[str]=None, show_plot:bool=False, path:str='./data/gblend'): \n",
    "        \n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            V_pct      : subset of train where OGR will be measured (to estimate L*)\n",
    "            n          : None: offline learning, int: super-epoch (online learning), tuple: (warmup super-epoch, super-epoch)(online learning with warm up)\n",
    "            sel_metric : which metric will be used to calculate overfitting and generalization during training. If None, loss will be used.\n",
    "            show_plot  : will show a plot with the wieghts at the end of training\n",
    "        \"\"\"\n",
    "        assert V_pct < 1, 'V_pct must be < 1'\n",
    "        self.V_pct, self.n, self.sel_metric, self.show_plot = V_pct, n, sel_metric, show_plot\n",
    "        self.metric_idx = None\n",
    "        self.path = Path(path)\n",
    "        if not os.path.exists(self.path): os.makedirs(self.path)\n",
    "\n",
    "    def before_fit(self):\n",
    "        \n",
    "        # model\n",
    "        self.M = self.model.M \n",
    "        self.old_multi_output = self.learn.model.multi_output\n",
    "        self.learn.model.multi_output = True\n",
    "\n",
    "        #loss\n",
    "        if cls_name(self.learn.loss_func) != 'GBlendLoss': self.learn.loss_func = GBlendLoss(crit=self.learn.loss_func)\n",
    "\n",
    "        # calculate super_epochs\n",
    "        if self.n is None: \n",
    "            self.super_epochs = [0]\n",
    "        else: \n",
    "            if is_listy(self.n): \n",
    "                self.wu_n = self.n[0]\n",
    "                self.n = self.n[1]\n",
    "            else: \n",
    "                self.wu_n = self.n\n",
    "            rng = range(int(max(0, self.n_epoch - self.wu_n) / self.n + 1))\n",
    "            self.super_epochs = []\n",
    "            for i in rng: \n",
    "                self.super_epochs.append((i * self.wu_n) if i <= 1 else int((i + self.wu_n / self.n - 1) * self.n))\n",
    "        self.super_epochs.append(self.n_epoch)\n",
    "        \n",
    "        # create T'(Tp) and V dataloaders\n",
    "        n_out = len(self.learn.dls.train.dataset.ptls) - self.learn.dls.train.dataset.n_inp\n",
    "        train_targets = self.learn.dls.train.dataset.ptls[-n_out]\n",
    "        Tp_idx, V_idx = get_splits(train_targets, valid_size=self.V_pct)\n",
    "        _Tp_train_dls = []\n",
    "        _V_train_dls = []\n",
    "        self.learn.new_dls = []\n",
    "        for dl in self.learn.dls[0].loaders: # train MixedDataLoaders\n",
    "            _Tp_dl = get_subset_dl(dl, Tp_idx)\n",
    "            _V_dl = get_subset_dl(dl, V_idx)\n",
    "            _Tp_train_dls.append(_Tp_dl)\n",
    "            _V_train_dls.append(_V_dl) \n",
    "            self.learn.new_dls.append(DataLoaders(_Tp_dl, _V_dl, device=self.learn.dls.device))\n",
    "        self.learn.new_dls.append(MixedDataLoaders(MixedDataLoader(*_Tp_train_dls, shuffle=True),  # train - train\n",
    "                                                   MixedDataLoader(*_V_train_dls, shuffle=False),  # train - valid\n",
    "                                                   device=self.learn.dls.device))\n",
    "        \n",
    "        # prepare containers\n",
    "        self.learn.LT = []\n",
    "        self.learn.LV = []\n",
    "\n",
    "    def before_train(self):\n",
    "        if self.epoch in self.super_epochs[:-1] and not 'LRFinder' in [cls_name(cb) for cb in self.learn.cbs]: \n",
    "            self.train_epochs = np.diff(self.super_epochs)[self.super_epochs.index(self.epoch)]\n",
    "            \n",
    "            #compute weights\n",
    "            self.learn.save('gblend_learner')\n",
    "            torch.save(self.learn.model, self.path/'gblend_model')\n",
    "            w = self.compute_weights()\n",
    "            if self.epoch == 0: self.learn.ws = [w]\n",
    "            else: self.learn.ws.append(w)\n",
    "            self.learn = self.learn.load('gblend_learner')\n",
    "            self.learn.loss_func.w = w\n",
    "\n",
    "    def compute_weights(self):\n",
    "\n",
    "        # _LT0 = []\n",
    "        # _LV0 = []\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        for i in range(self.M + 1):            \n",
    "            model = torch.load(self.path/'gblend_model')\n",
    "            learn = Learner(self.learn.new_dls[i], model.m[i], loss_func=GBlendLoss(), \n",
    "                            opt_func=self.learn.opt_func, metrics=self.learn.metrics)\n",
    "            learn.model.multi_output = False\n",
    "            learn.remove_cbs(learn.cbs[1])\n",
    "            learn.add_cb(Recorder(train_metrics=True))\n",
    "            with learn.no_bar():\n",
    "                with learn.no_logging(): \n",
    "                    learn.fit_one_cycle(self.train_epochs, pct_start=0)\n",
    "            if self.metric_idx is None and self.sel_metric is not None:\n",
    "                metric_names = learn.recorder.metric_names[1:-1]\n",
    "                self.metric_idx = [i for i,m in enumerate(metric_names) if self.sel_metric in m]\n",
    "            else: self.metric_idx = [0, 1]\n",
    "            metric_values = learn.recorder.values[-1][self.metric_idx]\n",
    "            _LT.append(metric_values[0])\n",
    "            _LV.append(metric_values[1])\n",
    "\n",
    "        # if self.epoch == 0: self.compute_previous_metrics()\n",
    "        self.compute_previous_metrics()\n",
    "        self.learn.LT.append(_LT)\n",
    "        self.learn.LV.append(_LV)\n",
    "\n",
    "        LT1 = array(self.learn.LT[-2])\n",
    "        LT2 = array(self.learn.LT[-1])\n",
    "        LV1 = array(self.learn.LV[-2])\n",
    "        LV2 = array(self.learn.LV[-1])\n",
    "\n",
    "        ΔG = (LV1 - LV2) if self.metric_idx[0] == 0 else (LV2 - LV1)\n",
    "        O1 = (LV1 - LT1) if self.metric_idx[0] == 0 else (LT1 - LV1)\n",
    "        O2 = (LV2 - LT2) if self.metric_idx[0] == 0 else (LT2 - LV2)\n",
    "\n",
    "        ΔG = np.maximum(0, ΔG)\n",
    "\n",
    "        ΔO = O2 - O1\n",
    "        ΔO2 = np.maximum(1e-8, (O2 - O1)**2)\n",
    "        w = np.maximum(1e-8, np.nan_to_num(ΔG / ΔO2))\n",
    "        w = w / w.sum()\n",
    "        w = w.tolist()\n",
    "        return w\n",
    "\n",
    "    def compute_previous_metrics(self):\n",
    "        if self.metric_idx[0] == 0:  metric = self.loss_func\n",
    "        else: metric = self.learn.metrics[(min(array(self.metric_idx) - 2) - 1) // 2]\n",
    "        _LT = []\n",
    "        _LV = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.M + 1):\n",
    "                model = torch.load(self.path/'gblend_model')\n",
    "                model.multi_output = False\n",
    "                model = model.m[i]\n",
    "                _train_metrics = []\n",
    "                _valid_metrics = []\n",
    "                for j,dl in enumerate(self.learn.new_dls[i]):\n",
    "                    it = iter(dl)\n",
    "                    _preds = []\n",
    "                    _targets = []\n",
    "                    for b in it: \n",
    "                        _preds.extend(model(*b[:-1]))\n",
    "                        _targets.extend(b[-1])\n",
    "                    _preds, _targets = stack(_preds), stack(_targets)\n",
    "                    try: _metric_values = metric(_preds, _targets).cpu().item()\n",
    "                    except: _metric_values = metric(torch.argmax(_preds, 1), _targets).cpu().item()\n",
    "                    if j == 0: _LT.append(_metric_values)\n",
    "                    else: _LV.append(_metric_values)\n",
    "            self.learn.LT.append(_LT)\n",
    "            self.learn.LV.append(_LV)\n",
    "\n",
    "    def after_fit(self):\n",
    "        if hasattr(self.learn, \"ws\") and self.show_plot:\n",
    "            widths = np.diff(self.super_epochs)\n",
    "            cum_ws = 0\n",
    "            for i in range(self.M + 1):\n",
    "                plt.bar(self.super_epochs[:-1] + widths/2, stack(self.learn.ws)[:, i], bottom=cum_ws, width=widths, \n",
    "                        label=f'k={i+1}' if i < self.M else f'fused')\n",
    "                cum_ws += stack(self.learn.ws)[:, i]\n",
    "            plt.xlim(0, self.super_epochs[-1])\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(self.super_epochs)\n",
    "            plt.legend(loc='best')\n",
    "            plt.title('Online G-Blend Weights by modality')\n",
    "            plt.show()\n",
    "\n",
    "        self.learn.model.multi_output = self.old_multi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import *\n",
    "from tsai.data.all import *\n",
    "from tsai.models.utils import *\n",
    "from tsai.models.XCM import *\n",
    "from tsai.models.TabModel import *\n",
    "from tsai.models.MultiInputNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:05<00:00,  7.22it/s]\n"
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "ts_features_df = get_ts_features(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Sequential' object has no attribute 'head_nf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-14c968530315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# mixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmixed_dls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mixed_dls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_dls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab_dls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mMultiModalNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiInputNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmixed_dls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mgblend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBlend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_pct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_dls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRocAuc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgblend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Machine_Learning/Jupyter_Notebooks/tsai/nbs/tsai/models/MultiInputNet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c_out, reshape_fn, multi_output, custom_head, device, *models, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mhead_nf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_nf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mmin_nf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_nf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_nf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'Sequential' object has no attribute 'head_nf'"
     ]
    }
   ],
   "source": [
    "# raw ts\n",
    "tfms  = [None, [Categorize()]]\n",
    "batch_tfms = TSStandardize()\n",
    "ts_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "ts_model = build_ts_model(XCM, dls=ts_dls, window_perc=.5)\n",
    "\n",
    "# ts features\n",
    "cat_names = None\n",
    "cont_names = ts_features_df.columns[:-2]\n",
    "y_names = 'target'\n",
    "tab_dls = get_tabular_dls(ts_features_df, cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)\n",
    "tab_model = build_tabular_model(TabModel, dls=tab_dls)\n",
    "\n",
    "# mixed\n",
    "mixed_dls = get_mixed_dls(ts_dls, tab_dls)\n",
    "MultiModalNet = MultiInputNet(ts_model, tab_model, c_out=mixed_dls.c)\n",
    "gblend = GBlend(V_pct=.5, n=(10, 5), sel_metric=None)\n",
    "learn = Learner(mixed_dls, MultiModalNet, metrics=[accuracy, RocAuc()], cbs=gblend)\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
