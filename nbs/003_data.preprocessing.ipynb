{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "> Functions used to preprocess time series (both X and y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.external import *\n",
    "from tsai.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'NATOPS'\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "tfms = [None, Categorize()]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToNumpyCategory(Transform):\n",
    "    \"Categorize a numpy batch\"\n",
    "    order = 90\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def encodes(self, o: np.ndarray):\n",
    "        self.type = type(o)\n",
    "        self.cat = Categorize()\n",
    "        self.cat.setup(o)\n",
    "        self.vocab = self.cat.vocab\n",
    "        return np.asarray(stack([self.cat(oi) for oi in o]))\n",
    "\n",
    "    def decodes(self, o: (np.ndarray, torch.Tensor)):\n",
    "        return stack([self.cat.decode(oi) for oi in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 3, 2, 4, 0, 5, 2, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ToNumpyCategory()\n",
    "y_cat = t(y)\n",
    "y_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.decode(tensor(y_cat)), y)\n",
    "test_eq(t.decode(np.array(y_cat)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OneHot(Transform): \n",
    "    \"One-hot encode/ decode a batch\"\n",
    "    order = 90\n",
    "    def __init__(self, n_classes=None, **kwargs): \n",
    "        self.n_classes = n_classes\n",
    "        super().__init__(**kwargs)\n",
    "    def encodes(self, o: torch.Tensor): \n",
    "        if not self.n_classes: self.n_classes = len(np.unique(o))\n",
    "        return torch.eye(self.n_classes)[o]\n",
    "    def encodes(self, o: np.ndarray): \n",
    "        o = ToNumpyCategory()(o)\n",
    "        if not self.n_classes: self.n_classes = len(np.unique(o))\n",
    "        return np.eye(self.n_classes)[o]\n",
    "    def decodes(self, o: torch.Tensor): return torch.argmax(o, dim=-1)\n",
    "    def decodes(self, o: np.ndarray): return np.argmax(o, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_encoder = OneHot()\n",
    "y_cat = ToNumpyCategory()(y)\n",
    "oht = oh_encoder(y_cat)\n",
    "oht[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = 100\n",
    "\n",
    "t = torch.randint(0, n_classes, (n_samples,))\n",
    "oh_encoder = OneHot()\n",
    "oht = oh_encoder(t)\n",
    "test_eq(oht.shape, (n_samples, n_classes))\n",
    "test_eq(torch.argmax(oht, dim=-1), t)\n",
    "test_eq(oh_encoder.decode(oht), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = 100\n",
    "\n",
    "a = np.random.randint(0, n_classes, (n_samples,))\n",
    "oh_encoder = OneHot()\n",
    "oha = oh_encoder(a)\n",
    "test_eq(oha.shape, (n_samples, n_classes))\n",
    "test_eq(np.argmax(oha, axis=-1), a)\n",
    "test_eq(oh_encoder.decode(oha), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSStandardize(Transform):\n",
    "    \"Standardizes batch of type `TSTensor`\"\n",
    "    parameters, order = L('mean', 'std'), 90\n",
    "    def __init__(self, mean=None, std=None, by_sample=False, by_var=False, by_step=False, eps=1e-8, verbose=False):\n",
    "        self.mean = tensor(mean) if mean is not None else None\n",
    "        self.std = tensor(std) if std is not None else None\n",
    "        self.eps = eps\n",
    "        self.by_sample, self.by_var, self.by_step = by_sample, by_var, by_step\n",
    "        drop_axes = []\n",
    "        if by_sample: drop_axes.append(0)\n",
    "        if by_var: drop_axes.append(1)\n",
    "        if by_step: drop_axes.append(2)\n",
    "        self.axes = tuple([ax for ax in (0, 1, 2) if ax not in drop_axes])\n",
    "        self.verbose = verbose\n",
    "        if self.mean is not None or self.std is not None:\n",
    "            pv(f'{self.__class__.__name__} mean={self.mean}, std={self.std}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n', self.verbose)\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std): return cls(mean, std)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x, *_ = dl.one_batch()\n",
    "            self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + self.eps\n",
    "            if len(self.mean.shape) == 0:\n",
    "                pv(f'{self.__class__.__name__} mean={self.mean}, std={self.std}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n',\n",
    "                   self.verbose)\n",
    "            else:\n",
    "                pv(f'{self.__class__.__name__} mean shape={self.mean.shape}, std shape={self.std.shape}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n',\n",
    "                   self.verbose)\n",
    "\n",
    "    def encodes(self, o:TSTensor):\n",
    "        if self.by_sample: self.mean, self.std = o.mean(self.axes, keepdim=self.axes!=()), o.std(self.axes, keepdim=self.axes!=()) + self.eps\n",
    "        return (o - self.mean) / self.std\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def mul_min(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.min(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    min_x = x\n",
    "    for ax in axes: min_x, _ = min_x.min(ax, keepdim)\n",
    "    return retain_type(min_x, x)\n",
    "\n",
    "\n",
    "@patch\n",
    "def mul_max(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.max(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    max_x = x\n",
    "    for ax in axes: max_x, _ = max_x.max(ax, keepdim)\n",
    "    return retain_type(max_x, x)\n",
    "\n",
    "\n",
    "class TSNormalize(Transform):\n",
    "    \"Normalizes batch of type `TSTensor`\"\n",
    "    parameters, order = L('min', 'max'), 90\n",
    "\n",
    "    def __init__(self, min=None, max=None, range=(-1, 1), by_sample=False, by_var=False, by_step=False, verbose=False):\n",
    "        self.min = tensor(min) if min is not None else None\n",
    "        self.max = tensor(max) if max is not None else None\n",
    "        self.range_min, self.range_max = range\n",
    "        self.by_sample, self.by_var, self.by_step = by_sample, by_var, by_step\n",
    "        drop_axes = []\n",
    "        if by_sample: drop_axes.append(0)\n",
    "        if by_var: drop_axes.append(1)\n",
    "        if by_step: drop_axes.append(2)\n",
    "        self.axes = tuple([ax for ax in (0, 1, 2) if ax not in drop_axes])\n",
    "        self.verbose = verbose\n",
    "        if self.min is not None or self.max is not None:\n",
    "            pv(f'{self.__class__.__name__} min={self.min}, max={self.max}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n', self.verbose)\n",
    "            \n",
    "    @classmethod\n",
    "    def from_stats(cls, min, max, range_min=0, range_max=1): return cls(min, max, self.range_min, self.range_max)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.min is None or self.max is None:\n",
    "            x, *_ = dl.one_batch()\n",
    "            self.min, self.max = x.mul_min(self.axes, keepdim=self.axes!=()), x.mul_max(self.axes, keepdim=self.axes!=())\n",
    "            if len(self.min.shape) == 0: \n",
    "                pv(f'{self.__class__.__name__} min={self.min}, max={self.max}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n', self.verbose)\n",
    "            else:\n",
    "                pv(f'{self.__class__.__name__} min shape={self.min.shape}, max shape={self.max.shape}, by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step}\\n', \n",
    "                   self.verbose)\n",
    "\n",
    "    def encodes(self, o:TSTensor): \n",
    "        if self.by_sample: self.min, self.max = o.mul_min(self.axes, keepdim=self.axes!=()), o.mul_max(self.axes, keepdim=self.axes!=())\n",
    "        return torch.clamp(((o - self.min) / (self.max - self.min)) * (self.range_max - self.range_min) + self.range_min, \n",
    "                           self.range_min, self.range_max)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__}(by_sample={self.by_sample}, by_var={self.by_var}, by_step={self.by_step})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSStandardize mean shape=(128, 1, 1), std shape=(128, 1, 1), by_sample=True, by_var=False, by_step=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_tfms=[TSStandardize(by_sample=True, by_var=False, verbose=True)]\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTensor(samples:128, vars:24, len:51)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSStandardize(by_sample=True, verbose=True)(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms=[TSStandardize(by_sample=True, by_var=False, verbose=False)]\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)\n",
    "xb, yb = next(iter(dls.valid))\n",
    "test_close(xb.mean(), 0, eps=1e-1)\n",
    "test_close(xb.std(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms=[TSNormalize(by_sample=True, by_var=False, verbose=False)]\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "assert xb.max() <= 1\n",
    "assert xb.min() >= -1\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)\n",
    "xb, yb = next(iter(dls.valid))\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSClipOutliers(Transform):\n",
    "    \"Clip outliers batch of type `TSTensor` based on the IQR\"\n",
    "    parameters, order = L('min', 'max'), 90\n",
    "    def __init__(self, min=None, max=None, by_sample=False, by_var=False, verbose=False):\n",
    "        self.su = (min is None or max is None) and not by_sample \n",
    "        self.min = tensor(min) if min is not None else tensor(-np.inf)\n",
    "        self.max = tensor(max) if max is not None else tensor(np.inf)\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axis = (2)\n",
    "        elif by_sample: self.axis = (1, 2)\n",
    "        elif by_var: self.axis = (0, 2)\n",
    "        else: self.axis = None\n",
    "        self.verbose = verbose\n",
    "        if min is not None or max is not None:\n",
    "            pv(f'{self.__class__.__name__} min={min}, max={max}\\n', self.verbose)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.su:\n",
    "            o, *_ = dl.one_batch()\n",
    "            min, max = get_outliers_IQR(o, self.axis)\n",
    "            self.min, self.max = tensor(min), tensor(max)\n",
    "            if self.axis is None: pv(f'{self.__class__.__name__} min={self.min}, max={self.max}, by_sample={self.by_sample}, by_var={self.by_var}\\n', \n",
    "                                     self.verbose)\n",
    "            else: pv(f'{self.__class__.__name__} min={self.min.shape}, max={self.max.shape}, by_sample={self.by_sample}, by_var={self.by_var}\\n', \n",
    "                     self.verbose)\n",
    "            self.su = False\n",
    "            \n",
    "    def encodes(self, o:TSTensor):\n",
    "        if self.axis is None: return torch.clamp(o, self.min, self.max)\n",
    "        elif self.by_sample: \n",
    "            min, max = get_outliers_IQR(o, axis=self.axis)\n",
    "            self.min, self.max = o.new(min), o.new(max)\n",
    "        return torch_clamp(o, self.min, self.max)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__}(by_sample={self.by_sample}, by_var={self.by_var})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSClipOutliers min=-1, max=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_tfms=[TSClipOutliers(-1, 1, verbose=True)]\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, after_batch=batch_tfms)\n",
    "xb, yb = next(iter(dls.train))\n",
    "assert xb.max() <= 1\n",
    "assert xb.min() >= -1\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)\n",
    "xb, yb = next(iter(dls.valid))\n",
    "test_close(xb.min(), -1, eps=1e-1)\n",
    "test_close(xb.max(), 1, eps=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSRobustScale(Transform):\n",
    "    r\"\"\"This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range)\"\"\"\n",
    "    parameters, order = L('median', 'min', 'max'), 90\n",
    "    def __init__(self, median=None, min=None, max=None, by_sample=False, by_var=False, verbose=False):\n",
    "        self.su = (median is None or min is None or max is None) and not by_sample \n",
    "        self.median = tensor(median) if median is not None else tensor(0)\n",
    "        self.min = tensor(min) if min is not None else tensor(-np.inf)\n",
    "        self.max = tensor(max) if max is not None else tensor(np.inf)\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axis = (2)\n",
    "        elif by_sample: self.axis = (1, 2)\n",
    "        elif by_var: self.axis = (0, 2)\n",
    "        else: self.axis = None\n",
    "        self.verbose = verbose\n",
    "        if median is not None or min is not None or max is not None:\n",
    "            pv(f'{self.__class__.__name__} median={median} min={min}, max={max}\\n', self.verbose)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.su:\n",
    "            o, *_ = dl.one_batch()\n",
    "            median = get_percentile(o, 50, self.axis)\n",
    "            min, max = get_outliers_IQR(o, self.axis)\n",
    "            self.median, self.min, self.max = tensor(median), tensor(min), tensor(max)\n",
    "            if self.axis is None: pv(f'{self.__class__.__name__} median={self.median} min={self.min}, max={self.max}, by_sample={self.by_sample}, by_var={self.by_var}\\n', \n",
    "                                     self.verbose)\n",
    "            else: pv(f'{self.__class__.__name__} median={self.median.shape} min={self.min.shape}, max={self.max.shape}, by_sample={self.by_sample}, by_var={self.by_var}\\n', \n",
    "                     self.verbose)\n",
    "            self.su = False\n",
    "            \n",
    "    def encodes(self, o:TSTensor):\n",
    "        if self.by_sample: \n",
    "            median = get_percentile(o, 50, self.axis)\n",
    "            min, max = get_outliers_IQR(o, axis=self.axis)\n",
    "            self.median, self.min, self.max = o.new(median), o.new(min), o.new(max)\n",
    "        return (o - self.median) / (self.max - self.min)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__}(by_sample={self.by_sample}, by_var={self.by_var})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.616624653339386,\n",
       " 1.0748440027236938,\n",
       " -2.7678210735321045,\n",
       " 2.5364139080047607)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid)\n",
    "xb, yb = next(iter(dls.train))\n",
    "clipped_xb = TSRobustScale(by_sample=true)(xb)\n",
    "test_ne(clipped_xb, xb)\n",
    "clipped_xb.min(), clipped_xb.max(), xb.min(), xb.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSDiff(Transform):\n",
    "    \"Differences batch of type `TSTensor`\"\n",
    "    order = 90\n",
    "    def __init__(self, lag=1, pad=True):\n",
    "        self.lag, self.pad = lag, pad\n",
    "\n",
    "    def encodes(self, o:TSTensor): \n",
    "        return torch_diff(o, lag=self.lag, pad=self.pad)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__}(lag={self.lag}, pad={self.pad})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor(torch.arange(24).reshape(2,3,4))\n",
    "test_eq(TSDiff()(t)[..., 1:].float().mean(), 1)\n",
    "test_eq(TSDiff(lag=2, pad=False)(t).float().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSLog(Transform):\n",
    "    \"Log transforms batch of type `TSTensor`. For positive values only\"\n",
    "    order = 90\n",
    "    \n",
    "    def encodes(self, o:TSTensor): \n",
    "        return torch.log(o)\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__}()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor(torch.rand(2,3,4) + 10)\n",
    "test_ne(TSLog()(t), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSLogReturn(Transform):\n",
    "    \"Calculates log-return of batch of type `TSTensor`. For positive values only\"\n",
    "    order = 90\n",
    "    def __init__(self, lag=1, pad=True):\n",
    "        self.lag, self.pad = lag, pad\n",
    "\n",
    "    def encodes(self, o:TSTensor):\n",
    "        return torch_diff(torch.log(o), lag=self.lag, pad=self.pad)\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(lag={self.lag}, pad={self.pad})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor([1,2,4,8,16,32,64,128,256]).float()\n",
    "test_eq(TSLogReturn(pad=False)(t).std(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSAdd(Transform):\n",
    "    \"Add a defined amount to each batch of type `TSTensor`.\"\n",
    "    order = 90\n",
    "    def __init__(self, add):\n",
    "        self.add = add\n",
    "\n",
    "    def encodes(self, o:TSTensor):\n",
    "        return torch.add(o, self.add)\n",
    "    def __repr__(self): return f'{self.__class__.__name__}(lag={self.lag}, pad={self.pad})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor([1,2,3]).float()\n",
    "test_eq(TSAdd(1)(t), TSTensor([2,3,4]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 000c_data.preparation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.preprocessing.ipynb.\n",
      "Converted 003b_data.transforms.ipynb.\n",
      "Converted 003c_data.mixed_augmentation.ipynb.\n",
      "Converted 003d_data.image.ipynb.\n",
      "Converted 003e_data.features.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_callback.core.ipynb.\n",
      "Converted 011_callback.noisy_student.ipynb.\n",
      "Converted 012_callback.gblend.ipynb.\n",
      "Converted 013_callback.TSBERT.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
