{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.external"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External data\n",
    "\n",
    "> Helper functions used to download and extract common time series datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import * \n",
    "from tsai.data.validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import zipfile\n",
    "import tempfile\n",
    "try: from urllib import urlretrieve\n",
    "except ImportError: from urllib.request import urlretrieve\n",
    "import shutil\n",
    "from pyunpack import Archive\n",
    "from scipy.io import arff\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def decompress_from_url(url, target_dir=None, verbose=False):\n",
    "    #Download\n",
    "    try:\n",
    "        pv(\"downloading data...\", verbose)\n",
    "        fname = os.path.basename(url)\n",
    "        tmpdir = tempfile.mkdtemp()\n",
    "        local_comp_fname = os.path.join(tmpdir, fname)\n",
    "        urlretrieve(url, local_comp_fname)\n",
    "        pv(\"...data downloaded\", verbose)\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not download url. Please, check url.\\n\")\n",
    "    \n",
    "    #Decompress\n",
    "    try:\n",
    "        pv(\"decompressing data...\", verbose)\n",
    "        if not os.path.exists(target_dir): os.makedirs(target_dir)\n",
    "        Archive(local_comp_fname).extractall(target_dir)\n",
    "        shutil.rmtree(tmpdir)\n",
    "        pv(\"...data decompressed\", verbose)\n",
    "        return target_dir\n",
    "    except:\n",
    "        shutil.rmtree(tmpdir)\n",
    "        if verbose: sys.stderr.write(\"Could not decompress file, aborting.\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_univariate_list():\n",
    "    return [\n",
    "        'ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken',\n",
    "        'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration',\n",
    "        'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY',\n",
    "        'CricketZ', 'Crop', 'DiatomSizeReduction',\n",
    "        'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect',\n",
    "        'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame',\n",
    "        'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays',\n",
    "        'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal',\n",
    "        'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords',\n",
    "        'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain',\n",
    "        'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3',\n",
    "        'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham',\n",
    "        'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate',\n",
    "        'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound',\n",
    "        'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2',\n",
    "        'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian',\n",
    "        'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect',\n",
    "        'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain',\n",
    "        'MoteStrain', 'NonInvasiveFetalECGThorax1',\n",
    "        'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf',\n",
    "        'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane',\n",
    "        'PowerCons', 'ProximalPhalanxOutlineAgeGroup',\n",
    "        'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW',\n",
    "        'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ',\n",
    "        'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace',\n",
    "        'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves',\n",
    "        'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl',\n",
    "        'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG',\n",
    "        'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX',\n",
    "        'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine',\n",
    "        'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_univariate_list()), 128)\n",
    "\n",
    "UCR_univariate_list = get_UCR_univariate_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_multivariate_list():\n",
    "    return [\n",
    "        'ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions',\n",
    "        'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms',\n",
    "        'Epilepsy', 'ERing', 'EthanolConcentration', 'FaceDetection',\n",
    "        'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat',\n",
    "        'InsectWingbeat', 'JapaneseVowels', 'Libras', 'LSST', 'MotorImagery',\n",
    "        'NATOPS', 'PEMS-SF', 'PenDigits', 'PhonemeSpectra', 'RacketSports',\n",
    "        'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits',\n",
    "        'StandWalkJump', 'UWaveGestureLibrary'\n",
    "    ]\n",
    "\n",
    "test_eq(len(get_UCR_multivariate_list()), 30)\n",
    "UCR_multivariate_list = get_UCR_multivariate_list()\n",
    "\n",
    "UCR_list = sorted(UCR_univariate_list + UCR_multivariate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_data(dsid, path='.', parent_dir='data/UCR', on_disk=True, return_split=True, split_data=True, force_download=False, verbose=False):\n",
    "    return_split = return_split and split_data # keep return_split for compatibility. It will be replaced by split_data\n",
    "    if dsid in ['InsectWingbeat']:\n",
    "        if verbose: print('There are problems with the original zip file and data cannot be correctly downloaded')\n",
    "        if return_split: return None, None, None, None\n",
    "        else: return None, None, None\n",
    "    if verbose: print('Dataset:', dsid)\n",
    "    assert dsid in UCR_list, f'{dsid} is not a UCR dataset'\n",
    "    full_parent_dir = Path(path)/parent_dir\n",
    "    full_tgt_dir = full_parent_dir/dsid\n",
    "    if force_download or not all([os.path.isfile(f'{full_parent_dir}/{dsid}/{fn}.npy') for fn in ['X_train', 'X_valid', 'y_train', 'y_valid', 'X', 'y']]):\n",
    "        src_website = 'http://www.timeseriesclassification.com/Downloads'\n",
    "        decompress_from_url(f'{src_website}/{dsid}.zip', target_dir=full_tgt_dir, verbose=verbose)\n",
    "        if dsid == 'DuckDuckGeese': \n",
    "            with zipfile.ZipFile(Path('data/UCR/DuckDuckGeese/DuckDuckGeese_ts.zip'), 'r') as zip_ref: \n",
    "                zip_ref.extractall(Path(parent_dir))\n",
    "        X_train_df, y_train = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TRAIN.ts')\n",
    "        X_valid_df, y_valid = load_from_tsfile_to_dataframe(full_tgt_dir/f'{dsid}_TEST.ts')\n",
    "        X_train_ = []\n",
    "        X_valid_ = []\n",
    "        for i in range(X_train_df.shape[-1]): \n",
    "            X_train_.append(stack_pad(X_train_df[f'dim_{i}'])) # stack arrays even if they have different lengths\n",
    "            X_valid_.append(stack_pad(X_valid_df[f'dim_{i}'])) # stack arrays even if they have different lengths\n",
    "        X_train = np.transpose(np.stack(X_train_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "        X_valid = np.transpose(np.stack(X_valid_, axis=-1), (0, 2, 1)).astype(np.float32)\n",
    "        np.save(f'{full_tgt_dir}/X_train.npy', X_train)\n",
    "        np.save(f'{full_tgt_dir}/y_train.npy', y_train)\n",
    "        np.save(f'{full_tgt_dir}/X_valid.npy', X_valid)\n",
    "        np.save(f'{full_tgt_dir}/y_valid.npy', y_valid)\n",
    "        np.save(f'{full_tgt_dir}/X.npy', concat(X_train, X_valid))\n",
    "        np.save(f'{full_tgt_dir}/y.npy', concat(y_train, y_valid))\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "        delete_all_in_dir(full_tgt_dir, exception='.npy')\n",
    "        \n",
    "    mmap_mode='r+' if on_disk else None\n",
    "    X_train = np.load(f'{full_tgt_dir}/X_train.npy', mmap_mode=mmap_mode)\n",
    "    y_train = np.load(f'{full_tgt_dir}/y_train.npy', mmap_mode=mmap_mode)\n",
    "    X_valid = np.load(f'{full_tgt_dir}/X_valid.npy', mmap_mode=mmap_mode)\n",
    "    y_valid = np.load(f'{full_tgt_dir}/y_valid.npy', mmap_mode=mmap_mode)\n",
    "\n",
    "    if return_split: \n",
    "        if verbose: \n",
    "            print('X_train:', X_train.shape)\n",
    "            print('y_train:', y_train.shape)\n",
    "            print('X_valid:', X_valid.shape)\n",
    "            print('y_valid:', y_valid.shape, '\\n')\n",
    "        return X_train, y_train, X_valid, y_valid\n",
    "    else: \n",
    "        X = np.load(f'{full_tgt_dir}/X.npy', mmap_mode=mmap_mode)\n",
    "        y = np.load(f'{full_tgt_dir}/y.npy', mmap_mode=mmap_mode)\n",
    "        splits = get_predefined_splits(X_train, X_valid)\n",
    "        if verbose: \n",
    "            print('X      :', X .shape)\n",
    "            print('y      :', y .shape)\n",
    "            print('splits :', coll_repr(splits[0]), coll_repr(splits[1]), '\\n')\n",
    "        return X, y, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "PATH = Path(os.getcwd()).parent # Path to /data/UCR\n",
    "dsids = ['OliveOil', 'AtrialFibrillation'] # univariate and multivariate\n",
    "for dsid in dsids:\n",
    "    tgt_dir = PATH/f'data/UCR/{dsid}'\n",
    "    if os.path.isdir(tgt_dir): shutil.rmtree(tgt_dir)\n",
    "    test_eq(len(get_files(tgt_dir)), 0) # no file left\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 6)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    start = time.time()\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR')\n",
    "    elapsed = time.time() - start\n",
    "    test_eq(elapsed < 1, True)\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), 6)\n",
    "    test_eq(len(get_files(tgt_dir, '.npy')), len(get_files(tgt_dir))) # test no left file/ dir\n",
    "    test_eq(X_train.ndim, 3)\n",
    "    test_eq(y_train.ndim, 1)\n",
    "    test_eq(X_valid.ndim, 3)\n",
    "    test_eq(y_valid.ndim, 1)\n",
    "    test_eq(X_train.dtype, np.float32)\n",
    "    test_eq(X_train.__class__.__name__, 'memmap')\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, PATH, parent_dir='data/UCR', on_disk=False)\n",
    "    test_eq(X_train.__class__.__name__, 'ndarray')\n",
    "    del X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NATOPS\n",
      "X_train: (180, 24, 51)\n",
      "y_train: (180,)\n",
      "X_valid: (180, 24, 51)\n",
      "y_valid: (180,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsid = 'NATOPS' \n",
    "X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, verbose=True)\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "test_eq(X[splits[0]], X_train)\n",
    "test_eq(y[splits[1]], y_valid)\n",
    "test_eq(X[splits[0]], X_train)\n",
    "test_eq(y[splits[1]], y_valid)\n",
    "test_type(X, X_train)\n",
    "test_type(y, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_info(X, y=None, splits=None):\n",
    "    if X.ndim == 3:\n",
    "        shape = f'[{X.shape[0]} samples x {X.shape[1]} features x {X.shape[-1]} timesteps]'\n",
    "        print(f'X      - shape: {shape}  type: {cls_name(X)}  dtype:{X.dtype}  isnan: {np.isnan(X).sum()}')\n",
    "    else: \n",
    "        print(f'X      - shape: {X.shape}  type: {cls_name(X)}  dtype:{X.dtype}  isnan: {np.isnan(X).sum()}')\n",
    "    if y is not None:\n",
    "        if isinstance(y[0], (Integral, str)): \n",
    "            n_classes = f'{len(np.unique(y))} {L(np.unique(y).tolist())}'\n",
    "            is_nan = 'nan' in [c.lower() for c in np.unique(y)]\n",
    "            print(f'y      - shape: {y.shape}  type: {cls_name(y)}  dtype:{y.dtype}  n_classes: {n_classes}  isnan: {is_nan}')\n",
    "        else: \n",
    "            print(f'y      - shape: {y.shape}  type: {cls_name(y)}  dtype:{y.dtype}  isnan: {np.isnan(y).sum()}')\n",
    "    if splits is not None: \n",
    "        _splits = get_splits_len(splits)\n",
    "        n_splits = len(_splits)\n",
    "        overlap = check_splits_overlap(splits)\n",
    "        print(f'splits - n_splits: {len(_splits)} shape: {_splits}  overlap: {overlap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X      - shape: [60 samples x 1 features x 570 timesteps]  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:<U1  n_classes: 4 ['1', '2', '3', '4']  isnan: False\n",
      "splits - n_splits: 2 shape: [30, 30]  overlap: [False]\n",
      "X      - shape: (60, 570)  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:<U1  n_classes: 4 ['1', '2', '3', '4']  isnan: False\n",
      "splits - n_splits: 2 shape: [30, 30]  overlap: [False]\n",
      "X      - shape: [60 samples x 1 features x 570 timesteps]  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:float32  isnan: 0\n",
      "splits - n_splits: 2 shape: [30, 30]  overlap: [False]\n",
      "X      - shape: (60, 570)  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:float32  isnan: 10\n",
      "splits - n_splits: 2 shape: [30, 30]  overlap: [False]\n",
      "X      - shape: [60 samples x 1 features x 570 timesteps]  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:<U1  n_classes: 4 ['1', '2', '3', '4']  isnan: False\n",
      "splits - n_splits: 3 shape: [[40, 20], [40, 20], [40, 20]]  overlap: [False, False, False]\n",
      "X      - shape: (60, 570)  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:<U1  n_classes: 4 ['1', '2', '3', '4']  isnan: False\n",
      "splits - n_splits: 3 shape: [[40, 20], [40, 20], [40, 20]]  overlap: [False, False, False]\n",
      "X      - shape: (60, 570)  type: ndarray  dtype:float32  isnan: 0\n",
      "y      - shape: (60,)  type: ndarray  dtype:<U1  n_classes: 5 ['1', '2', '3', '4', 'n']  isnan: False\n",
      "splits - n_splits: 3 shape: [[40, 20], [40, 20], [40, 20]]  overlap: [False, False, False]\n"
     ]
    }
   ],
   "source": [
    "dsid = 'OliveOil'\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False, on_disk=False, force_download=True)\n",
    "get_info(X, y, splits)\n",
    "get_info(X[:, 0], y, splits)\n",
    "y = y.astype(np.float32)\n",
    "get_info(X, y, splits)\n",
    "y[:10] = np.nan\n",
    "get_info(X[:, 0], y, splits)\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False, on_disk=False, force_download=True)\n",
    "splits = get_splits(y, 3)\n",
    "get_info(X, y, splits)\n",
    "get_info(X[:, 0], y, splits)\n",
    "y[:5]= np.nan\n",
    "get_info(X[:, 0], y, splits)\n",
    "X, y, splits = get_UCR_data(dsid, split_data=False, on_disk=False, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
