{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Core\n",
    "\n",
    "> Main Numpy and Times Series functions used throughout the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.external import *\n",
    "from tsai.data.validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: OliveOil\n",
      "X_train: (30, 1, 570)\n",
      "y_train: (30,)\n",
      "X_valid: (30, 1, 570)\n",
      "y_valid: (30,) \n",
      "\n",
      "Dataset: OliveOil\n",
      "X      : (60, 1, 570)\n",
      "y      : (60,)\n",
      "splits : ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]) \n",
      "\n",
      "Dataset: OliveOil\n",
      "X      : (60, 1, 570)\n",
      "y      : (60,)\n",
      "splits : ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsid = 'OliveOil'\n",
    "X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=True)\n",
    "X_on_disk, y_on_disk, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=True, return_split=False)\n",
    "X_in_memory, y_in_memory, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=False, return_split=False)\n",
    "y_tensor = cat2int(y_on_disk)\n",
    "y_array = y_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _fa_rebuild_tensor (cls, *args, **kwargs): return cls(torch._utils._rebuild_tensor_v2(*args, **kwargs))\n",
    "def _fa_rebuild_qtensor(cls, *args, **kwargs): return cls(torch._utils._rebuild_qtensor  (*args, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#old\n",
    "class TensorBase2(Tensor):\n",
    "    def __new__(cls, x, **kwargs):\n",
    "        res = cast(tensor(x), cls)\n",
    "        res._meta = kwargs\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _before_cast(cls, x): return x if isinstance(x,Tensor) else tensor(x)\n",
    "\n",
    "    def __reduce_ex__(self,proto):\n",
    "        torch.utils.hooks.warn_if_has_hooks(self)\n",
    "        args = (type(self), self.storage(), self.storage_offset(), tuple(self.size()), self.stride())\n",
    "        if self.is_quantized: args = args + (self.q_scale(), self.q_zero_point())\n",
    "        f = _fa_rebuild_qtensor if self.is_quantized else  _fa_rebuild_tensor\n",
    "        return (f, args + (self.requires_grad, OrderedDict()))\n",
    "\n",
    "    def gi(self, i):\n",
    "        res = self[i]\n",
    "        return res.as_subclass(type(self)) if isinstance(res,Tensor) else res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return re.sub('tensor', self.__class__.__name__, super().__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(5., grad_fn=<AliasBackward>)\n",
      "TensorBase(10.)\n"
     ]
    }
   ],
   "source": [
    "inp = TensorBase(torch.tensor(5.)).requires_grad_(True)\n",
    "# inp = torch.tensor(5.).requires_grad_(True) # This is OK\n",
    "print(inp)\n",
    "out = inp**2\n",
    "grad = torch.autograd.grad(out, inp, only_inputs=True)[0]\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1019)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_img = TensorBase(torch.randn(2, 3, 16)) # get from Dataloaders\n",
    "# true_img = torch.randn(2, 3, 16) # This is OK\n",
    "w = torch.tensor(3., requires_grad=True)\n",
    "fake_img = torch.randn(2, 3, 16) * w # generate from model\n",
    "def loss_func(fake_img, true_img): return ((fake_img-true_img)**2).mean()\n",
    "loss = loss_func(fake_img, true_img)\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# class NumpyTensor(Tensor): # Temporarily until the issue with require_grad is fixed! TensorBase\n",
    "#     \"Returns a `tensor` with subclass `NumpyTensor` that has a show method\"\n",
    "\n",
    "#     def __new__(cls, o, **kwargs):\n",
    "#         if isinstance(o, (list, L)): o = stack(o)\n",
    "#         res = cast(tensor(o), cls)\n",
    "#         res._meta = kwargs\n",
    "#         return res\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         res = super().__getitem__(idx)\n",
    "#         return res.as_subclass(type(self))\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         if self.numel() == 1: return f'{self}'\n",
    "#         else: return f'NumpyTensor(shape:{list(self.shape)})'\n",
    "\n",
    "#     def show(self, ax=None, ctx=None, title=None, title_color='black', **kwargs):\n",
    "#         if self.ndim != 2: self = type(self)(to2d(self))\n",
    "#         self = self.detach().cpu().numpy()\n",
    "#         ax = ifnone(ax, ctx)\n",
    "#         if ax is None: fig, ax = plt.subplots(**kwargs)\n",
    "#         ax.plot(self.T)\n",
    "#         ax.axis(xmin=0, xmax=self.shape[-1] - 1)\n",
    "#         ax.set_title(title, weight='bold', color=title_color)\n",
    "#         plt.tight_layout()\n",
    "#         return ax\n",
    "\n",
    "\n",
    "# class ToNumpyTensor(Transform):\n",
    "#     \"Transforms an object into NumpyTensor\"\n",
    "#     def encodes(self, o): return NumpyTensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NumpyTensor(TensorBase):\n",
    "    \"Returns a `tensor` with subclass `NumpyTensor` that has a show method\"\n",
    "\n",
    "    def __new__(cls, o, **kwargs):\n",
    "        if isinstance(o, (list, L)): o = stack(o)\n",
    "        res = cast(tensor(o), cls)\n",
    "        res._meta = kwargs\n",
    "        return res\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        return res.as_subclass(type(self))\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.numel() == 1: return f'{self}'\n",
    "        else: return f'NumpyTensor(shape:{tuple(self.shape)})'\n",
    "\n",
    "    def show(self, ax=None, ctx=None, title=None, title_color='black', **kwargs):\n",
    "        if self.ndim != 2: self = type(self)(to2d(self))\n",
    "        self = self.detach().cpu().numpy()\n",
    "        ax = ifnone(ax, ctx)\n",
    "        if ax is None: fig, ax = plt.subplots(**kwargs)\n",
    "        ax.plot(self.T)\n",
    "        ax.axis(xmin=0, xmax=self.shape[-1] - 1)\n",
    "        ax.set_title(title, weight='bold', color=title_color)\n",
    "        plt.tight_layout()\n",
    "        return ax\n",
    "\n",
    "\n",
    "class ToNumpyTensor(Transform):\n",
    "    \"Transforms an object into NumpyTensor\"\n",
    "    def encodes(self, o): return NumpyTensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSTensor(NumpyTensor):\n",
    "    '''Returns a `tensor` with subclass `TSTensor` that has a show method'''\n",
    "    @property\n",
    "    def vars(self): return self.shape[1]\n",
    "\n",
    "    @property\n",
    "    def len(self): return self.shape[-1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.numel() == 1: return f'{self}'\n",
    "        elif self.ndim >= 3:\n",
    "            return f'TSTensor(samples:{self.shape[0]}, vars:{self.shape[1]}, len:{self.shape[-1]})'\n",
    "        elif self.ndim == 2:\n",
    "            return f'TSTensor(vars:{self.shape[1]}, len:{self.shape[-1]})'\n",
    "        elif self.ndim == 1:\n",
    "            return f'TSTensor(len:{self.shape[-1]})'\n",
    "\n",
    "\n",
    "class ToTSTensor(Transform):\n",
    "    \"Transforms an object into TSTensor\"\n",
    "    def encodes(self, o): return TSTensor(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.2446)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/fastai/fastai/issues/278\n",
    "true = TSTensor(torch.randn(2, 3, 4))\n",
    "w = torch.tensor(3., requires_grad=True)\n",
    "fake = torch.randn(2, 3, 4) * w  # generated by model\n",
    "\n",
    "\n",
    "def loss_func(fake, true):\n",
    "    return ((fake - true)**2).mean()\n",
    "\n",
    "\n",
    "loss = loss_func(fake, true)\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor(torch.randn(2, 3, 4))\n",
    "p = torch.tensor(3., requires_grad=True)\n",
    "test = torch.add(true, p)\n",
    "test_eq(test.requires_grad, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTensor(vars:4, len:4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = L([0,1,2,3], [4,5,6,7], [8, 9, 10, 11])\n",
    "TSTensor(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSTensor(samples:30, vars:1, len:570)\n",
      "TSTensor(vars:570, len:570)\n",
      "TSTensor(len:570)\n",
      "-0.6113752722740173\n"
     ]
    }
   ],
   "source": [
    "t = TSTensor(X_train)\n",
    "for i in range(4):\n",
    "    print(t)\n",
    "    if i < 3: t = t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTensor(samples:60, vars:1, len:570)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSTensor(X_on_disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSTensor(samples:60, vars:1, len:570)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToTSTensor()(X_on_disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSTensor(X_train).show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToFloat(Transform):\n",
    "    \"Transforms an object dtype to float\"\n",
    "    def encodes(self, o:torch.Tensor): return o.float()\n",
    "    def encodes(self, o): return o.astype(np.float32)\n",
    "    \n",
    "    \n",
    "class ToInt(Transform):\n",
    "    \"Transforms an object dtype to int\"\n",
    "    def encodes(self, o:torch.Tensor): return o.long()\n",
    "    def encodes(self, o): return o.astype(np.float32).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 2, 10)\n",
    "b = np.array(['1', '2', '3'])\n",
    "c = np.array(['1.0', '2.0', '3.0'])\n",
    "t = torch.randint(0, 2, (10, ))\n",
    "test_eq(ToFloat()(a).dtype, 'float32')\n",
    "test_eq(ToFloat()(b).dtype, 'float32')\n",
    "test_eq(ToFloat()(c).dtype, 'float32')\n",
    "test_eq(ToFloat()(t).dtype, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10)*10\n",
    "b = np.array(['1.0', '2.0', '3.0'])\n",
    "t = torch.rand(10)*10\n",
    "test_eq(ToInt()(a).dtype, 'int64')\n",
    "test_eq(ToInt()(b).dtype, 'int64')\n",
    "test_eq(ToInt()(t).dtype, torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NumpyTensorBlock():\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "        self.type_tfms  =                 L(type_tfms)\n",
    "        self.item_tfms  = ToNumpyTensor + L(item_tfms)\n",
    "        self.batch_tfms =                 L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\n",
    "        \n",
    "class TSTensorBlock():\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "        self.type_tfms  =              L(type_tfms)\n",
    "        self.item_tfms  = ToTSTensor + L(item_tfms)\n",
    "        self.batch_tfms =              L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(NumpyTensorBlock().item_tfms[0].__name__, 'ToNumpyTensor')\n",
    "test_eq(TSTensorBlock().item_tfms[0].__name__, 'ToTSTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TorchDataset():\n",
    "    def __init__(self, X, y=None): self.X, self.y = X, y\n",
    "    def __getitem__(self, idx): return (self.X[idx],) if self.y is None else (self.X[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    \n",
    "class NumpyDataset():\n",
    "    def __init__(self, X, y=None, types=None): self.X, self.y, self.types = X, y, types\n",
    "    def __getitem__(self, idx): \n",
    "        if self.types is None: return (self.X[idx], self.y[idx]) if self.y is not None else (self.X[idx])\n",
    "        else: return (self.types[0](self.X[idx]), self.types[1](self.y[idx])) if self.y is not None else (self.types[0](self.X[idx]))\n",
    "    def __len__(self): return len(self.X)\n",
    "    @property\n",
    "    def c(self): return 0 if self.y is None else 1 if isinstance(self.y[0], float) else len(np.unique(self.y)) \n",
    "\n",
    "    \n",
    "class TSDataset():\n",
    "    def __init__(self, X, y=None, types=None, sel_vars=None, sel_steps=None): \n",
    "        self.X, self.y, self.types = to3darray(X), y, types\n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "    def __getitem__(self, idx): \n",
    "        if self.types is None: return (self.X[idx, self.sel_vars, self.sel_steps], self.y[idx]) if self.y is not None else (self.X[idx])\n",
    "        else: \n",
    "            return (self.types[0](self.X[idx, self.sel_vars, self.sel_steps]), self.types[1](self.y[idx])) if self.y is not None \\\n",
    "            else (self.types[0](self.X[idx]))\n",
    "    def __len__(self): return len(self.X)\n",
    "    @property\n",
    "    def c(self): return 0 if self.y is None else 1 if isinstance(self.y[0], float) else len(np.unique(self.y)) \n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[0]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(5,6,7)\n",
    "b = np.random.rand(5)\n",
    "ds = NumpyDataset(a,b)\n",
    "xb, yb = ds[[0,4]]\n",
    "test_eq(xb.shape, (2,6,7))\n",
    "test_eq(yb.shape, (2,))\n",
    "test_eq(ds.c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(5,6,7)\n",
    "b = np.random.randint(0, 2, 5)\n",
    "ds = TSDataset(a,b)\n",
    "test_eq(ds.c, len(np.unique(b)))\n",
    "test_eq(ds.vars, 6)\n",
    "test_eq(ds.len, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#old\n",
    "class NumpyDatasets(Datasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `tfms` of type item_tfms\"\n",
    "    _xtype, _ytype = NumpyTensor, None # Expected X and y output types (must have a show method)\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None: \n",
    "            X = itemify(X, tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0: \n",
    "            # type(tl[0]).__name__ == 'memmap' is added to avoid loading in memory larger than RAM datasets\n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else tensor(tl[:]) for tl in self.tls])\n",
    "            self.types = [ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for tl,_typ in zip(self.tls, [self._xtype, self._ytype])]\n",
    "    \n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it] if i==0 else ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, inplace=self.inplace, tfms=self.tfms)\n",
    "    \n",
    "    def _new(self, X, *args, y=None, **kwargs): \n",
    "        items = ifnoneelse(y,tuple((X)),tuple((X, y)))\n",
    "        return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    \n",
    "    def show_at(self, idx, **kwargs):\n",
    "        self.show(self[idx], **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "    @property\n",
    "    def items(self): return tuple([tl.items for tl in self.tls])\n",
    "    @items.setter\n",
    "    def items(self, vs):\n",
    "        for tl,c in zip(self.tls, vs): tl.items = v\n",
    "\n",
    "\n",
    "class TSDatasets(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _ytype = TSTensor, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None, \n",
    "                 inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None: \n",
    "            X = itemify(X, tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0: \n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else tensor(tl[:]) for tl in self.tls])\n",
    "            self.types = [ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for tl,_typ in zip(self.tls, [self._xtype, self._ytype])]\n",
    "    \n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms, sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Datasets.__init__)\n",
    "class NumpyDatasets(Datasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `tfms` of type item_tfms\"\n",
    "    _xtype, _ytype = NumpyTensor, None # Expected X and y output types (must have a show method)\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None: \n",
    "            X = itemify(X, tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if 'split' in kwargs: self.split_idxs = kwargs['split']\n",
    "        elif 'splits' in kwargs:  self.split_idxs = kwargs['splits']\n",
    "        else: self.split_idxs = L(np.arange(len(self.tls[0]) if len(self.tls[0]) > 0 else len(self.tls)).tolist())\n",
    "        if len(self.tls[0]) > 0: \n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for tl,_typ in zip(self.tls, [self._xtype, self._ytype])])\n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else tensor(stack(tl[:])) for tl in self.tls])\n",
    "    \n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, inplace=self.inplace, tfms=self.tfms,\n",
    "                                          split=L(self.splits[i]) if self.splits is not None else None)\n",
    "    \n",
    "    def _new(self, X, *args, y=None, **kwargs): \n",
    "        items = tuple((X,)) if y is None else tuple((X, y))\n",
    "        return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "    \n",
    "    def show_at(self, idx, **kwargs):\n",
    "        self.show(self[idx], **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "    @property\n",
    "    def items(self): return tuple([tl.items for tl in self.tls])\n",
    "    @items.setter\n",
    "    def items(self, vs):\n",
    "        for tl,c in zip(self.tls, vs): tl.items = v\n",
    "    @property\n",
    "    def c(self): \n",
    "        return 0 if len(self.tls) == 1 else 1 if isinstance(self.ptls[1][0].item(), float) else len(np.unique(self.ptls[1])) \n",
    "    @property\n",
    "    def loss_func(self): \n",
    "        return MSELossFlat() if self.c == 1 else CrossEntropyLossFlat()\n",
    "\n",
    "\n",
    "@delegates(NumpyDatasets.__init__)\n",
    "class TSDatasets(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _ytype = TSTensor, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None, \n",
    "                 inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None: \n",
    "            X = itemify(to3darray(X), tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if 'split' in kwargs: self.split_idxs = kwargs['split']\n",
    "        elif 'splits' in kwargs:  self.split_idxs = kwargs['splits']\n",
    "        else: self.split_idxs = L(np.arange(len(self.tls[0]) if len(self.tls[0]) > 0 else len(self.tls)).tolist())\n",
    "        if len(self.tls[0]) > 0: \n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for tl,_typ in zip(self.tls, [self._xtype, self._ytype])])\n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else tensor(stack(tl[:])) for tl in self.tls])\n",
    "    \n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, inplace=self.inplace, tfms=self.tfms, \n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps, split=L(self.splits[i]) if self.splits is not None else None)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[0]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits, inplace=False)\n",
    "dsets2 = TSDatasets(X_on_disk[:, 0], y_array, tfms=None, splits=splits, inplace=True)\n",
    "test_eq_type(dsets[0][0].data, dsets2[0][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits, inplace=False)\n",
    "test_eq(len(dsets.train), len(X_train))\n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits, inplace=True)\n",
    "test_eq(len(dsets.train), len(X_train))\n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[add(1), Categorize()], splits=splits, inplace=True)\n",
    "test_eq(len(dsets.train), len(X_train))\n",
    "test_eq(dsets.train[0][0].data, tensor(X_train[0] + 1))\n",
    "test_eq(dsets.train[0][1].data, y_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_ds(dsets, X, y=None, inplace=True):\n",
    "    \"Create test datasets from X (and y) using validation transforms of `dsets`\"\n",
    "    items = tuple((X,)) if y is None else tuple((X, y))\n",
    "    with_labels = False if y is None else True\n",
    "    if isinstance(dsets, (Datasets, NumpyDatasets, TSDatasets)):\n",
    "        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]\n",
    "        new_tls = L([tl._new(item, split_idx=1) for tl,item in zip(tls, items)])\n",
    "        if isinstance(dsets, TSDatasets):\n",
    "            return TSDatasets(tls=new_tls, n_inp=dsets.n_inp, inplace=inplace, tfms=dsets.tfms,\n",
    "                              sel_vars=dsets.sel_vars, sel_steps=dsets.sel_steps)\n",
    "        elif isinstance(dsets, NumpyDatasets):\n",
    "            return NumpyDatasets(tls=new_tls, n_inp=dsets.n_inp, inplace=inplace, tfms=dsets.tfms)\n",
    "        elif isinstance(dsets, Datasets): return Datasets(tls=new_tls)\n",
    "    elif isinstance(dsets, TfmdLists):\n",
    "        new_tl = dsets._new(items, split_idx=1)\n",
    "        return new_tl\n",
    "    else: raise Exception(f\"This method requires using the fastai library to assemble your data.Expected a `Datasets` or a `TfmdLists` but got {dsets.__class__.__name__}\")\n",
    "\n",
    "@patch\n",
    "def add_dataset(self:NumpyDatasets, X, y=None, inplace=True):\n",
    "    return add_ds(self, X, y=y, inplace=inplace)\n",
    "\n",
    "@patch\n",
    "def add_test(self:NumpyDatasets, X, y=None, inplace=True):\n",
    "    return add_ds(self, X, y=y, inplace=inplace)\n",
    "\n",
    "@patch\n",
    "def add_unlabeled(self:NumpyDatasets, X, inplace=True):\n",
    "    return add_ds(self, X, y=None, inplace=inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, Categorize()], splits=splits, inplace=True)\n",
    "test_eq(len(dsets.add_test(X_train, y_train)), len(X_train))\n",
    "test_eq(len(dsets.add_unlabeled(X_train)), len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_batch_tfms = ('after_item','before_batch','after_batch')\n",
    "\n",
    "@delegates(TfmdDL.__init__)\n",
    "class NumpyDataLoader(TfmdDL):\n",
    "    idxs = None\n",
    "    do_item = noops # create batch returns indices\n",
    "    def __init__(self, dataset, bs=64, shuffle=True, drop_last=True, num_workers=None, verbose=False, do_setup=True, batch_tfms=None, **kwargs):\n",
    "        '''batch_tfms == after_batch (either can be used)'''\n",
    "        if num_workers is None: num_workers = min(16, defaults.cpus)\n",
    "        for nm in _batch_tfms: \n",
    "            if nm == 'after_batch':\n",
    "                if batch_tfms is not None: kwargs[nm] = Pipeline(batch_tfms if isinstance(batch_tfms, list) else [batch_tfms])\n",
    "                else: kwargs[nm] = Pipeline(kwargs.get(nm,None))\n",
    "            else: kwargs[nm] = Pipeline(kwargs.get(nm,None))\n",
    "        bs = min(bs, len(dataset))\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers, **kwargs)\n",
    "        if do_setup:\n",
    "            for nm in _batch_tfms:\n",
    "                pv(f\"Setting up {nm}: {kwargs[nm]}\", verbose)\n",
    "                kwargs[nm].setup(self)\n",
    "\n",
    "    def create_batch(self, b):\n",
    "        it = b if self.shuffle else slice(b[0], b[0] + self.bs)\n",
    "        self.idxs = b\n",
    "        if hasattr(self, \"split_idxs\"): self.input_idxs = self.split_idxs[it]\n",
    "        return self.dataset[it]\n",
    "\n",
    "    def create_item(self, s): return s\n",
    "\n",
    "    def get_idxs(self):\n",
    "        idxs = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is not None: idxs = list(range(len(self.dataset)))\n",
    "        if self.shuffle: idxs = self.shuffle_fn(idxs)\n",
    "        return idxs\n",
    "    \n",
    "    def unique_batch(self, max_n=9):\n",
    "        old_bs = self.bs\n",
    "        self.bs = 1\n",
    "        old_get_idxs = self.get_idxs\n",
    "        self.get_idxs = lambda: Inf.zeros\n",
    "        out_len = len(self.items)\n",
    "        types = self.dataset.types\n",
    "        x, y = [], []\n",
    "        for _ in range(max_n): \n",
    "            out = self.one_batch()\n",
    "            if out_len == 2: \n",
    "                x.extend(out[0])\n",
    "                y.extend(out[1])\n",
    "            else: \n",
    "                x.extend(out)\n",
    "        b = (types[0](stack(x)), types[1](stack(y))) if out_len == 2 else (types[0](stack(x)), )\n",
    "        self.bs = old_bs\n",
    "        self.get_idxs = old_get_idxs\n",
    "        return b\n",
    "\n",
    "\n",
    "    @delegates(plt.subplots)\n",
    "    def show_batch(self, b=None, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=(16, 10), unique=False, **kwargs):\n",
    "        if unique: b = self.unique_batch(max_n=max_n)\n",
    "        elif b is None: b = self.one_batch()\n",
    "        db = self.decode_batch(b, max_n=max_n)\n",
    "        if figsize is None: figsize = (ncols*6, max_n//ncols*4)\n",
    "        if ctxs is None: ctxs = get_grid(min(len(db), nrows*ncols), nrows=None, ncols=ncols, figsize=figsize, **kwargs)\n",
    "        for i,ctx in enumerate(ctxs): show_tuple(db[i], ctx=ctx)\n",
    "\n",
    "\n",
    "    @delegates(plt.subplots)\n",
    "    def show_results(self, b, preds, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=(16, 10), **kwargs):\n",
    "        t = self.decode_batch(b, max_n=max_n)\n",
    "        p = self.decode_batch((b[0],preds), max_n=max_n)\n",
    "        if figsize is None: figsize = (ncols*6, max_n//ncols*4)\n",
    "        if ctxs is None: ctxs = get_grid(min(len(t), nrows*ncols), nrows=None, ncols=ncols, figsize=figsize, **kwargs)\n",
    "        for i,ctx in enumerate(ctxs): \n",
    "            title = f'True: {t[i][1]}\\nPred: {p[i][1]}'\n",
    "            color = 'green' if t[i][1] == p[i][1] else 'red'\n",
    "            t[i][0].show(ctx=ctx, title=title, title_color=color)\n",
    "            \n",
    "    @property\n",
    "    def c(self): return self.dataset.c \n",
    "\n",
    "    \n",
    "@delegates(plt.subplots)\n",
    "def show_tuple(tup, **kwargs):\n",
    "    \"Display a timeseries plot from a decoded tuple\"\n",
    "    tup[0].show(title='unlabeled' if len(tup) == 1 else tup[1], **kwargs)\n",
    "    \n",
    "class TSDataLoader(NumpyDataLoader): \n",
    "    @property\n",
    "    def vars(self): \n",
    "        b = self.one_batch()\n",
    "        x = b[0] if isinstance(b, tuple) else b\n",
    "        return x.shape[1]\n",
    "    @property\n",
    "    def len(self): return self.dataset[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_batch_tfms = ('after_item','before_batch','after_batch')\n",
    "\n",
    "class NumpyDataLoaders(DataLoaders):\n",
    "    _xblock = NumpyTensorBlock\n",
    "    _dl_type = NumpyDataLoader \n",
    "    def __init__(self, *loaders, path='.', device=default_device()):\n",
    "        self.loaders,self.path = list(loaders),Path(path)\n",
    "        self.device = device\n",
    "        \n",
    "    @classmethod\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    def from_numpy(cls, X, y=None, splitter=None, valid_pct=0.2, seed=0, item_tfms=None, batch_tfms=None, **kwargs):\n",
    "        \"Create timeseries dataloaders from arrays (X and y, unless unlabeled)\"\n",
    "        if splitter is None: splitter = RandomSplitter(valid_pct=valid_pct, seed=seed)\n",
    "        getters = [ItemGetter(0), ItemGetter(1)] if y is not None else [ItemGetter(0)]\n",
    "        dblock = DataBlock(blocks=(cls._xblock, CategoryBlock),\n",
    "                           getters=getters,\n",
    "                           splitter=splitter,\n",
    "                           item_tfms=item_tfms,\n",
    "                           batch_tfms=batch_tfms)\n",
    "\n",
    "        source = itemify(X) if y is None else itemify(X,y)\n",
    "        return cls.from_dblock(dblock, source, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dsets(cls, *ds, path='.', bs=64, num_workers=0, batch_tfms=None, device=default_device(), shuffle_train=True, **kwargs):\n",
    "        if batch_tfms is not None and not isinstance(batch_tfms, list): batch_tfms = [batch_tfms]\n",
    "        default = (shuffle_train,) + (False,) * (len(ds)-1)\n",
    "        defaults = {'shuffle': default, 'drop_last': default}\n",
    "        kwargs = merge(defaults, {k: tuplify(v, match=ds) for k,v in kwargs.items()})\n",
    "        kwargs = [{k: v[i] for k,v in kwargs.items()} for i in range_of(ds)]\n",
    "        if not is_listy(bs): bs = [bs]\n",
    "        if len(bs) != len(ds): bs = bs * len(ds)\n",
    "        return cls(*[cls._dl_type(d, bs=b, num_workers=num_workers, batch_tfms=batch_tfms, **k) \\\n",
    "                     for d,k,b in zip(ds, kwargs, bs)], path=path, device=device)\n",
    "\n",
    "class TSDataLoaders(NumpyDataLoaders):\n",
    "    _xblock = TSTensorBlock\n",
    "    _dl_type = TSDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def cws(self:NumpyDataLoader):\n",
    "    if isinstance(tensor(self.dataset[0][-1]).item(), Integral):\n",
    "        target = torch.Tensor(self.dataset.items[-1]).to(dtype=torch.int64)\n",
    "        # Compute samples weight (each sample should get its own weight)\n",
    "        class_sample_count = torch.tensor([(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
    "        weights = 1. / class_sample_count.float()\n",
    "        return (weights / weights.sum()).to(default_device())\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 25\n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[None, Categorize()], splits=splits, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2], batch_tfms=add(1))\n",
    "xb,yb = dls.train.one_batch()\n",
    "test_eq(xb.data, tensor(X_on_disk[splits[0]][dls.train.idxs]) + 1)\n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[None, Categorize()], splits=splits, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])\n",
    "xb,yb = dls.train.one_batch()\n",
    "test_eq(xb.shape, (min(bs, len(splits[0])), X_on_disk.shape[1], X_on_disk.shape[-1]))\n",
    "for xb,yb in dls.train: \n",
    "    test_eq(xb.data, tensor(X_on_disk[splits[0]][dls.train.idxs]))\n",
    "it = iter(dls.train)\n",
    "for _ in range(len(dls.train)):\n",
    "    xb,yb = next(it)\n",
    "    test_eq(xb.data, tensor(X_on_disk[dls.train.idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[add(1), Categorize()], splits=RandomSplitter(valid_pct=.3)(y_array), inplace=True)\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])\n",
    "xb,yb = dls.train.one_batch()\n",
    "test_eq(xb.shape, (min(bs, len(dsets.train)), X_on_disk.shape[1], X_on_disk.shape[-1]))\n",
    "xb,yb = dls.valid.one_batch()\n",
    "test_eq(xb.shape, (min(bs*2, len(dsets.valid)), X_on_disk.shape[1], X_on_disk.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[None, Categorize()], splits=splits, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[32, 64])\n",
    "for i in range(100):\n",
    "    dl = dls.train if random.random() < .5 else dls.valid\n",
    "    xb,yb = dl.one_batch()\n",
    "    torch.equal(xb, TSTensor(X_on_disk[dl.input_idxs]))\n",
    "    \n",
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[None, Categorize()], inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets, bs=32)\n",
    "for i in range(100):\n",
    "    xb,yb = dls.one_batch()\n",
    "    torch.equal(xb, TSTensor(X_on_disk[dl.input_idxs]))\n",
    "    \n",
    "dsets = TSDatasets(X_on_disk, tfms=None, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets, bs=32)\n",
    "for i in range(100):\n",
    "    xb = dls.one_batch()\n",
    "    torch.equal(xb[0], TSTensor(X_on_disk[dl.input_idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = TSDatasets(X_on_disk, y_array, tfms=[None, Categorize()], inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets, bs=32)\n",
    "test_eq_type(dls.split_idxs, L(np.arange(len(X_on_disk)).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'NATOPS' \n",
    "bs = 64\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'NATOPS' \n",
    "bs = 64\n",
    "X, y, splits = get_UCR_data(dsid, return_split=False)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=False)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 003_data.transforms.ipynb.\n",
      "Converted 003b_data.image.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 007_metrics.ipynb.\n",
      "Converted 008_learner.ipynb.\n",
      "Converted 009_optimizer.ipynb.\n",
      "Converted 010_callback.ipynb.\n",
      "Converted 100_models.utils.ipynb.\n",
      "Converted 100b_models.layers.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.FCN.ipynb.\n",
      "Converted 103b_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 130_models.Hybrid.ipynb.\n",
      "Converted 200_trading.utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/timeseries/tsai\n",
      "Correct conversion! 😃\n",
      "Total time elapsed 72 s\n",
      "Thursday 11/05/20 21:04:02 CET\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
