{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.mWDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilevel Wavelet Decomposition Network (mWDN)\n",
    "\n",
    "> This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "\n",
    "* Wang, J., Wang, Z., Li, J., & Wu, J. (2018, July). Multilevel wavelet decomposition network for interpretable time series analysis. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2437-2446).\n",
    "* No official implementation found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.models.utils import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "\n",
    "# Wang, J., Wang, Z., Li, J., & Wu, J. (2018, July). Multilevel wavelet decomposition network for interpretable time series analysis. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2437-2446).\n",
    "# No official implementation found\n",
    "\n",
    "\n",
    "class WaveBlock(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len, wavelet=None):\n",
    "        if wavelet is None:\n",
    "            self.h_filter = [-0.2304,0.7148,-0.6309,-0.028,0.187,0.0308,-0.0329,-0.0106]\n",
    "            self.l_filter = [-0.0106,0.0329,0.0308,-0.187,-0.028,0.6309,0.7148,0.2304]\n",
    "        else:\n",
    "            w = pywt.Wavelet(wavelet)\n",
    "            self.h_filter = w.dec_hi\n",
    "            self.l_filter = w.dec_lo\n",
    "\n",
    "        self.mWDN_H = nn.Linear(seq_len,seq_len)\n",
    "        self.mWDN_L = nn.Linear(seq_len,seq_len)\n",
    "        self.mWDN_H.weight = nn.Parameter(self.create_W(seq_len,False))\n",
    "        self.mWDN_L.weight = nn.Parameter(self.create_W(seq_len,True))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.pool = nn.AvgPool1d(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        hp_1 = self.sigmoid(self.mWDN_H(x))\n",
    "        lp_1 = self.sigmoid(self.mWDN_L(x))\n",
    "        hp_out = self.pool(hp_1)\n",
    "        lp_out = self.pool(lp_1)\n",
    "        all_out = torch.cat((hp_out, lp_out), dim=-1)\n",
    "        return lp_out, all_out\n",
    "    \n",
    "    def create_W(self, P, is_l, is_comp=False):\n",
    "        if is_l: filter_list = self.l_filter\n",
    "        else: filter_list = self.h_filter\n",
    "        list_len = len(filter_list)\n",
    "        max_epsilon = np.min(np.abs(filter_list))\n",
    "        if is_comp: weight_np = np.zeros((P, P))\n",
    "        else: weight_np = np.random.randn(P, P) * 0.1 * max_epsilon\n",
    "        for i in range(0, P):\n",
    "            filter_index = 0\n",
    "            for j in range(i, P):\n",
    "                if filter_index < len(filter_list):\n",
    "                    weight_np[i][j] = filter_list[filter_index]\n",
    "                    filter_index += 1\n",
    "        return tensor(weight_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class mWDNPlus(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len, levels=3, wavelet=None, arch=InceptionTimePlus, arch_kwargs={}):\n",
    "        self.levels=levels\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(levels): self.blocks.append(WaveBlock(c_in, c_out, seq_len // 2 ** i, wavelet=wavelet))\n",
    "        self.model = build_model(arch, c_in, c_out, seq_len=seq_len, **arch_kwargs)\n",
    "        if hasattr(self.model, 'head'): \n",
    "            self.head = self.model.head\n",
    "            self.head_nf = self.model.head_nf\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.levels):\n",
    "            x, out_ =  self.blocks[i](x)\n",
    "            if i == 0: out = out_ if i == 0 else torch.cat((out, out_), dim=-1)\n",
    "        out = self.model(out)\n",
    "        return out\n",
    "    \n",
    "mWDN = mWDNPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "c_in = 3\n",
    "seq_len = 12\n",
    "c_out = 2\n",
    "xb = torch.rand(bs, c_in, seq_len)\n",
    "m = mWDN(c_in, c_out, seq_len)\n",
    "test_eq(mWDN(c_in, c_out, seq_len)(xb).shape, [bs, c_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mWDNPlus(\n",
       "  (blocks): ModuleList(\n",
       "    (0): WaveBlock(\n",
       "      (mWDN_H): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (mWDN_L): Linear(in_features=12, out_features=12, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    )\n",
       "    (1): WaveBlock(\n",
       "      (mWDN_H): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (mWDN_L): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    )\n",
       "    (2): WaveBlock(\n",
       "      (mWDN_H): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (mWDN_L): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    )\n",
       "  )\n",
       "  (model): InceptionTimePlus(\n",
       "    (backbone): Sequential(\n",
       "      (0): InceptionBlockPlus(\n",
       "        (inception): ModuleList(\n",
       "          (0): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (1): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (2): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (4): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (5): InceptionModulePlus(\n",
       "            (bottleneck): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (convs): ModuleList(\n",
       "              (0): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "              )\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "              )\n",
       "              (2): ConvBlock(\n",
       "                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (mp_conv): Sequential(\n",
       "              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): ConvBlock(\n",
       "                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (concat): Concat(dim=1)\n",
       "            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): ModuleList(\n",
       "          (0): ConvBlock(\n",
       "            (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): ModuleList(\n",
       "          (0): ReLU()\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (add): Add\n",
       "      )\n",
       "    )\n",
       "    (head): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): GAP1d(\n",
       "          (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          (flatten): Flatten(full=False)\n",
       "        )\n",
       "        (1): LinBnDrop(\n",
       "          (0): Linear(in_features=128, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): GAP1d(\n",
       "        (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "        (flatten): Flatten(full=False)\n",
       "      )\n",
       "      (1): LinBnDrop(\n",
       "        (0): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Sequential(\n",
       "     (0): GAP1d(\n",
       "       (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "       (flatten): Flatten(full=False)\n",
       "     )\n",
       "     (1): LinBnDrop(\n",
       "       (0): Linear(in_features=128, out_features=2, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 128)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.head, m.head_nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "out = create_scripts()\n",
    "beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
