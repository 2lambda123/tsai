#AUTOGENERATED! DO NOT EDIT! file to edit: ./TSBasicData.ipynb (unless otherwise specified)
import fastai
from fastai.torch_core import *
from fastai.basic_data import *
from fastai.data_block import *
from fastai.core import *


try:
    from exp.nb_TSUtilities import *
    from exp.nb_TSDatasets import *
except ImportError:
    from .nb_TSUtilities import *
    from .nb_TSDatasets import *

device = 'cuda' if torch.cuda.is_available() else 'cpu'


class TSItem(ItemBase):
    "`ItemBase` suitable for time series"

    def __init__(self, item, *args, **kwargs):
        super().__init__(item, *args, **kwargs)
        self.data = item
        self.obj = item
        self.channels = item.shape[-2]
        self.seq_len = item.shape[-1]


    def __str__(self):
        return 'TimeSeries(ch={:.0f}, seq_len={:.0f})'.format(
            self.channels, self.seq_len)

    def clone(self):
        return self.__class__(self.data.clone())

    def apply_tfms(self, tfms=None, **kwargs):
        if tfms is None: return self
        x = self.clone()
        for tfm in tfms: x.data = tfm(x.data)
        return x

    def reconstruct(self, item):
        return TSItem(item)

    def show(self, ax=None, title=None, **kwargs):
        x = self.clone()
        if ax is None:
            plt.plot(x.data.transpose_(0, 1))
            plt.title(title)
            plt.show()
        else:
            ax.plot(x.data.transpose_(0, 1))
            ax.title.set_text(title)
            ax.tick_params(
                axis='both',
                which='both',
                bottom='off',
                top='off',
                labelbottom='off',
                right='off',
                left='off',
                labelleft='off')
            return ax

class TimeSeriesItem(TSItem): pass

device = 'cuda' if torch.cuda.is_available() else 'cpu'

class TSDataBunch(DataBunch):

    def scale(self, scale_type='standardize', scale_subtype='per_channel', scale_range=(-1, 1)) -> None:
        self.scale_type = scale_type
        self.scale_subtype = scale_subtype
        self.scale_range = scale_range
        if scale_type is None:
            self.stats = None
            return self

        if scale_subtype == 'per_sample':
            train = To3dArray(self.train_ds.x.items)
            valid = To3dArray(self.valid_ds.x.items)
            if self.test_ds is not None: test = To3dArray(self.test_ds.x.items)

            if self.scale_type == 'normalize':
                train_min = train.min(axis=(1, 2), keepdims=True)
                train_max = train.max(axis=(1, 2), keepdims=True)
                self.train_ds.x.items = (
                    ((train - train_min)) /
                    (train_max - train_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
                valid_min = valid.min(axis=(1, 2), keepdims=True)
                valid_max = valid.max(axis=(1, 2), keepdims=True)
                self.valid_ds.x.items = (
                    ((valid - valid_min)) /
                    (valid_max - valid_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
                if self.test_ds is not None:
                    test_min = test.min(axis=(1, 2), keepdims=True)
                    test_max = test.max(axis=(1, 2), keepdims=True)
                    self.test_ds.x.items = (
                        ((test - test_min)) /
                        (test_max - test_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
                self.stats = None
                return self

            elif self.scale_type == 'standardize':
                train_mean = train.mean(axis=(1, 2), keepdims=True)
                train_std = train.std(axis=(1, 2), keepdims=True)
                self.train_ds.x.items = (train - train_mean) / train_std
                valid_mean = valid.mean(axis=(1, 2), keepdims=True)
                valid_std = valid.std(axis=(1, 2), keepdims=True)
                self.valid_ds.x.items = (valid - valid_mean) / valid_std
                if self.test_ds is not None:
                    test_mean = test.mean(axis=(1, 2), keepdims=True)
                    test_std = test.std(axis=(1, 2), keepdims=True)
                    self.test_ds.x.items = (test - test_mean) / test_std
                self.stats = None
                return self

        elif self.scale_type == 'standardize':
            train = To3dArray(self.train_ds.x.items)
            if self.scale_subtype == 'all_samples':
                train_mean = train.mean(keepdims=True)
                train_std = train.std(keepdims=True)
            elif self.scale_subtype == 'per_channel':
                train_mean = train.mean(axis=(0, 2), keepdims=True)
                train_std = train.std(axis=(0, 2), keepdims=True)
            else:
                print('***** Please, select a valid  scale_subtype *****')
                return
            self.stats = train_mean, train_std
            self.train_ds.x.items = (self.train_ds.x.items - train_mean) / train_std
            self.valid_ds.x.items = (self.valid_ds.x.items - train_mean) / train_std
            if self.test_ds is not None:
                self.test_ds.x.items = (self.test_ds.x.items - train_mean) / train_std
            return self

        elif self.scale_type == 'normalize':
            train = To3dArray(self.train_ds.x.items)
            if self.scale_subtype == 'all_samples':
                train_min = train.min(keepdims=True)
                train_max = train.max(keepdims=True)
            elif self.scale_subtype == 'per_channel':
                train_min = train.min(axis=(0, 2), keepdims=True)
                train_max = train.max(axis=(0, 2), keepdims=True)
            else:
                print('***** Please, select a valid  scaling_subtype *****')
                return
            self.stats = train_min, train_max
            self.train_ds.x.items = (
                ((self.train_ds.x.items - train_min)) /
                (train_max - train_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
            self.valid_ds.x.items = (
                ((self.valid_ds.x.items - train_min)) /
                (train_max - train_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
            if self.test_ds is not None:
                self.test_ds.x.items = (
                    ((self.test_ds.x.items - train_min)) /
                    (train_max - train_min)) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0]
            return self
        else: return print('Select a correct type', self.scale_type)

    @property
    def cw(self)->None: return self._get_cw(self.train_dl)

    @property
    def dbtype(self)->str: return '1D'

    def _get_cw(self, train_dl):
        target = torch.Tensor(train_dl.dataset.y.items).to(dtype=torch.int64)
        # Compute samples weight (each sample should get its own weight)
        class_sample_count = torch.tensor(
            [(target == t).sum() for t in torch.unique(target, sorted=True)])
        weights = 1. / class_sample_count.float()
        return (weights / weights.sum()).to(device)


def show_counts(databunch):
    labels, counts = np.unique(databunch.train_ds.y.items, return_counts=True)
    plt.bar(labels, counts)
    plt.title('labels')
    plt.xticks(labels)
    plt.show()

DataBunch.show_counts = show_counts



class TSPreProcessor(PreProcessor):

    def __init__(self, ds: ItemList): self.ds = ds

    def process(self, ds: ItemList):
        ds.features, ds.seq_len = self.ds.get(0).data.size(-2), self.ds.get(0).data.size(-1)
        ds.f = ds.features
        ds.s = ds.seq_len


class TimeSeriesList(ItemList):
    "`ItemList` suitable for time series"
    _bunch = TSDataBunch
    _processor = TSPreProcessor
    _label_cls = None
    _square_show = True

    def __init__(self, items, *args, mask=None, tfms=None, **kwargs):
        items = To3dTensor(items)
        super().__init__(items, *args, **kwargs)
        self.tfms,self.mask = tfms,mask
        self.copy_new.append('tfms')

    def get(self, i):
        item = super().get(i)
        if self.mask is None: return TSItem(To2dTensor(item))
        else: return[TSItem(To2dTensor(item[m])) for m in self.mask]


    def show_xys(self, xs, ys, figsize=(10, 10), **kwargs):
        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows, rows, figsize=figsize)
        for x, y, ax in zip(xs, ys, axs.flatten()):
            x.show(ax=ax, title=str(y), **kwargs)
        plt.tight_layout()
        plt.show()

    def show_xyzs(self, xs, ys, zs, figsize=(10, 10), **kwargs):
        if self._square_show_res:
            rows = int(np.ceil(math.sqrt(len(xs))))
            fig, axs = plt.subplots(
                rows,
                rows,
                figsize=figsize,
                title='Ground truth\nPredictions',
                weight='bold',
                size=12)
            for x, y, z, ax in zip(xs, ys, zs, axs.flatten()):
                x.show(ax=ax, title=f'{str(y)}\n{str(z)}', **kwargs)
        else:
            fig, axs = plt.subplots(
                len(xs),
                2,
                figsize=figsize,
                title='Ground truth/Predictions',
                weight='bold',
                size=12)
            for i, (x, y, z) in enumerate(zip(xs, ys, zs)):
                x.show(ax=axs[i, 0], title=str(y), **kwargs)
                x.show(ax=axs[i, 1], title=str(z), **kwargs)
        plt.tight_layout()
        plt.show()

    @classmethod
    def from_array(cls, ts, **kwargs):
        return cls(ts)

    @classmethod
    def from_df(cls, df, path='.', cols=None, feat=None, processor=None, **kwargs) -> 'ItemList':
        "Create an `ItemList` in `path` from the inputs in the `cols` of `df`."
        if cols is 0:
            inputs = df
        else:
            col_idxs = df_names_to_idx(list(cols), df)
            inputs = df.iloc[:, col_idxs]
        assert inputs.isna().sum().sum(
        ) == 0, f"You have NaN values in column(s) {cols} of your dataframe, please fix it."
        inputs = df2array(inputs, feat)
        res = cls(
            items=inputs,
            path=path,
            inner_df=df,
            processor=processor,
            **kwargs)
        return res

class TSList(TimeSeriesList): pass



class MixedTimeSeriesList(ItemList):
    "`ItemList` suitable for time series"
    _bunch = TSDataBunch
    _processor = TSPreProcessor
    _label_cls = None
    _square_show = True

    def __init__(self, items, *args, mask=None, tfms=None, **kwargs):
        items = To3dTensor(items)
        super().__init__(items, *args, **kwargs)
        self.tfms,self.mask = tfms,mask
        self.copy_new.append('tfms')

    def get(self, i):
        item = super().get(i)
        if self.mask is None: return TSItem(To2dTensor(item))
        else: return[TSItem(To2dTensor(item[m])) for m in self.mask]


    def show_xys(self, xs, ys, figsize=(10, 10), **kwargs):
        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows, rows, figsize=figsize)
        for x, y, ax in zip(xs, ys, axs.flatten()):
            x.show(ax=ax, title=str(y), **kwargs)
        plt.tight_layout()
        plt.show()

    def show_xyzs(self, xs, ys, zs, figsize=(10, 10), **kwargs):
        if self._square_show_res:
            rows = int(np.ceil(math.sqrt(len(xs))))
            fig, axs = plt.subplots(
                rows,
                rows,
                figsize=figsize,
                title='Ground truth\nPredictions',
                weight='bold',
                size=12)
            for x, y, z, ax in zip(xs, ys, zs, axs.flatten()):
                x.show(ax=ax, title=f'{str(y)}\n{str(z)}', **kwargs)
        else:
            fig, axs = plt.subplots(
                len(xs),
                2,
                figsize=figsize,
                title='Ground truth/Predictions',
                weight='bold',
                size=12)
            for i, (x, y, z) in enumerate(zip(xs, ys, zs)):
                x.show(ax=axs[i, 0], title=str(y), **kwargs)
                x.show(ax=axs[i, 1], title=str(z), **kwargs)
        plt.tight_layout()
        plt.show()

    @classmethod
    def from_array(cls, ts, processor=None, **kwargs):
        return cls(ts, processor=processor, **kwargs)

    @classmethod
    def from_df(cls, df, path='.', cols=None, feat=None, processor=None, **kwargs) -> 'ItemList':
        "Create an `ItemList` in `path` from the inputs in the `cols` of `df`."
        if cols is 0:
            inputs = df
        else:
            col_idxs = df_names_to_idx(list(cols), df)
            inputs = df.iloc[:, col_idxs]
        assert inputs.isna().sum().sum(
        ) == 0, f"You have NaN values in column(s) {cols} of your dataframe, please fix it."
        inputs = df2array(inputs, feat)

        res = cls(
            items=inputs,
            path=path,
            inner_df=df,
            processor=processor,
            **kwargs)
        return res


def df2array(df, feat=None):
    if feat is None:
        return df.values[:, None]
    for i, ch in enumerate(df[feat].unique()):
        data_i = df[df[feat] == ch].values[:, None]
        if i == 0: data = data_i
        else: data = np.concatenate((data, data_i), axis=1)
    return data