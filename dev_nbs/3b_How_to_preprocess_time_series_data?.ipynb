{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T19:14:39.903780Z",
     "start_time": "2020-11-18T19:14:27.952767Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FUSgg3RZy1ad",
    "outputId": "f9cf0373-9d87-4f69-a086-1b4398dcc746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsai       : 0.2.8\n",
      "fastai     : 2.1.6\n",
      "fastcore   : 1.3.5\n",
      "torch      : 1.7.0\n"
     ]
    }
   ],
   "source": [
    "stable = True # True: latest version, False: stable version\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "if ISCOLAB:\n",
    "    if stable: \n",
    "        !pip install tsai\n",
    "    else:\n",
    "        !pip install git+https://github.com/timeseriesAI/tsai.git\n",
    "    \n",
    "import tsai\n",
    "from tsai.all import *\n",
    "print('tsai       :', tsai.__version__)\n",
    "print('fastai     :', fastai.__version__)\n",
    "print('fastcore   :', fastcore.__version__)\n",
    "print('torch      :', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to prepare the input to a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSST state-of-the-art accuracy = 0.64; balanced accuracy: 0.458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy chart!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "97IiBR3Gi76j",
    "outputId": "ca7c9a10-308d-48f9-cb92-8352871b3842"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[TSStandardize(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>1.482326</td>\n",
       "      <td>0.690187</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[TSNormalize(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>1.412870</td>\n",
       "      <td>0.689376</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[TSClipOutliers(by_sample=False, by_var=False)]</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>1.759094</td>\n",
       "      <td>0.628548</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[TSClipOutliers(by_sample=False, by_var=True)]</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>1.648627</td>\n",
       "      <td>0.628143</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[TSNormalize(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[TSNormalize(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619627</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[TSRobustScaler(by_sample=False, by_var=True), TSClipOutliers(by_sample=False, by_var=True)]</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>1.748324</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[TSRobustScaler(by_sample=True, by_var=False), TSClipOutliers(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>1.817344</td>\n",
       "      <td>0.610300</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[TSRobustScaler(by_sample=False, by_var=False), TSClipOutliers(by_sample=False, by_var=False)]</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>1.766534</td>\n",
       "      <td>0.606650</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[TSNormalize(by_sample=False, by_var=False)]</td>\n",
       "      <td>0.635609</td>\n",
       "      <td>1.250225</td>\n",
       "      <td>0.605028</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[TSStandardize(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>1.970584</td>\n",
       "      <td>0.600568</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[TSRobustScaler(by_sample=True, by_var=True), TSClipOutliers(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576237</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[TSRobustScaler(by_sample=False, by_var=False)]</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>2.158556</td>\n",
       "      <td>0.461882</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[TSRobustScaler(by_sample=False, by_var=True)]</td>\n",
       "      <td>0.661591</td>\n",
       "      <td>2.927106</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[TSStandardize(by_sample=False, by_var=False)]</td>\n",
       "      <td>0.644991</td>\n",
       "      <td>3.938079</td>\n",
       "      <td>0.339822</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[TSRobustScaler(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281022</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.605358</td>\n",
       "      <td>3.732968</td>\n",
       "      <td>0.268856</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[TSStandardize(by_sample=False, by_var=True)]</td>\n",
       "      <td>0.627508</td>\n",
       "      <td>4.283718</td>\n",
       "      <td>0.261557</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[TSClipOutliers(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.934182</td>\n",
       "      <td>4.460559</td>\n",
       "      <td>0.235604</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[TSRobustScaler(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>6.568175</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[TSClipOutliers(by_sample=True, by_var=True)]</td>\n",
       "      <td>0.825270</td>\n",
       "      <td>5.356087</td>\n",
       "      <td>0.202758</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      preprocessor  ...  time\n",
       "0                                                    [TSStandardize(by_sample=True, by_var=False)]  ...    70\n",
       "1                                                      [TSNormalize(by_sample=True, by_var=False)]  ...    70\n",
       "2                                                  [TSClipOutliers(by_sample=False, by_var=False)]  ...    70\n",
       "3                                                   [TSClipOutliers(by_sample=False, by_var=True)]  ...    69\n",
       "4                                                       [TSNormalize(by_sample=True, by_var=True)]  ...    71\n",
       "5                                                       [TSNormalize(by_sample=True, by_var=True)]  ...    70\n",
       "6     [TSRobustScaler(by_sample=False, by_var=True), TSClipOutliers(by_sample=False, by_var=True)]  ...    70\n",
       "7     [TSRobustScaler(by_sample=True, by_var=False), TSClipOutliers(by_sample=True, by_var=False)]  ...    81\n",
       "8   [TSRobustScaler(by_sample=False, by_var=False), TSClipOutliers(by_sample=False, by_var=False)]  ...    71\n",
       "9                                                     [TSNormalize(by_sample=False, by_var=False)]  ...    71\n",
       "10                                                    [TSStandardize(by_sample=True, by_var=True)]  ...    70\n",
       "11      [TSRobustScaler(by_sample=True, by_var=True), TSClipOutliers(by_sample=True, by_var=True)]  ...    84\n",
       "12                                                 [TSRobustScaler(by_sample=False, by_var=False)]  ...    70\n",
       "13                                                  [TSRobustScaler(by_sample=False, by_var=True)]  ...    70\n",
       "14                                                  [TSStandardize(by_sample=False, by_var=False)]  ...    69\n",
       "15                                                   [TSRobustScaler(by_sample=True, by_var=True)]  ...    78\n",
       "16                                                                                              []  ...    69\n",
       "17                                                   [TSStandardize(by_sample=False, by_var=True)]  ...    69\n",
       "18                                                  [TSClipOutliers(by_sample=True, by_var=False)]  ...    74\n",
       "19                                                  [TSRobustScaler(by_sample=True, by_var=False)]  ...    77\n",
       "20                                                   [TSClipOutliers(by_sample=True, by_var=True)]  ...    75\n",
       "\n",
       "[21 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsid = 'LSST' \n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "batch_tfm_list = [None, \n",
    "                  TSStandardize(), TSStandardize(by_sample=True), TSStandardize(by_var=True), TSStandardize(by_sample=True, by_var=True), \n",
    "                  TSNormalize(), TSNormalize(by_sample=True), TSNormalize(by_var=True), TSNormalize(by_sample=True, by_var=True), \n",
    "                  TSRobustScaler(), TSRobustScaler(by_sample=True), TSRobustScaler(by_var=True), TSRobustScaler(by_sample=True, by_var=True), \n",
    "                  TSClipOutliers(), TSClipOutliers(by_sample=True), TSClipOutliers(by_var=True), TSClipOutliers(by_sample=True, by_var=True), \n",
    "                  [TSRobustScaler(), TSClipOutliers()], [TSRobustScaler(by_sample=True), TSClipOutliers(by_sample=True)], \n",
    "                  [TSRobustScaler(by_var=True), TSClipOutliers(by_var=True)], \n",
    "                  [TSRobustScaler(by_sample=True, by_var=True), TSClipOutliers(by_sample=True, by_var=True)]]\n",
    "results = pd.DataFrame(columns=['preprocessor', 'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, bt in enumerate(batch_tfm_list): \n",
    "    bt_name = [t for t in L(bt)]\n",
    "    print(f'{i} {bt_name}')\n",
    "    tfms  = [None, Categorize()]\n",
    "    dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=bt)\n",
    "    model = build_model(InceptionTime, dls=dls)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(50, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results.loc[i] = [bt_name, vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    clear_output()\n",
    "    display(results)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "id": "b9--XdQNmhjL",
    "outputId": "b3beb677-e898-4483-dc55-001126fb7766"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[TSStandardize(by_sample=True, by_var=False), TSDiff(lag=1, pad=True)]</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>1.822300</td>\n",
       "      <td>0.628954</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[TSDiff(lag=1, pad=True), TSStandardize(by_sample=True, by_var=False)]</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>1.968431</td>\n",
       "      <td>0.608272</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[TSDiff(lag=1, pad=True)]</td>\n",
       "      <td>0.321753</td>\n",
       "      <td>3.684876</td>\n",
       "      <td>0.340227</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             preprocessor  ...  time\n",
       "0  [TSStandardize(by_sample=True, by_var=False), TSDiff(lag=1, pad=True)]  ...    71\n",
       "1  [TSDiff(lag=1, pad=True), TSStandardize(by_sample=True, by_var=False)]  ...    71\n",
       "2                                               [TSDiff(lag=1, pad=True)]  ...    70\n",
       "\n",
       "[3 rows x 5 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsid = 'LSST' \n",
    "X, y, splits = get_UCR_data(dsid, split_data=False)\n",
    "batch_tfm_list = [TSDiff(), [TSDiff(), TSStandardize(by_sample=True)], [TSStandardize(by_sample=True), TSDiff()]]\n",
    "results4 = pd.DataFrame(columns=['preprocessor', 'train loss', 'valid loss', 'accuracy', 'time'])\n",
    "for i, bt in enumerate(batch_tfm_list): \n",
    "    bt_name = [t for t in L(bt)]\n",
    "    print(f'{i} {bt_name}')\n",
    "    tfms  = [None, Categorize()]\n",
    "    dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=bt)\n",
    "    model = build_model(InceptionTime, dls=dls)\n",
    "    learn = Learner(dls, model,  metrics=accuracy)\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(50, 1e-3)\n",
    "    elapsed = time.time() - start\n",
    "    vals = learn.recorder.values[-1]\n",
    "    results4.loc[i] = [bt_name, vals[0], vals[1], vals[2], int(elapsed)]\n",
    "    results4.sort_values(by='accuracy', ascending=False, ignore_index=True, inplace=True)\n",
    "    clear_output()\n",
    "    display(results4)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAmcucKrnsle"
   },
   "source": [
    "Data preprocessing can have a dramatic impact on performance as we have just seen. There are 2 important aspects to take into account: \n",
    "\n",
    "1. **Scaling:**\n",
    "    When you scale time series data, it's important to decide: what do you want to preserve?\n",
    "\n",
    "    * the ratio between different samples   ---> by_sample=False\n",
    "    * the ratio between different variables ---> by_var=False\n",
    "    * both of them                          ---> by_sample=False, by_bar=False\n",
    "    * neither of them                       ---> by_sample=True, by_bar=True\n",
    "    \n",
    "    My preferred option is to test `None` (as a baseline), `TSStandardize()`, `TSStandardize(by_sample=True)`, and `TSStandardize(by_var=True)`. If any of the last 2 improves performance I may also test `TSStandardize(by_sample=True, by_bar=True)`. \n",
    "\n",
    "\n",
    "2. **Stationarity:**\n",
    "    Another aspect to consider is: should I make the time series stationary?\n",
    "    In general, I have not seen a lot of improvement by making a TS stationary. In case you want to try it though there are 3 options: \n",
    "    \n",
    "    * TSDiff: for differencing. It can be used with both positive and negative inputs.\n",
    "    * TSLog: to apply a logarithm to the inputs. It can only be used with positive inputs.\n",
    "    * TSLogReturn: to apply differencing to the logarithm of the inputs. It can only be used with positive inputs.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is an important requirement to achieve a great performance in many cases. It's important to consider 2 things: \n",
    "\n",
    "* how you want to scale your time series data\n",
    "* whether of not to make data stationary"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "3b_How_to_preprocess_time_series_data?.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
